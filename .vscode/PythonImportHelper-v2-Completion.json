[
    {
        "label": "cgi",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cgi",
        "description": "cgi",
        "detail": "cgi",
        "documentation": {}
    },
    {
        "label": "cStringIO",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cStringIO",
        "description": "cStringIO",
        "detail": "cStringIO",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "fnmatch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fnmatch",
        "description": "fnmatch",
        "detail": "fnmatch",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "scipy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy",
        "description": "scipy",
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "scipy.interpolate",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.interpolate",
        "description": "scipy.interpolate",
        "detail": "scipy.interpolate",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "listdir",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "ceil",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "gviz_api",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gviz_api",
        "description": "gviz_api",
        "detail": "gviz_api",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "basename",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "splitext",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "c_parser",
        "importPath": "pycparser",
        "description": "pycparser",
        "isExtraImport": true,
        "detail": "pycparser",
        "documentation": {}
    },
    {
        "label": "c_ast",
        "importPath": "pycparser",
        "description": "pycparser",
        "isExtraImport": true,
        "detail": "pycparser",
        "documentation": {}
    },
    {
        "label": "parse_file",
        "importPath": "pycparser",
        "description": "pycparser",
        "isExtraImport": true,
        "detail": "pycparser",
        "documentation": {}
    },
    {
        "label": "c_parser",
        "importPath": "pycparser",
        "description": "pycparser",
        "isExtraImport": true,
        "detail": "pycparser",
        "documentation": {}
    },
    {
        "label": "parse_file",
        "importPath": "pycparser",
        "description": "pycparser",
        "isExtraImport": true,
        "detail": "pycparser",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "currentframe",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "getframeinfo",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pycparser.c_ast",
        "description": "pycparser.c_ast",
        "isExtraImport": true,
        "detail": "pycparser.c_ast",
        "documentation": {}
    },
    {
        "label": "CParser",
        "importPath": "pycparser.c_parser",
        "description": "pycparser.c_parser",
        "isExtraImport": true,
        "detail": "pycparser.c_parser",
        "documentation": {}
    },
    {
        "label": "Coord",
        "importPath": "pycparser.c_parser",
        "description": "pycparser.c_parser",
        "isExtraImport": true,
        "detail": "pycparser.c_parser",
        "documentation": {}
    },
    {
        "label": "ParseError",
        "importPath": "pycparser.c_parser",
        "description": "pycparser.c_parser",
        "isExtraImport": true,
        "detail": "pycparser.c_parser",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "auto_refactor",
        "description": "auto_refactor",
        "isExtraImport": true,
        "detail": "auto_refactor",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "codecs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "codecs",
        "description": "codecs",
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "getopt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "getopt",
        "description": "getopt",
        "detail": "getopt",
        "documentation": {}
    },
    {
        "label": "sre_compile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sre_compile",
        "description": "sre_compile",
        "detail": "sre_compile",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "sysconfig",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sysconfig",
        "description": "sysconfig",
        "detail": "sysconfig",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "scipy.optimize",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.optimize",
        "description": "scipy.optimize",
        "detail": "scipy.optimize",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "diff",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "diff",
        "description": "diff",
        "detail": "diff",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Popen",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "PIPE",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "STDOUT",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Popen",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "PIPE",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "STDOUT",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "shlex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shlex",
        "description": "shlex",
        "detail": "shlex",
        "documentation": {}
    },
    {
        "label": "cmd",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cmd",
        "description": "cmd",
        "detail": "cmd",
        "documentation": {}
    },
    {
        "label": "zmq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zmq",
        "description": "zmq",
        "detail": "zmq",
        "documentation": {}
    },
    {
        "label": "pycurl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pycurl",
        "description": "pycurl",
        "detail": "pycurl",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "sha1",
        "importPath": "hashlib",
        "description": "hashlib",
        "isExtraImport": true,
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "imap",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "izip",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "izip_longest",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "imap",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "izip",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "numpy.linalg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy.linalg",
        "description": "numpy.linalg",
        "detail": "numpy.linalg",
        "documentation": {}
    },
    {
        "label": "gaussian_filter",
        "importPath": "scipy.ndimage.filters",
        "description": "scipy.ndimage.filters",
        "isExtraImport": true,
        "detail": "scipy.ndimage.filters",
        "documentation": {}
    },
    {
        "label": "gaussian_filter",
        "importPath": "scipy.ndimage.filters",
        "description": "scipy.ndimage.filters",
        "isExtraImport": true,
        "detail": "scipy.ndimage.filters",
        "documentation": {}
    },
    {
        "label": "csc_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "csc_matrix",
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "isExtraImport": true,
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "inv",
        "importPath": "scipy.sparse.linalg",
        "description": "scipy.sparse.linalg",
        "isExtraImport": true,
        "detail": "scipy.sparse.linalg",
        "documentation": {}
    },
    {
        "label": "inv",
        "importPath": "scipy.sparse.linalg",
        "description": "scipy.sparse.linalg",
        "isExtraImport": true,
        "detail": "scipy.sparse.linalg",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "importPath": "MotionEST",
        "description": "MotionEST",
        "isExtraImport": true,
        "detail": "MotionEST",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "importPath": "MotionEST",
        "description": "MotionEST",
        "isExtraImport": true,
        "detail": "MotionEST",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "importPath": "MotionEST",
        "description": "MotionEST",
        "isExtraImport": true,
        "detail": "MotionEST",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "importPath": "MotionEST",
        "description": "MotionEST",
        "isExtraImport": true,
        "detail": "MotionEST",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "importPath": "MotionEST",
        "description": "MotionEST",
        "isExtraImport": true,
        "detail": "MotionEST",
        "documentation": {}
    },
    {
        "label": "MSE",
        "importPath": "Util",
        "description": "Util",
        "isExtraImport": true,
        "detail": "Util",
        "documentation": {}
    },
    {
        "label": "drawMF",
        "importPath": "Util",
        "description": "Util",
        "isExtraImport": true,
        "detail": "Util",
        "documentation": {}
    },
    {
        "label": "MSE",
        "importPath": "Util",
        "description": "Util",
        "isExtraImport": true,
        "detail": "Util",
        "documentation": {}
    },
    {
        "label": "MSE",
        "importPath": "Util",
        "description": "Util",
        "isExtraImport": true,
        "detail": "Util",
        "documentation": {}
    },
    {
        "label": "filters",
        "importPath": "scipy.ndimage",
        "description": "scipy.ndimage",
        "isExtraImport": true,
        "detail": "scipy.ndimage",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "LineCollection",
        "importPath": "matplotlib.collections",
        "description": "matplotlib.collections",
        "isExtraImport": true,
        "detail": "matplotlib.collections",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "rmtree",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "random",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randrange",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "seed",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "SCMError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "ComparisonError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "SkippedTestError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "DisabledTestError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "NoSuchTestError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "ComparisonError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "FailedTestError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "DisabledTestError",
        "importPath": "digress.errors",
        "description": "digress.errors",
        "isExtraImport": true,
        "detail": "digress.errors",
        "documentation": {}
    },
    {
        "label": "OptionParser",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "OptionGroup",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "digress",
        "description": "digress",
        "isExtraImport": true,
        "detail": "digress",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "digress.constants",
        "description": "digress.constants",
        "isExtraImport": true,
        "detail": "digress.constants",
        "documentation": {}
    },
    {
        "label": "dispatchable",
        "importPath": "digress.cli",
        "description": "digress.cli",
        "isExtraImport": true,
        "detail": "digress.cli",
        "documentation": {}
    },
    {
        "label": "Dispatcher",
        "importPath": "digress.cli",
        "description": "digress.cli",
        "isExtraImport": true,
        "detail": "digress.cli",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "depends",
        "importPath": "digress.testing",
        "description": "digress.testing",
        "isExtraImport": true,
        "detail": "digress.testing",
        "documentation": {}
    },
    {
        "label": "comparer",
        "importPath": "digress.testing",
        "description": "digress.testing",
        "isExtraImport": true,
        "detail": "digress.testing",
        "documentation": {}
    },
    {
        "label": "Fixture",
        "importPath": "digress.testing",
        "description": "digress.testing",
        "isExtraImport": true,
        "detail": "digress.testing",
        "documentation": {}
    },
    {
        "label": "Case",
        "importPath": "digress.testing",
        "description": "digress.testing",
        "isExtraImport": true,
        "detail": "digress.testing",
        "documentation": {}
    },
    {
        "label": "compare_pass",
        "importPath": "digress.comparers",
        "description": "digress.comparers",
        "isExtraImport": true,
        "detail": "digress.comparers",
        "documentation": {}
    },
    {
        "label": "git",
        "importPath": "digress.scm",
        "description": "digress.scm",
        "isExtraImport": true,
        "detail": "digress.scm",
        "documentation": {}
    },
    {
        "label": "DataTableException",
        "kind": 6,
        "importPath": "aom.test.gviz_api",
        "description": "aom.test.gviz_api",
        "peekOfCode": "class DataTableException(Exception):\n  \"\"\"The general exception object thrown by DataTable.\"\"\"\n  pass\nclass DataTableJSONEncoder(json.JSONEncoder):\n  \"\"\"JSON encoder that handles date/time/datetime objects correctly.\"\"\"\n  def __init__(self):\n    json.JSONEncoder.__init__(self,\n                              separators=(\",\", \":\"),\n                              ensure_ascii=False)\n  def default(self, o):",
        "detail": "aom.test.gviz_api",
        "documentation": {}
    },
    {
        "label": "DataTableJSONEncoder",
        "kind": 6,
        "importPath": "aom.test.gviz_api",
        "description": "aom.test.gviz_api",
        "peekOfCode": "class DataTableJSONEncoder(json.JSONEncoder):\n  \"\"\"JSON encoder that handles date/time/datetime objects correctly.\"\"\"\n  def __init__(self):\n    json.JSONEncoder.__init__(self,\n                              separators=(\",\", \":\"),\n                              ensure_ascii=False)\n  def default(self, o):\n    if isinstance(o, datetime.datetime):\n      if o.microsecond == 0:\n        # If the time doesn't have ms-resolution, leave it out to keep",
        "detail": "aom.test.gviz_api",
        "documentation": {}
    },
    {
        "label": "DataTable",
        "kind": 6,
        "importPath": "aom.test.gviz_api",
        "description": "aom.test.gviz_api",
        "peekOfCode": "class DataTable(object):\n  \"\"\"Wraps the data to convert to a Google Visualization API DataTable.\n  Create this object, populate it with data, then call one of the ToJS...\n  methods to return a string representation of the data in the format described.\n  You can clear all data from the object to reuse it, but you cannot clear\n  individual cells, rows, or columns. You also cannot modify the table schema\n  specified in the class constructor.\n  You can add new data one or more rows at a time. All data added to an\n  instantiated DataTable must conform to the schema passed in to __init__().\n  You can reorder the columns in the output table, and also specify row sorting",
        "detail": "aom.test.gviz_api",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.test.gviz_api",
        "description": "aom.test.gviz_api",
        "peekOfCode": "__author__ = \"Amit Weinstein, Misha Seltzer, Jacob Baskin\"\nimport cgi\nimport cStringIO\nimport csv\nimport datetime\ntry:\n  import json\nexcept ImportError:\n  import simplejson as json\nimport types",
        "detail": "aom.test.gviz_api",
        "documentation": {}
    },
    {
        "label": "bdsnr2",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def bdsnr2(metric_set1, metric_set2):\n  \"\"\"\n  BJONTEGAARD    Bjontegaard metric calculation adapted\n  Bjontegaard's snr metric allows to compute the average % saving in decibels\n  between two rate-distortion curves [1].  This is an adaptation of that\n  method that fixes inconsistencies when the curve fit operation goes awry\n  by replacing the curve fit function with a Piecewise Cubic Hermite\n  Interpolating Polynomial and then integrating that by evaluating that\n  function at small intervals using the trapezoid method to calculate\n  the integral.",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "bdrate2",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def bdrate2(metric_set1, metric_set2):\n  \"\"\"\n  BJONTEGAARD    Bjontegaard metric calculation adapted\n  Bjontegaard's metric allows to compute the average % saving in bitrate\n  between two rate-distortion curves [1].  This is an adaptation of that\n  method that fixes inconsistencies when the curve fit operation goes awry\n  by replacing the curve fit function with a Piecewise Cubic Hermite\n  Interpolating Polynomial and then integrating that by evaluating that\n  function at small intervals using the trapezoid method to calculate\n  the integral.",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "FillForm",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def FillForm(string_for_substitution, dictionary_of_vars):\n  \"\"\"\n  This function substitutes all matches of the command string //%% ... %%//\n  with the variable represented by ...  .\n  \"\"\"\n  return_string = string_for_substitution\n  for i in re.findall(\"//%%(.*)%%//\", string_for_substitution):\n    return_string = re.sub(\"//%%\" + i + \"%%//\", dictionary_of_vars[i],\n                           return_string)\n  return return_string",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "HasMetrics",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def HasMetrics(line):\n  \"\"\"\n  The metrics files produced by aomenc are started with a B for headers.\n  \"\"\"\n  # If the first char of the first word on the line is a digit\n  if len(line) == 0:\n    return False\n  if len(line.split()) == 0:\n    return False\n  if line.split()[0][0:1].isdigit():",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "GetMetrics",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def GetMetrics(file_name):\n  metric_file = open(file_name, \"r\")\n  return metric_file.readline().split();\ndef ParseMetricFile(file_name, metric_column):\n  metric_set1 = set([])\n  metric_file = open(file_name, \"r\")\n  for line in metric_file:\n    metrics = string.split(line)\n    if HasMetrics(line):\n      if metric_column < len(metrics):",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "ParseMetricFile",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def ParseMetricFile(file_name, metric_column):\n  metric_set1 = set([])\n  metric_file = open(file_name, \"r\")\n  for line in metric_file:\n    metrics = string.split(line)\n    if HasMetrics(line):\n      if metric_column < len(metrics):\n        try:\n          tuple = float(metrics[0]), float(metrics[metric_column])\n        except:",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "FileBetter",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def FileBetter(file_name_1, file_name_2, metric_column, method):\n  \"\"\"\n  Compares two data files and determines which is better and by how\n  much. Also produces a histogram of how much better, by PSNR.\n  metric_column is the metric.\n  \"\"\"\n  # Store and parse our two files into lists of unique tuples.\n  # Read the two files, parsing out lines starting with bitrate.\n  metric_set1_sorted = ParseMetricFile(file_name_1, metric_column)\n  metric_set2_sorted = ParseMetricFile(file_name_2, metric_column)",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "HandleFiles",
        "kind": 2,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "def HandleFiles(variables):\n  \"\"\"\n  This script creates html for displaying metric data produced from data\n  in a video stats file,  as created by the AOM project when enable_psnr\n  is turned on:\n  Usage: visual_metrics.py template.html pattern base_dir sub_dir [ sub_dir2 ..]\n  The script parses each metrics file [see below] that matches the\n  statfile_pattern  in the baseline directory and looks for the file that\n  matches that same file in each of the sub_dirs, and compares the resultant\n  metrics bitrate, avg psnr, glb psnr, and ssim. \"",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.test.visual_metrics",
        "description": "aom.test.visual_metrics",
        "peekOfCode": "__author__ = \"jzern@google.com (James Zern),\"\n__author__ += \"jimbankoski@google.com (Jim Bankoski)\"\nimport fnmatch\nimport numpy as np\nimport scipy as sp\nimport scipy.interpolate\nimport os\nimport re\nimport string\nimport sys",
        "detail": "aom.test.visual_metrics",
        "documentation": {}
    },
    {
        "label": "StructItem",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class StructItem():\n  def __init__(self,\n               typedef_name=None,\n               struct_name=None,\n               struct_node=None,\n               is_union=False):\n    self.typedef_name = typedef_name\n    self.struct_name = struct_name\n    self.struct_node = struct_node\n    self.is_union = is_union",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "StructInfo",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class StructInfo():\n  def __init__(self):\n    self.struct_name_dic = {}\n    self.typedef_name_dic = {}\n    self.enum_value_dic = {}  # enum value -> enum_node\n    self.enum_name_dic = {}  # enum name -> enum_node\n    self.struct_item_list = []\n  def get_struct_by_typedef_name(self, typedef_name):\n    if typedef_name in self.typedef_name_dic:\n      return self.typedef_name_dic[typedef_name]",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "StructDefVisitor",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class StructDefVisitor(c_ast.NodeVisitor):\n  def __init__(self):\n    self.struct_info = StructInfo()\n  def visit_Struct(self, node):\n    if node.decls != None:\n      self.struct_info.update(None, node.name, node)\n    self.generic_visit(node)\n  def visit_Union(self, node):\n    if node.decls != None:\n      self.struct_info.update(None, node.name, node, True)",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "DeclStatus",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class DeclStatus():\n  def __init__(self, name, struct_item=None, is_ptr_decl=False):\n    self.name = name\n    self.struct_item = struct_item\n    self.is_ptr_decl = is_ptr_decl\n  def get_child_decl_status(self, decl_name):\n    if self.struct_item != None:\n      return self.struct_item.get_child_decl_status(decl_name)\n    else:\n      #TODO(angiebird): 2. Investigage the situation when a struct's definition can't be found.",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "FuncDefVisitor",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class FuncDefVisitor(c_ast.NodeVisitor):\n  func_dictionary = {}\n  def visit_FuncDef(self, node):\n    func_name = node.decl.name\n    self.func_dictionary[func_name] = node\ndef build_func_dictionary(ast):\n  v = FuncDefVisitor()\n  v.visit(ast)\n  return v.func_dictionary\ndef get_func_start_coord(func_node):",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "IDTreeStack",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class IDTreeStack():\n  def __init__(self, global_id_tree):\n    self.stack = deque()\n    self.global_id_tree = global_id_tree\n  def add_link_node(self, node, link_id_chain):\n    link_node = self.add_id_node(link_id_chain)\n    node.link_node = link_node\n    node.link_id_chain = link_id_chain\n  def push_id_tree(self, id_tree=None):\n    if id_tree == None:",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "IDStatusNode",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class IDStatusNode():\n  def __init__(self, name=None, root=None):\n    if root is None:\n      self.root = self\n    else:\n      self.root = root\n    self.name = name\n    self.parent = None\n    self.children = {}\n    self.assign = False",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "FuncInOutVisitor",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class FuncInOutVisitor(c_ast.NodeVisitor):\n  def __init__(self,\n               func_def_node,\n               struct_info,\n               func_dictionary,\n               keep_body_id_tree=True,\n               call_param_map=None,\n               global_id_tree=None,\n               func_history=None,\n               unknown=None):",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "FuncAnalyzer",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "class FuncAnalyzer():\n  def __init__(self):\n    self.ast = get_av1_ast()\n    self.struct_info = build_struct_info(self.ast)\n    self.func_dictionary = build_func_dictionary(self.ast)\n    self.global_id_tree = build_global_id_tree(self.ast, self.struct_info)\n  def analyze(self, func_name):\n    if func_name in self.func_dictionary:\n      func_def_node = self.func_dictionary[func_name]\n      visitor = FuncInOutVisitor(func_def_node, self.struct_info,",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "debug_print",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def debug_print(frameinfo):\n  print('******** ERROR:', frameinfo.filename, frameinfo.lineno, '********')\nclass StructItem():\n  def __init__(self,\n               typedef_name=None,\n               struct_name=None,\n               struct_node=None,\n               is_union=False):\n    self.typedef_name = typedef_name\n    self.struct_name = struct_name",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "build_struct_info",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def build_struct_info(ast):\n  v = StructDefVisitor()\n  v.visit(ast)\n  struct_info = v.struct_info\n  struct_info.update_struct_item_list()\n  return v.struct_info\nclass DeclStatus():\n  def __init__(self, name, struct_item=None, is_ptr_decl=False):\n    self.name = name\n    self.struct_item = struct_item",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "peel_ptr_decl",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def peel_ptr_decl(decl_type_node):\n  \"\"\" Remove PtrDecl and ArrayDecl layer \"\"\"\n  is_ptr_decl = False\n  peeled_decl_type_node = decl_type_node\n  while peeled_decl_type_node.__class__.__name__ == 'PtrDecl' or peeled_decl_type_node.__class__.__name__ == 'ArrayDecl':\n    is_ptr_decl = True\n    peeled_decl_type_node = peeled_decl_type_node.type\n  return is_ptr_decl, peeled_decl_type_node\ndef parse_peeled_decl_type_node(struct_info, node):\n  struct_item = None",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "parse_peeled_decl_type_node",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def parse_peeled_decl_type_node(struct_info, node):\n  struct_item = None\n  if node.__class__.__name__ == 'TypeDecl':\n    if node.type.__class__.__name__ == 'IdentifierType':\n      identifier_type_node = node.type\n      typedef_name = identifier_type_node.names[0]\n      struct_item = struct_info.get_struct_by_typedef_name(typedef_name)\n    elif node.type.__class__.__name__ == 'Struct':\n      struct_node = node.type\n      if struct_node.name != None:",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "parse_decl_node",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def parse_decl_node(struct_info, decl_node):\n  # struct_item is None if this decl_node is not a struct_item\n  decl_node_name = decl_node.name\n  decl_type_node = decl_node.type\n  is_ptr_decl, peeled_decl_type_node = peel_ptr_decl(decl_type_node)\n  struct_item = parse_peeled_decl_type_node(struct_info, peeled_decl_type_node)\n  return DeclStatus(decl_node_name, struct_item, is_ptr_decl)\ndef get_lvalue_lead(lvalue_node):\n  \"\"\"return '&' or '*' of lvalue if available\"\"\"\n  if lvalue_node.__class__.__name__ == 'UnaryOp' and lvalue_node.op == '&':",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_lvalue_lead",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_lvalue_lead(lvalue_node):\n  \"\"\"return '&' or '*' of lvalue if available\"\"\"\n  if lvalue_node.__class__.__name__ == 'UnaryOp' and lvalue_node.op == '&':\n    return '&'\n  elif lvalue_node.__class__.__name__ == 'UnaryOp' and lvalue_node.op == '*':\n    return '*'\n  return None\ndef parse_lvalue(lvalue_node):\n  \"\"\"get id_chain from lvalue\"\"\"\n  id_chain = parse_lvalue_recursive(lvalue_node, [])",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "parse_lvalue",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def parse_lvalue(lvalue_node):\n  \"\"\"get id_chain from lvalue\"\"\"\n  id_chain = parse_lvalue_recursive(lvalue_node, [])\n  return id_chain\ndef parse_lvalue_recursive(lvalue_node, id_chain):\n  \"\"\"cpi->rd->u -> (cpi->rd)->u\"\"\"\n  if lvalue_node.__class__.__name__ == 'ID':\n    id_chain.append(lvalue_node.name)\n    id_chain.reverse()\n    return id_chain",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "parse_lvalue_recursive",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def parse_lvalue_recursive(lvalue_node, id_chain):\n  \"\"\"cpi->rd->u -> (cpi->rd)->u\"\"\"\n  if lvalue_node.__class__.__name__ == 'ID':\n    id_chain.append(lvalue_node.name)\n    id_chain.reverse()\n    return id_chain\n  elif lvalue_node.__class__.__name__ == 'StructRef':\n    id_chain.append(lvalue_node.field.name)\n    return parse_lvalue_recursive(lvalue_node.name, id_chain)\n  elif lvalue_node.__class__.__name__ == 'ArrayRef':",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "build_func_dictionary",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def build_func_dictionary(ast):\n  v = FuncDefVisitor()\n  v.visit(ast)\n  return v.func_dictionary\ndef get_func_start_coord(func_node):\n  return func_node.coord\ndef find_end_node(node):\n  node_list = []\n  for c in node:\n    node_list.append(c)",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_func_start_coord",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_func_start_coord(func_node):\n  return func_node.coord\ndef find_end_node(node):\n  node_list = []\n  for c in node:\n    node_list.append(c)\n  if len(node_list) == 0:\n    return node\n  else:\n    return find_end_node(node_list[-1])",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "find_end_node",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def find_end_node(node):\n  node_list = []\n  for c in node:\n    node_list.append(c)\n  if len(node_list) == 0:\n    return node\n  else:\n    return find_end_node(node_list[-1])\ndef get_func_end_coord(func_node):\n  return find_end_node(func_node).coord",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_func_end_coord",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_func_end_coord(func_node):\n  return find_end_node(func_node).coord\ndef get_func_size(func_node):\n  start_coord = get_func_start_coord(func_node)\n  end_coord = get_func_end_coord(func_node)\n  if start_coord.file == end_coord.file:\n    return end_coord.line - start_coord.line + 1\n  else:\n    return None\ndef save_object(obj, filename):",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_func_size",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_func_size(func_node):\n  start_coord = get_func_start_coord(func_node)\n  end_coord = get_func_end_coord(func_node)\n  if start_coord.file == end_coord.file:\n    return end_coord.line - start_coord.line + 1\n  else:\n    return None\ndef save_object(obj, filename):\n  with open(filename, 'wb') as obj_fp:\n    pickle.dump(obj, obj_fp, protocol=-1)",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "save_object",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def save_object(obj, filename):\n  with open(filename, 'wb') as obj_fp:\n    pickle.dump(obj, obj_fp, protocol=-1)\ndef load_object(filename):\n  obj = None\n  with open(filename, 'rb') as obj_fp:\n    obj = pickle.load(obj_fp)\n  return obj\ndef get_av1_ast(gen_ast=False):\n  # TODO(angiebird): Generalize this path",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "load_object",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def load_object(filename):\n  obj = None\n  with open(filename, 'rb') as obj_fp:\n    obj = pickle.load(obj_fp)\n  return obj\ndef get_av1_ast(gen_ast=False):\n  # TODO(angiebird): Generalize this path\n  c_filename = './av1_pp.c'\n  print('generate ast')\n  ast = parse_file(c_filename)",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_av1_ast",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_av1_ast(gen_ast=False):\n  # TODO(angiebird): Generalize this path\n  c_filename = './av1_pp.c'\n  print('generate ast')\n  ast = parse_file(c_filename)\n  #save_object(ast, ast_file)\n  print('finished generate ast')\n  return ast\ndef get_func_param_id_map(func_def_node):\n  param_id_map = {}",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_func_param_id_map",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def get_func_param_id_map(func_def_node):\n  param_id_map = {}\n  func_decl = func_def_node.decl.type\n  param_list = func_decl.args.params\n  for decl in param_list:\n    param_id_map[decl.name] = decl\n  return param_id_map\nclass IDTreeStack():\n  def __init__(self, global_id_tree):\n    self.stack = deque()",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "build_global_id_tree",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.auto_refactor",
        "description": "aom.tools.auto_refactor.auto_refactor",
        "peekOfCode": "def build_global_id_tree(ast, struct_info):\n  global_id_tree = IDStatusNode()\n  for node in ast.ext:\n    if node.__class__.__name__ == 'Decl':\n      # id tree is for tracking assign/refer status\n      # we don't care about function id because they can't be changed\n      if node.type.__class__.__name__ != 'FuncDecl':\n        decl_status = parse_decl_node(struct_info, node)\n        descendant = global_id_tree.add_child(decl_status.name, decl_status)\n  return global_id_tree",
        "detail": "aom.tools.auto_refactor.auto_refactor",
        "documentation": {}
    },
    {
        "label": "is_code_file",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def is_code_file(filename):\n  return filename.endswith(\".c\") or filename.endswith(\".h\")\ndef is_simd_file(filename):\n  simd_keywords = [\n      \"avx2\", \"sse2\", \"sse3\", \"ssse3\", \"sse4\", \"dspr2\", \"neon\", \"msa\", \"simd\",\n      \"x86\"\n  ]\n  for keyword in simd_keywords:\n    if filename.find(keyword) >= 0:\n      return True",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "is_simd_file",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def is_simd_file(filename):\n  simd_keywords = [\n      \"avx2\", \"sse2\", \"sse3\", \"ssse3\", \"sse4\", \"dspr2\", \"neon\", \"msa\", \"simd\",\n      \"x86\"\n  ]\n  for keyword in simd_keywords:\n    if filename.find(keyword) >= 0:\n      return True\n  return False\ndef get_code_file_list(path, exclude_file_set):",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "get_code_file_list",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def get_code_file_list(path, exclude_file_set):\n  code_file_list = []\n  for cur_dir, sub_dir, file_list in os.walk(path):\n    for filename in file_list:\n      if is_code_file(filename) and not is_simd_file(\n          filename) and filename not in exclude_file_set:\n        file_path = os.path.join(cur_dir, filename)\n        code_file_list.append(file_path)\n  return code_file_list\ndef av1_exclude_file_set():",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "av1_exclude_file_set",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def av1_exclude_file_set():\n  exclude_file_set = {\n      \"cfl_ppc.c\",\n      \"ppc_cpudetect.c\",\n  }\n  return exclude_file_set\ndef get_av1_pp_command(fake_header_dir, code_file_list):\n  pre_command = \"gcc -w -nostdinc -E -I./ -I../ -I\" + fake_header_dir + (\" \"\n                                                                         \"-D'ATTRIBUTE_PACKED='\"\n                                                                         \" \"",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "get_av1_pp_command",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def get_av1_pp_command(fake_header_dir, code_file_list):\n  pre_command = \"gcc -w -nostdinc -E -I./ -I../ -I\" + fake_header_dir + (\" \"\n                                                                         \"-D'ATTRIBUTE_PACKED='\"\n                                                                         \" \"\n                                                                         \"-D'__attribute__(x)='\"\n                                                                         \" \"\n                                                                         \"-D'__inline__='\"\n                                                                         \" \"\n                                                                         \"-D'float_t=float'\"\n                                                                         \" \"",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "modify_av1_rtcd",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def modify_av1_rtcd(build_dir):\n  av1_rtcd = os.path.join(build_dir, \"config/av1_rtcd.h\")\n  fp = open(av1_rtcd)\n  string = fp.read()\n  fp.close()\n  new_string = string.replace(\"#ifdef RTCD_C\", \"#if 0\")\n  fp = open(av1_rtcd, \"w\")\n  fp.write(new_string)\n  fp.close()\ndef preprocess_av1(aom_dir, build_dir, fake_header_dir):",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "preprocess_av1",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.av1_preprocess",
        "description": "aom.tools.auto_refactor.av1_preprocess",
        "peekOfCode": "def preprocess_av1(aom_dir, build_dir, fake_header_dir):\n  cur_dir = os.getcwd()\n  output = os.path.join(cur_dir, \"av1_pp.c\")\n  path_list = [\n      os.path.join(aom_dir, \"av1/encoder\"),\n      os.path.join(aom_dir, \"av1/common\")\n  ]\n  code_file_list = []\n  for path in path_list:\n    path = os.path.realpath(path)",
        "detail": "aom.tools.auto_refactor.av1_preprocess",
        "documentation": {}
    },
    {
        "label": "TestStructInfo",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "class TestStructInfo(googletest.TestCase):\n  def setUp(self):\n    filename = get_c_file_path('struct_code.c')\n    self.ast = parse_file(filename)\n  def test_build_struct_info(self):\n    struct_info = build_struct_info(self.ast)\n    typedef_name_dic = struct_info.typedef_name_dic\n    self.assertEqual('T1' in typedef_name_dic, True)\n    self.assertEqual('T4' in typedef_name_dic, True)\n    self.assertEqual('T5' in typedef_name_dic, True)",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "TestParseLvalue",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "class TestParseLvalue(googletest.TestCase):\n  def setUp(self):\n    filename = get_c_file_path('parse_lvalue.c')\n    self.ast = parse_file(filename)\n    self.func_dictionary = build_func_dictionary(self.ast)\n  def test_parse_lvalue(self):\n    func_node = self.func_dictionary['func']\n    func_body_items = func_node.body.block_items\n    id_list = parse_lvalue(func_body_items[0].lvalue)\n    ref_id_list = ['cpi', 'rd', 'u']",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "TestIDStatusNode",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "class TestIDStatusNode(googletest.TestCase):\n  def test_add_descendant(self):\n    root = IDStatusNode('root')\n    id_chain1 = ['cpi', 'rd', 'u']\n    id_chain2 = ['cpi', 'rd', 'v']\n    root.add_descendant(id_chain1)\n    root.add_descendant(id_chain2)\n    ref_children_list1 = ['cpi']\n    children_list1 = list(root.children.keys())\n    self.assertEqual(children_list1, ref_children_list1)",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "TestFuncInOut",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "class TestFuncInOut(googletest.TestCase):\n  def setUp(self):\n    c_filename = get_c_file_path('func_in_out.c')\n    self.ast = parse_file(c_filename)\n    self.func_dictionary = build_func_dictionary(self.ast)\n    self.struct_info = build_struct_info(self.ast)\n  def test_get_func_param_id_map(self):\n    func_def_node = self.func_dictionary['func']\n    param_id_map = get_func_param_id_map(func_def_node)\n    ref_param_id_map_keys = ['cpi', 'x']",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "TestDeclStatus",
        "kind": 6,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "class TestDeclStatus(googletest.TestCase):\n  def setUp(self):\n    filename = get_c_file_path('decl_status_code.c')\n    self.ast = parse_file(filename)\n    self.func_dictionary = build_func_dictionary(self.ast)\n    self.struct_info = build_struct_info(self.ast)\n  def test_parse_decl_node(self):\n    func_def_node = self.func_dictionary['main']\n    decl_list = func_def_node.body.block_items\n    decl_status = parse_decl_node(self.struct_info, decl_list[0])",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "get_c_file_path",
        "kind": 2,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "def get_c_file_path(filename):\n  return os.path.join('c_files', filename)\nclass TestStructInfo(googletest.TestCase):\n  def setUp(self):\n    filename = get_c_file_path('struct_code.c')\n    self.ast = parse_file(filename)\n  def test_build_struct_info(self):\n    struct_info = build_struct_info(self.ast)\n    typedef_name_dic = struct_info.typedef_name_dic\n    self.assertEqual('T1' in typedef_name_dic, True)",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "sys.path[0:0]",
        "kind": 5,
        "importPath": "aom.tools.auto_refactor.test_auto_refactor",
        "description": "aom.tools.auto_refactor.test_auto_refactor",
        "peekOfCode": "sys.path[0:0] = ['.', '..']\nfrom pycparser import c_parser, parse_file\nfrom pycparser.c_ast import *\nfrom pycparser.c_parser import CParser, Coord, ParseError\nfrom auto_refactor import *\ndef get_c_file_path(filename):\n  return os.path.join('c_files', filename)\nclass TestStructInfo(googletest.TestCase):\n  def setUp(self):\n    filename = get_c_file_path('struct_code.c')",
        "detail": "aom.tools.auto_refactor.test_auto_refactor",
        "documentation": {}
    },
    {
        "label": "lstsq_solution",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def lstsq_solution(A, B):\n    A_inv = np.linalg.pinv(A)\n    x = np.matmul(A_inv, B)\n    return x[0][0]\n# Model B only.\n# Uses the pseudoinverse matrix to find the solution\n# when there are two unknown variables.\ndef pinv_solution(A, mv, B):\n    new_A = np.concatenate((A, mv), axis=1)\n    new_A_inv = np.linalg.pinv(new_A)",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "pinv_solution",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def pinv_solution(A, mv, B):\n    new_A = np.concatenate((A, mv), axis=1)\n    new_A_inv = np.linalg.pinv(new_A)\n    new_x = np.matmul(new_A_inv, B)\n    print(\"pinv solution:\", new_x[0][0], new_x[1][0])\n    return (new_x[0][0], new_x[1][0])\n# Model A only.\n# Finds the coefficient to multiply A by to minimize\n# the percentage error between A and B.\ndef minimize_percentage_error_model_a(A, B):",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "minimize_percentage_error_model_a",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def minimize_percentage_error_model_a(A, B):\n    R = np.divide(A, B)\n    num = 0\n    den = 0\n    best_x = 0\n    best_error = 100\n    for r_i in R:\n        num += r_i\n        den += r_i**2\n    if den == 0:",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "minimize_percentage_error_model_b",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def minimize_percentage_error_model_b(r_e, r_m, r_f):\n    r_ef = np.divide(r_e, r_f)\n    r_mf = np.divide(r_m, r_f)\n    sum_ef = np.sum(r_ef)\n    sum_ef_sq = np.sum(np.square(r_ef))\n    sum_mf = np.sum(r_mf)\n    sum_mf_sq = np.sum(np.square(r_mf))\n    sum_ef_mf = np.sum(np.multiply(r_ef, r_mf))\n    # Divides x by y. If y is zero, returns 0.\n    divide = lambda x, y : 0 if y == 0 else x / y",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "average_lstsq_error",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def average_lstsq_error(A, B, x):\n    error = 0\n    n = 0\n    for i, a in enumerate(A):\n        a = a[0]\n        b = B[i][0]\n        if b == 0:\n            continue\n        n += 1\n        error += (b - x*a)**2",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "average_percent_error_model_a",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def average_percent_error_model_a(A, B, x):\n    error = 0\n    n = 0\n    for i, a in enumerate(A):\n        a = a[0]\n        b = B[i][0]\n        if b == 0:\n            continue\n        n += 1\n        error_i = (abs(x*a-b)/b)*100",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "average_percent_error_model_b",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def average_percent_error_model_b(A, M, B, x):\n    error = 0\n    for i, a in enumerate(A):\n        a = a[0]\n        mv = M[i]\n        b = B[i][0]\n        if b == 0:\n            continue\n        estimate = x[0]*a\n        estimate += x[1]*mv",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "average_squared_error_model_a",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def average_squared_error_model_a(A, B, x):\n    error = 0\n    n = 0\n    for i, a in enumerate(A):\n        a = a[0]\n        b = B[i][0]\n        if b == 0:\n            continue\n        n += 1\n        error_i = (1 - x*(a/b))**2",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "average_squared_error_model_b",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def average_squared_error_model_b(A, M, B, x):\n    error = 0\n    n = 0\n    for i, a in enumerate(A):\n        a = a[0]\n        b = B[i][0]\n        mv = M[i]\n        if b == 0:\n            continue\n        n += 1",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "print_solutions",
        "kind": 2,
        "importPath": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "description": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "peekOfCode": "def print_solutions(file_path):\n    data = np.genfromtxt(file_path, delimiter=\"\\t\")\n    prev_update = 0\n    split_list_indices = list()\n    for i, val in enumerate(data):\n        if prev_update != val[3]:\n            split_list_indices.append(i)\n            prev_update = val[3]\n    split = np.split(data, split_list_indices)\n    for array in split:",
        "detail": "aom.tools.gop_bitrate.python.bitrate_accuracy",
        "documentation": {}
    },
    {
        "label": "get_file_basename",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def get_file_basename(filename):\n  return filename.split(\".\")[0]\ndef parse_log(log_file):\n  data_list = []\n  with open(log_file) as fp:\n    for line in fp:\n      dic = {}\n      word_ls = line.split()\n      i = 0\n      while i < len(word_ls):",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "parse_log",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def parse_log(log_file):\n  data_list = []\n  with open(log_file) as fp:\n    for line in fp:\n      dic = {}\n      word_ls = line.split()\n      i = 0\n      while i < len(word_ls):\n        dic[word_ls[i]] = float(word_ls[i + 1])\n        i += 2",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "extract_data",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def extract_data(data_list, name):\n  arr = []\n  for data in data_list:\n    arr.append(data[name])\n  return arr\ndef visualize_q_indices(exp_summary, exp_list, fig_path=None):\n  for exp in exp_list:\n    data = parse_log(exp[\"log\"])\n    q_indices = extract_data(data, \"q\")\n    plt.title(exp_summary)",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "visualize_q_indices",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def visualize_q_indices(exp_summary, exp_list, fig_path=None):\n  for exp in exp_list:\n    data = parse_log(exp[\"log\"])\n    q_indices = extract_data(data, \"q\")\n    plt.title(exp_summary)\n    plt.xlabel(\"frame_coding_idx\")\n    plt.ylabel(\"q_index\")\n    plt.plot(q_indices, marker=\".\", label=exp[\"label\"])\n  plt.legend()\n  if fig_path:",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "get_rc_type_from_exp_type",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def get_rc_type_from_exp_type(exp_type):\n  if exp_type == \"Q_3P\":\n    return \"q\"\n  return \"vbr\"\ndef test_video(exe_name, input, exp_type, level, log=None, limit=150):\n  basic_cmd = (\"--test-decode=warn --threads=0 --profile=0 --min-q=0 --max-q=63\"\n               \" --auto-alt-ref=1 --kf-max-dist=160 --kf-min-dist=0 \"\n               \"--drop-frame=0 --static-thresh=0 --minsection-pct=0 \"\n               \"--maxsection-pct=2000 --arnr-maxframes=7 --arnr-strength=5 \"\n               \"--sharpness=0 --undershoot-pct=100 --overshoot-pct=100 \"",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "test_video",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def test_video(exe_name, input, exp_type, level, log=None, limit=150):\n  basic_cmd = (\"--test-decode=warn --threads=0 --profile=0 --min-q=0 --max-q=63\"\n               \" --auto-alt-ref=1 --kf-max-dist=160 --kf-min-dist=0 \"\n               \"--drop-frame=0 --static-thresh=0 --minsection-pct=0 \"\n               \"--maxsection-pct=2000 --arnr-maxframes=7 --arnr-strength=5 \"\n               \"--sharpness=0 --undershoot-pct=100 --overshoot-pct=100 \"\n               \"--frame-parallel=0 --tile-columns=0 --cpu-used=3 \"\n               \"--lag-in-frames=48 --psnr\")\n  rc_type = get_rc_type_from_exp_type(exp_type)\n  rc_cmd = \"--end-usage=\" + rc_type",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "gen_ratectrl_log",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def gen_ratectrl_log(test_case):\n  exe = test_case[\"exe\"]\n  video = test_case[\"video\"]\n  exp_type = test_case[\"exp_type\"]\n  level = test_case[\"level\"]\n  log = test_case[\"log\"]\n  test_video(exe, video, exp_type, level, log=log, limit=150)\n  return log\ndef gen_test_case(exp_type, dataset, videoname, level, log_dir=None):\n  test_case = {}",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "gen_test_case",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def gen_test_case(exp_type, dataset, videoname, level, log_dir=None):\n  test_case = {}\n  exe = \"./aomenc_bl\"\n  if exp_type == \"BA_3P\":\n    exe = \"./aomenc_ba\"\n  test_case[\"exe\"] = exe\n  video = os.path.join(dataset, videoname)\n  test_case[\"video\"] = video\n  test_case[\"exp_type\"] = exp_type\n  test_case[\"level\"] = level",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "run_ratectrl_exp",
        "kind": 2,
        "importPath": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "description": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "peekOfCode": "def run_ratectrl_exp(exp_config):\n  fp = open(exp_config)\n  log_dir = \"./lowres_rc_log\"\n  fig_dir = \"./lowres_rc_fig\"\n  dataset = \"lowres\"\n  for line in fp:\n    word_ls = line.split()\n    dataset = word_ls[0]\n    videoname = word_ls[1]\n    exp_type_ls = [\"VBR_3P\", \"BA_3P\"]",
        "detail": "aom.tools.ratectrl_log_analyzer.analyze_ratectrl_log",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.aggregate_entropy_stats",
        "description": "aom.tools.aggregate_entropy_stats",
        "peekOfCode": "def main():\n    dir = sys.argv[1]\n    sum = []\n    for fn in os.listdir(dir):\n        if sys.argv[2] in fn:\n            stats = np.fromfile(dir + fn, dtype=np.int32)\n            if len(sum) == 0:\n                sum = stats\n            else:\n                sum = np.add(sum, stats)",
        "detail": "aom.tools.aggregate_entropy_stats",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.tools.aggregate_entropy_stats",
        "description": "aom.tools.aggregate_entropy_stats",
        "peekOfCode": "__author__ = \"yuec@google.com\"\nimport os\nimport sys\nimport numpy as np\ndef main():\n    dir = sys.argv[1]\n    sum = []\n    for fn in os.listdir(dir):\n        if sys.argv[2] in fn:\n            stats = np.fromfile(dir + fn, dtype=np.int32)",
        "detail": "aom.tools.aggregate_entropy_stats",
        "documentation": {}
    },
    {
        "label": "_IncludeState",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _IncludeState(object):\n  \"\"\"Tracks line numbers for includes, and the order in which includes appear.\n  include_list contains list of lists of (header, line number) pairs.\n  It's a lists of lists rather than just one flat list to make it\n  easier to update across preprocessor boundaries.\n  Call CheckNextIncludeOrder() once for each header in the file, passing\n  in the type constants defined above. Calls in an illegal order will\n  raise an _IncludeError with an appropriate error message.\n  \"\"\"\n  # self._section will move monotonically through this set. If it ever",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CppLintState",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _CppLintState(object):\n  \"\"\"Maintains module-wide state..\"\"\"\n  def __init__(self):\n    self.verbose_level = 1  # global setting.\n    self.error_count = 0    # global count of reported errors\n    # filters to apply when emitting error messages\n    self.filters = _DEFAULT_FILTERS[:]\n    # backup of filter list. Used to restore the state after each file.\n    self._filters_backup = self.filters[:]\n    self.counting = 'total'  # In what way are we counting errors?",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_FunctionState",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _FunctionState(object):\n  \"\"\"Tracks current function name and the number of lines in its body.\"\"\"\n  _NORMAL_TRIGGER = 250  # for --v=0, 500 for --v=1, etc.\n  _TEST_TRIGGER = 400    # about 50% more than _NORMAL_TRIGGER.\n  def __init__(self):\n    self.in_a_function = False\n    self.lines_in_function = 0\n    self.current_function = ''\n  def Begin(self, function_name):\n    \"\"\"Start analyzing function body.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_IncludeError",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _IncludeError(Exception):\n  \"\"\"Indicates a problem with the include order in a file.\"\"\"\n  pass\nclass FileInfo(object):\n  \"\"\"Provides utility functions for filenames.\n  FileInfo provides easy access to the components of a file's path\n  relative to the project root.\n  \"\"\"\n  def __init__(self, filename):\n    self._filename = filename",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FileInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class FileInfo(object):\n  \"\"\"Provides utility functions for filenames.\n  FileInfo provides easy access to the components of a file's path\n  relative to the project root.\n  \"\"\"\n  def __init__(self, filename):\n    self._filename = filename\n  def FullName(self):\n    \"\"\"Make Windows paths like Unix.\"\"\"\n    return os.path.abspath(self._filename).replace('\\\\', '/')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleansedLines",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class CleansedLines(object):\n  \"\"\"Holds 4 copies of all lines with different preprocessing applied to them.\n  1) elided member contains lines without strings and comments.\n  2) lines member contains lines without comments.\n  3) raw_lines member contains all the lines without processing.\n  4) lines_without_raw_strings member is same as raw_lines, but with C++11 raw\n     strings removed.\n  All these members are of <type 'list'>, and of the same length.\n  \"\"\"\n  def __init__(self, lines):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_BlockInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"\n  def __init__(self, linenum, seen_open_brace):\n    self.starting_linenum = linenum\n    self.seen_open_brace = seen_open_brace\n    self.open_parentheses = 0\n    self.inline_asm = _NO_ASM\n    self.check_namespace_indentation = False\n  def CheckBegin(self, filename, clean_lines, linenum, error):\n    \"\"\"Run checks that applies to text up to the opening brace.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ExternCInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _ExternCInfo(_BlockInfo):\n  \"\"\"Stores information about an 'extern \"C\"' block.\"\"\"\n  def __init__(self, linenum):\n    _BlockInfo.__init__(self, linenum, True)\nclass _ClassInfo(_BlockInfo):\n  \"\"\"Stores information about a class.\"\"\"\n  def __init__(self, name, class_or_struct, clean_lines, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name\n    self.is_derived = False",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ClassInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _ClassInfo(_BlockInfo):\n  \"\"\"Stores information about a class.\"\"\"\n  def __init__(self, name, class_or_struct, clean_lines, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name\n    self.is_derived = False\n    self.check_namespace_indentation = True\n    if class_or_struct == 'struct':\n      self.access = 'public'\n      self.is_struct = True",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_NamespaceInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _NamespaceInfo(_BlockInfo):\n  \"\"\"Stores information about a namespace.\"\"\"\n  def __init__(self, name, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name or ''\n    self.check_namespace_indentation = True\n  def CheckEnd(self, filename, clean_lines, linenum, error):\n    \"\"\"Check end of namespace comments.\"\"\"\n    line = clean_lines.raw_lines[linenum]\n    # Check how many lines is enclosed in this namespace.  Don't issue",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_PreprocessorInfo",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class _PreprocessorInfo(object):\n  \"\"\"Stores checkpoints of nesting stacks when #if/#else is seen.\"\"\"\n  def __init__(self, stack_before_if):\n    # The entire nesting stack before #if\n    self.stack_before_if = stack_before_if\n    # The entire nesting stack up to #else\n    self.stack_before_else = []\n    # Whether we have already seen #else or #elif\n    self.seen_else = False\nclass NestingState(object):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "NestingState",
        "kind": 6,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "class NestingState(object):\n  \"\"\"Holds states related to parsing braces.\"\"\"\n  def __init__(self):\n    # Stack for tracking all braces.  An object is pushed whenever we\n    # see a \"{\", and popped when we see a \"}\".  Only 3 types of\n    # objects are possible:\n    # - _ClassInfo: a class or struct.\n    # - _NamespaceInfo: a namespace.\n    # - _BlockInfo: some other type of block.\n    self.stack = []",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessHppHeadersOption",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)\n  except ValueError:\n    PrintUsage('Header extensions must be comma separated list.')\ndef IsHeaderExtension(file_extension):\n  return file_extension in _hpp_headers",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsHeaderExtension",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsHeaderExtension(file_extension):\n  return file_extension in _hpp_headers\ndef ParseNolintSuppressions(filename, raw_line, linenum, error):\n  \"\"\"Updates the global list of line error-suppressions.\n  Parses any NOLINT comments on the current line, updating the global\n  error_suppressions store.  Reports an error if the NOLINT comment\n  was malformed.\n  Args:\n    filename: str, the name of the input file.\n    raw_line: str, the line of input text, with comments.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ParseNolintSuppressions",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ParseNolintSuppressions(filename, raw_line, linenum, error):\n  \"\"\"Updates the global list of line error-suppressions.\n  Parses any NOLINT comments on the current line, updating the global\n  error_suppressions store.  Reports an error if the NOLINT comment\n  was malformed.\n  Args:\n    filename: str, the name of the input file.\n    raw_line: str, the line of input text, with comments.\n    linenum: int, the number of the current line.\n    error: function, an error handler.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessGlobalSuppresions",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessGlobalSuppresions(lines):\n  \"\"\"Updates the list of global error suppressions.\n  Parses any lint directives in the file that have global effect.\n  Args:\n    lines: An array of strings, each representing a line of the file, with the\n           last element being empty if the file is terminated with a newline.\n  \"\"\"\n  for line in lines:\n    if _SEARCH_C_FILE.search(line):\n      for category in _DEFAULT_C_SUPPRESSED_CATEGORIES:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ResetNolintSuppressions",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ResetNolintSuppressions():\n  \"\"\"Resets the set of NOLINT suppressions to empty.\"\"\"\n  _error_suppressions.clear()\n  _global_error_suppressions.clear()\ndef IsErrorSuppressedByNolint(category, linenum):\n  \"\"\"Returns true if the specified error category is suppressed on this line.\n  Consults the global error_suppressions map populated by\n  ParseNolintSuppressions/ProcessGlobalSuppresions/ResetNolintSuppressions.\n  Args:\n    category: str, the category of the error.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsErrorSuppressedByNolint",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsErrorSuppressedByNolint(category, linenum):\n  \"\"\"Returns true if the specified error category is suppressed on this line.\n  Consults the global error_suppressions map populated by\n  ParseNolintSuppressions/ProcessGlobalSuppresions/ResetNolintSuppressions.\n  Args:\n    category: str, the category of the error.\n    linenum: int, the current line number.\n  Returns:\n    bool, True iff the error should be suppressed due to a NOLINT comment or\n    global suppression.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Match",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def Match(pattern, s):\n  \"\"\"Matches the string with the pattern, caching the compiled regexp.\"\"\"\n  # The regexp compilation caching is inlined in both Match and Search for\n  # performance reasons; factoring it out into a separate function turns out\n  # to be noticeably expensive.\n  if pattern not in _regexp_compile_cache:\n    _regexp_compile_cache[pattern] = sre_compile.compile(pattern)\n  return _regexp_compile_cache[pattern].match(s)\ndef ReplaceAll(pattern, rep, s):\n  \"\"\"Replaces instances of pattern in a string with a replacement.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ReplaceAll",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ReplaceAll(pattern, rep, s):\n  \"\"\"Replaces instances of pattern in a string with a replacement.\n  The compiled regex is kept in a cache shared by Match and Search.\n  Args:\n    pattern: regex pattern\n    rep: replacement text\n    s: search string\n  Returns:\n    string with replacements made (or original string if no replacements)\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Search",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def Search(pattern, s):\n  \"\"\"Searches the string for the pattern, caching the compiled regexp.\"\"\"\n  if pattern not in _regexp_compile_cache:\n    _regexp_compile_cache[pattern] = sre_compile.compile(pattern)\n  return _regexp_compile_cache[pattern].search(s)\ndef _IsSourceExtension(s):\n  \"\"\"File extension (excluding dot) matches a source file extension.\"\"\"\n  return s in ('c', 'cc', 'cpp', 'cxx')\nclass _IncludeState(object):\n  \"\"\"Tracks line numbers for includes, and the order in which includes appear.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Error",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def Error(filename, linenum, category, confidence, message):\n  \"\"\"Logs the fact we've found a lint error.\n  We log where the error was found, and also our confidence in the error,\n  that is, how certain we are this is a legitimate style regression, and\n  not a misidentification or a use that's sometimes justified.\n  False positives can be suppressed by the use of\n  \"cpplint(category)\"  comments on the offending line.  These are\n  parsed into _error_suppressions.\n  Args:\n    filename: The name of the file containing the error.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsCppString",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsCppString(line):\n  \"\"\"Does line terminate so, that the next symbol is in string constant.\n  This function does not consider single-line nor multi-line comments.\n  Args:\n    line: is a partial line of code starting from the 0..n.\n  Returns:\n    True, if next character appended to 'line' is inside a\n    string constant.\n  \"\"\"\n  line = line.replace(r'\\\\', 'XX')  # after this, \\\\\" does not match to \\\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleanseRawStrings",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CleanseRawStrings(raw_lines):\n  \"\"\"Removes C++11 raw strings from lines.\n    Before:\n      static const char kData[] = R\"(\n          multi-line string\n          )\";\n    After:\n      static const char kData[] = \"\"\n          (replaced by blank line)\n          \"\";",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindNextMultiLineCommentStart",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FindNextMultiLineCommentStart(lines, lineix):\n  \"\"\"Find the beginning marker for a multiline comment.\"\"\"\n  while lineix < len(lines):\n    if lines[lineix].strip().startswith('/*'):\n      # Only return this marker if the comment goes beyond this line\n      if lines[lineix].strip().find('*/', 2) < 0:\n        return lineix\n    lineix += 1\n  return len(lines)\ndef FindNextMultiLineCommentEnd(lines, lineix):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindNextMultiLineCommentEnd",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FindNextMultiLineCommentEnd(lines, lineix):\n  \"\"\"We are inside a comment, find the end marker.\"\"\"\n  while lineix < len(lines):\n    if lines[lineix].strip().endswith('*/'):\n      return lineix\n    lineix += 1\n  return len(lines)\ndef RemoveMultiLineCommentsFromRange(lines, begin, end):\n  \"\"\"Clears a range of lines for multi-line comments.\"\"\"\n  # Having // <empty> comments makes the lines non-empty, so we will not get",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "RemoveMultiLineCommentsFromRange",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def RemoveMultiLineCommentsFromRange(lines, begin, end):\n  \"\"\"Clears a range of lines for multi-line comments.\"\"\"\n  # Having // <empty> comments makes the lines non-empty, so we will not get\n  # unnecessary blank line warnings later in the code.\n  for i in range(begin, end):\n    lines[i] = '/**/'\ndef RemoveMultiLineComments(filename, lines, error):\n  \"\"\"Removes multiline (c-style) comments from lines.\"\"\"\n  lineix = 0\n  while lineix < len(lines):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "RemoveMultiLineComments",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def RemoveMultiLineComments(filename, lines, error):\n  \"\"\"Removes multiline (c-style) comments from lines.\"\"\"\n  lineix = 0\n  while lineix < len(lines):\n    lineix_begin = FindNextMultiLineCommentStart(lines, lineix)\n    if lineix_begin >= len(lines):\n      return\n    lineix_end = FindNextMultiLineCommentEnd(lines, lineix_begin)\n    if lineix_end >= len(lines):\n      error(filename, lineix_begin + 1, 'readability/multiline_comment', 5,",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleanseComments",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CleanseComments(line):\n  \"\"\"Removes //-comments and single-line C-style /* */ comments.\n  Args:\n    line: A line of C++ source.\n  Returns:\n    The line with single-line comments removed.\n  \"\"\"\n  commentpos = line.find('//')\n  if commentpos != -1 and not IsCppString(line[:commentpos]):\n    line = line[:commentpos].rstrip()",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindEndOfExpressionInLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FindEndOfExpressionInLine(line, startpos, stack):\n  \"\"\"Find the position just after the end of current parenthesized expression.\n  Args:\n    line: a CleansedLines line.\n    startpos: start searching at this position.\n    stack: nesting stack at startpos.\n  Returns:\n    On finding matching end: (index just after matching end, None)\n    On finding an unclosed expression: (-1, None)\n    Otherwise: (-1, new stack at end of this line)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CloseExpression",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CloseExpression(clean_lines, linenum, pos):\n  \"\"\"If input points to ( or { or [ or <, finds the position that closes it.\n  If lines[linenum][pos] points to a '(' or '{' or '[' or '<', finds the\n  linenum/pos that correspond to the closing of the expression.\n  TODO(unknown): cpplint spends a fair bit of time matching parentheses.\n  Ideally we would want to index all opening and closing parentheses once\n  and have CloseExpression be just a simple lookup, but due to preprocessor\n  tricks, this is not so easy.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindStartOfExpressionInLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FindStartOfExpressionInLine(line, endpos, stack):\n  \"\"\"Find position at the matching start of current expression.\n  This is almost the reverse of FindEndOfExpressionInLine, but note\n  that the input position and returned position differs by 1.\n  Args:\n    line: a CleansedLines line.\n    endpos: start searching at this position.\n    stack: nesting stack at endpos.\n  Returns:\n    On finding matching start: (index at matching start, None)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ReverseCloseExpression",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ReverseCloseExpression(clean_lines, linenum, pos):\n  \"\"\"If input points to ) or } or ] or >, finds the position that opens it.\n  If lines[linenum][pos] points to a ')' or '}' or ']' or '>', finds the\n  linenum/pos that correspond to the opening of the expression.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    pos: A position on the line.\n  Returns:\n    A tuple (line, linenum, pos) pointer *at* the opening brace, or",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForCopyright",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForCopyright(filename, lines, error):\n  \"\"\"Logs an error if no Copyright message appears at the top of the file.\"\"\"\n  # We'll say it should occur by line 10. Don't forget there's a\n  # placeholder line at the front.\n  for line in xrange(1, min(len(lines), 11)):\n    if re.search(r'Copyright', lines[line], re.I): break\n  else:                       # means no copyright line was found\n    error(filename, 0, 'legal/copyright', 5,\n          'No copyright message found.  '\n          'You should have a line: \"Copyright [year] <Copyright Owner>\"')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetIndentLevel",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def GetIndentLevel(line):\n  \"\"\"Return the number of leading spaces in line.\n  Args:\n    line: A string to check.\n  Returns:\n    An integer count of leading spaces, possibly zero.\n  \"\"\"\n  indent = Match(r'^( *)\\S', line)\n  if indent:\n    return len(indent.group(1))",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PathSplitToList",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def PathSplitToList(path):\n  \"\"\"Returns the path split into a list by the separator.\n  Args:\n    path: An absolute or relative path (e.g. '/a/b/c/' or '../a')\n  Returns:\n    A list of path components (e.g. ['a', 'b', 'c]).\n  \"\"\"\n  lst = []\n  while True:\n    (head, tail) = os.path.split(path)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetHeaderGuardCPPVariable",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def GetHeaderGuardCPPVariable(filename):\n  \"\"\"Returns the CPP variable that should be used as a header guard.\n  Args:\n    filename: The name of a C++ header file.\n  Returns:\n    The CPP variable that should be used as a header guard in the\n    named file.\n  \"\"\"\n  # Restores original filename in case that cpplint is invoked from Emacs's\n  # flymake.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForHeaderGuard",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForHeaderGuard(filename, clean_lines, error):\n  \"\"\"Checks that the file contains a header guard.\n  Logs an error if no #ifndef header guard is present.  For other\n  headers, checks that the full pathname is used.\n  Args:\n    filename: The name of the C++ header file.\n    clean_lines: A CleansedLines instance containing the file.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Don't check for header guards if there are error suppression",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckHeaderFileIncluded",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckHeaderFileIncluded(filename, include_state, error):\n  \"\"\"Logs an error if a .cc file does not include its header.\"\"\"\n  # Do not check test files\n  fileinfo = FileInfo(filename)\n  if Search(_TEST_FILE_SUFFIX, fileinfo.BaseName()):\n    return\n  headerfile = filename[0:len(filename) - len(fileinfo.Extension())] + '.h'\n  if not os.path.exists(headerfile):\n    return\n  headername = FileInfo(headerfile).RepositoryName()",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForBadCharacters",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForBadCharacters(filename, lines, error):\n  \"\"\"Logs an error for each line containing bad characters.\n  Two kinds of bad characters:\n  1. Unicode replacement characters: These indicate that either the file\n  contained invalid UTF-8 (likely) or Unicode replacement characters (which\n  it shouldn't).  Note that it's possible for this to throw off line\n  numbering if the invalid UTF-8 occurred adjacent to a newline.\n  2. NUL bytes.  These are problematic for some tools.\n  Args:\n    filename: The name of the current file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNewlineAtEOF",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForNewlineAtEOF(filename, lines, error):\n  \"\"\"Logs an error if there is no newline char at the end of the file.\n  Args:\n    filename: The name of the current file.\n    lines: An array of strings, each representing a line of the file.\n    error: The function to call with any errors found.\n  \"\"\"\n  # The array lines() was created by adding two newlines to the\n  # original file (go figure), then splitting on \\n.\n  # To verify that the file ends in \\n, we just have to make sure the",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForMultilineCommentsAndStrings",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForMultilineCommentsAndStrings(filename, clean_lines, linenum, error):\n  \"\"\"Logs an error if we see /* ... */ or \"...\" that extend past one line.\n  /* ... */ comments are legit inside macros, for one line.\n  Otherwise, we prefer // comments, so it's ok to warn about the\n  other.  Likewise, it's ok for strings to extend across multiple\n  lines, as long as a line continuation character (backslash)\n  terminates each line. Although not currently prohibited by the C++\n  style guide, it's ugly and unnecessary. We don't do well with either\n  in this lint program, so we warn about both.\n  Args:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckPosixThreading",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckPosixThreading(filename, clean_lines, linenum, error):\n  \"\"\"Checks for calls to thread-unsafe functions.\n  Much code has been originally written without consideration of\n  multi-threading. Also, engineers are relying on their old experience;\n  they have learned posix before threading extensions were added. These\n  tests guide the engineers to use thread-safe functions (when using\n  posix directly).\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckVlogArguments",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckVlogArguments(filename, clean_lines, linenum, error):\n  \"\"\"Checks that VLOG() is only used for defining a logging level.\n  For example, VLOG(2) is correct. VLOG(INFO), VLOG(WARNING), VLOG(ERROR), and\n  VLOG(FATAL) are not.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckInvalidIncrement",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckInvalidIncrement(filename, clean_lines, linenum, error):\n  \"\"\"Checks for invalid increment *count++.\n  For example following function:\n  void increment_counter(int* count) {\n    *count++;\n  }\n  is invalid, because it effectively does count++, moving pointer, and should\n  be replaced with ++*count, (*count)++ or *count += 1.\n  Args:\n    filename: The name of the current file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsMacroDefinition",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsMacroDefinition(clean_lines, linenum):\n  if Search(r'^#define', clean_lines[linenum]):\n    return True\n  if linenum > 0 and Search(r'\\\\$', clean_lines[linenum - 1]):\n    return True\n  return False\ndef IsForwardClassDeclaration(clean_lines, linenum):\n  return Match(r'^\\s*(\\btemplate\\b)*.*class\\s+\\w+;\\s*$', clean_lines[linenum])\nclass _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsForwardClassDeclaration",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsForwardClassDeclaration(clean_lines, linenum):\n  return Match(r'^\\s*(\\btemplate\\b)*.*class\\s+\\w+;\\s*$', clean_lines[linenum])\nclass _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"\n  def __init__(self, linenum, seen_open_brace):\n    self.starting_linenum = linenum\n    self.seen_open_brace = seen_open_brace\n    self.open_parentheses = 0\n    self.inline_asm = _NO_ASM\n    self.check_namespace_indentation = False",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNonStandardConstructs",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForNonStandardConstructs(filename, clean_lines, linenum,\n                                  nesting_state, error):\n  r\"\"\"Logs an error if we see certain non-ANSI constructs ignored by gcc-2.\n  Complain about several constructs which gcc-2 accepts, but which are\n  not standard C++.  Warning about these in lint is one way to ease the\n  transition to new compilers.\n  - put storage class first (e.g. \"static const\" instead of \"const static\").\n  - \"%lld\" instead of %qd\" in printf-type functions.\n  - \"%1$d\" is non-standard in printf-type functions.\n  - \"\\%\" is an undefined character escape sequence.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSpacingForFunctionCall",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckSpacingForFunctionCall(filename, clean_lines, linenum, error):\n  \"\"\"Checks for the correctness of various spacing around function calls.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Since function calls often occur inside if/for/while/switch",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsBlankLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsBlankLine(line):\n  \"\"\"Returns true if the given line is blank.\n  We consider a line to be blank if the line is empty or consists of\n  only white spaces.\n  Args:\n    line: A line of a string.\n  Returns:\n    True, if the given line is blank.\n  \"\"\"\n  return not line or line.isspace()",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNamespaceIndentation",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForNamespaceIndentation(filename, nesting_state, clean_lines, line,\n                                 error):\n  is_namespace_indent_item = (\n      len(nesting_state.stack) > 1 and\n      nesting_state.stack[-1].check_namespace_indentation and\n      isinstance(nesting_state.previous_stack_top, _NamespaceInfo) and\n      nesting_state.previous_stack_top == nesting_state.stack[-2])\n  if ShouldCheckNamespaceIndentation(nesting_state, is_namespace_indent_item,\n                                     clean_lines.elided, line):\n    CheckItemIndentationInNamespace(filename, clean_lines.elided,",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForFunctionLengths",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForFunctionLengths(filename, clean_lines, linenum,\n                            function_state, error):\n  \"\"\"Reports for long function bodies.\n  For an overview why this is done, see:\n  https://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Write_Short_Functions\n  Uses a simplistic algorithm assuming other style guidelines\n  (especially spacing) are followed.\n  Only checks unindented functions, so class members are unchecked.\n  Trivial bodies are unchecked, so constructors with huge initializer lists\n  may be missed.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckComment",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckComment(line, filename, linenum, next_line_start, error):\n  \"\"\"Checks for common mistakes in comments.\n  Args:\n    line: The line in question.\n    filename: The name of the current file.\n    linenum: The number of the line to check.\n    next_line_start: The first non-whitespace column of the next line.\n    error: The function to call with any errors found.\n  \"\"\"\n  commentpos = line.find('//')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckSpacing(filename, clean_lines, linenum, nesting_state, error):\n  \"\"\"Checks for the correctness of various spacing issues in the code.\n  Things we check for: spaces around operators, spaces after\n  if/for/while/switch, no spaces around parens in function calls, two\n  spaces between code and comment, don't start a block with a blank\n  line, don't end a function with a blank line, don't add a blank line\n  after public/protected/private, don't have too many blank lines in a row.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckOperatorSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckOperatorSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing around operators.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Don't try to do spacing checks for operator methods.  Do this by",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckParenthesisSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckParenthesisSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing around parentheses.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # No spaces after an if, while, switch, or for",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCommaSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckCommaSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing near commas and semicolons.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  raw = clean_lines.lines_without_raw_strings\n  line = clean_lines.elided[linenum]",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckBracesSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckBracesSpacing(filename, clean_lines, linenum, nesting_state, error):\n  \"\"\"Checks for horizontal spacing near commas.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    nesting_state: A NestingState instance which maintains information about\n                   the current stack of nested blocks being parsed.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsDecltype",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsDecltype(clean_lines, linenum, column):\n  \"\"\"Check if the token ending on (linenum, column) is decltype().\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: the number of the line to check.\n    column: end column of the token to check.\n  Returns:\n    True if this token is decltype() expression, False otherwise.\n  \"\"\"\n  (text, _, start_col) = ReverseCloseExpression(clean_lines, linenum, column)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSectionSpacing",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckSectionSpacing(filename, clean_lines, class_info, linenum, error):\n  \"\"\"Checks for additional blank line issues related to sections.\n  Currently the only thing checked here is blank line before protected/private.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    class_info: A _ClassInfo objects.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetPreviousNonBlankLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def GetPreviousNonBlankLine(clean_lines, linenum):\n  \"\"\"Return the most recent non-blank line and its line number.\n  Args:\n    clean_lines: A CleansedLines instance containing the file contents.\n    linenum: The number of the line to check.\n  Returns:\n    A tuple with two elements.  The first element is the contents of the last\n    non-blank line before the current line, or the empty string if this is the\n    first non-blank line.  The second is the line number of that line, or -1\n    if this is the first non-blank line.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckBraces",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckBraces(filename, clean_lines, linenum, error):\n  \"\"\"Looks for misplaced braces (e.g. at the end of line).\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]        # get rid of comments and strings\n  if Match(r'\\s*{\\s*$', line):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckTrailingSemicolon",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckTrailingSemicolon(filename, clean_lines, linenum, error):\n  \"\"\"Looks for redundant trailing semicolon.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Block bodies should not be followed by a semicolon.  Due to C++11",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckEmptyBlockBody",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckEmptyBlockBody(filename, clean_lines, linenum, error):\n  \"\"\"Look for empty loop/conditional body with only a single semicolon.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Search for loop keywords at the beginning of the line.  Because only\n  # whitespaces are allowed before the keywords, this will also ignore most",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindCheckMacro",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FindCheckMacro(line):\n  \"\"\"Find a replaceable CHECK-like macro.\n  Args:\n    line: line to search on.\n  Returns:\n    (macro name, start position), or (None, -1) if no replaceable\n    macro is found.\n  \"\"\"\n  for macro in _CHECK_MACROS:\n    i = line.find(macro)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCheck",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckCheck(filename, clean_lines, linenum, error):\n  \"\"\"Checks the use of CHECK and EXPECT macros.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Decide the set of replacement macros that should be suggested\n  lines = clean_lines.elided",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckAltTokens",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckAltTokens(filename, clean_lines, linenum, error):\n  \"\"\"Check alternative keywords being used in boolean expressions.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Avoid preprocessor lines",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetLineWidth",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def GetLineWidth(line):\n  \"\"\"Determines the width of the line in column positions.\n  Args:\n    line: A string, which may be a Unicode string.\n  Returns:\n    The width of the line in column positions, accounting for Unicode\n    combining characters and wide characters.\n  \"\"\"\n  if isinstance(line, unicode):\n    width = 0",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckStyle",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n               error):\n  \"\"\"Checks rules from the 'C++ style rules' section of cppguide.html.\n  Most of these rules are hard to test (naming, comment style), but we\n  do what we can.  In particular we check for 2-space indents, line lengths,\n  tab usage, spaces inside code, etc.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckIncludeLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):\n  \"\"\"Check rules that are applicable to #include lines.\n  Strings on #include lines are NOT removed from elided line, to make\n  certain tasks easier. However, to prevent false positives, checks\n  applicable to #include lines in CheckLanguage must be put here.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    include_state: An _IncludeState instance in which the headers are inserted.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckLanguage",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using\n  uint32 inappropriately), but we do the best we can.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    file_extension: The extension (without the dot) of the filename.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckGlobalStatic",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckGlobalStatic(filename, clean_lines, linenum, error):\n  \"\"\"Check for unsafe global or static objects.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Match two lines at a time to support multiline declarations",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckPrintf",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckPrintf(filename, clean_lines, linenum, error):\n  \"\"\"Check for printf related issues.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # When snprintf is used, the second argument shouldn't be a literal.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsDerivedFunction",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsDerivedFunction(clean_lines, linenum):\n  \"\"\"Check if current line contains an inherited function.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line contains a function with \"override\"\n    virt-specifier.\n  \"\"\"\n  # Scan back a few lines for start of current function",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsOutOfLineMethodDefinition",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsOutOfLineMethodDefinition(clean_lines, linenum):\n  \"\"\"Check if current line contains an out-of-line method definition.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line contains an out-of-line method definition.\n  \"\"\"\n  # Scan back a few lines for start of current function\n  for i in xrange(linenum, max(-1, linenum - 10), -1):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsInitializerList",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsInitializerList(clean_lines, linenum):\n  \"\"\"Check if current line is inside constructor initializer list.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line appears to be inside constructor initializer\n    list, False otherwise.\n  \"\"\"\n  for i in xrange(linenum, 1, -1):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNonConstReference",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForNonConstReference(filename, clean_lines, linenum,\n                              nesting_state, error):\n  \"\"\"Check for non-const references.\n  Separate from CheckLanguage since it scans backwards from current\n  line, instead of scanning forward.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    nesting_state: A NestingState instance which maintains information about",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCasts",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckCasts(filename, clean_lines, linenum, error):\n  \"\"\"Various cast related checks.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Check to see if they're using an conversion function cast.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCStyleCast",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckCStyleCast(filename, clean_lines, linenum, cast_type, pattern, error):\n  \"\"\"Checks for a C-style cast by looking for the pattern.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    cast_type: The string for the C++ cast to recommend.  This is either\n      reinterpret_cast, static_cast, or const_cast, depending.\n    pattern: The regular expression used to find C-style casts.\n    error: The function to call with any errors found.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ExpectingFunctionArgs",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ExpectingFunctionArgs(clean_lines, linenum):\n  \"\"\"Checks whether where function type arguments are expected.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if the line at 'linenum' is inside something that expects arguments\n    of function types.\n  \"\"\"\n  line = clean_lines.elided[linenum]",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FilesBelongToSameModule",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FilesBelongToSameModule(filename_cc, filename_h):\n  \"\"\"Check if these two filenames belong to the same module.\n  The concept of a 'module' here is a as follows:\n  foo.h, foo-inl.h, foo.cc, foo_test.cc and foo_unittest.cc belong to the\n  same 'module' if they are in the same directory.\n  some/path/public/xyzzy and some/path/internal/xyzzy are also considered\n  to belong to the same module here.\n  If the filename_cc contains a longer path than the filename_h, for example,\n  '/absolute/path/to/base/sysinfo.cc', and this file would include\n  'base/sysinfo.h', this function also produces the prefix needed to open the",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "UpdateIncludeState",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def UpdateIncludeState(filename, include_dict, io=codecs):\n  \"\"\"Fill up the include_dict with new includes found from the file.\n  Args:\n    filename: the name of the header to read.\n    include_dict: a dictionary in which the headers are inserted.\n    io: The io factory to use to read the file. Provided for testability.\n  Returns:\n    True if a header was successfully added. False otherwise.\n  \"\"\"\n  headerfile = None",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForIncludeWhatYouUse",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n                              io=codecs):\n  \"\"\"Reports for missing stl includes.\n  This function will output warnings to make sure you are including the headers\n  necessary for the stl containers and functions that you use. We only give one\n  reason to include a header. For example, if you use both equal_to<> and\n  less<> in a .h file, only one (the latter in the file) of these will be\n  reported as a reason to include the <functional>.\n  Args:\n    filename: The name of the current file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckMakePairUsesDeduction",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):\n  \"\"\"Check that make_pair's template arguments are deduced.\n  G++ 4.6 in C++11 mode fails badly if make_pair's template arguments are\n  specified explicitly, and such use isn't intended in any case.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckRedundantVirtual",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckRedundantVirtual(filename, clean_lines, linenum, error):\n  \"\"\"Check if line contains a redundant \"virtual\" function-specifier.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Look for \"virtual\" on current line.\n  line = clean_lines.elided[linenum]",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckRedundantOverrideOrFinal",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckRedundantOverrideOrFinal(filename, clean_lines, linenum, error):\n  \"\"\"Check if line contains a redundant \"override\" or \"final\" virt-specifier.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Look for closing parenthesis nearby.  We need one to confirm where\n  # the declarator ends and where the virt-specifier starts to avoid",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsBlockInNameSpace",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def IsBlockInNameSpace(nesting_state, is_forward_declaration):\n  \"\"\"Checks that the new block is directly in a namespace.\n  Args:\n    nesting_state: The _NestingState object that contains info about our state.\n    is_forward_declaration: If the class is a forward declared class.\n  Returns:\n    Whether or not the new block is directly in a namespace.\n  \"\"\"\n  if is_forward_declaration:\n    if len(nesting_state.stack) >= 1 and (",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ShouldCheckNamespaceIndentation",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ShouldCheckNamespaceIndentation(nesting_state, is_namespace_indent_item,\n                                    raw_lines_no_comments, linenum):\n  \"\"\"This method determines if we should apply our namespace indentation check.\n  Args:\n    nesting_state: The current nesting state.\n    is_namespace_indent_item: If we just put a new class on the stack, True.\n      If the top of the stack is not a class, or we did not recently\n      add the class, False.\n    raw_lines_no_comments: The lines without the comments.\n    linenum: The current line number we are processing.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckItemIndentationInNamespace",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def CheckItemIndentationInNamespace(filename, raw_lines_no_comments, linenum,\n                                    error):\n  line = raw_lines_no_comments[linenum]\n  if Match(r'^\\s+', line):\n    error(filename, linenum, 'runtime/indentation_namespace', 4,\n          'Do not indent within a namespace')\ndef ProcessLine(filename, file_extension, clean_lines, line,\n                include_state, function_state, nesting_state, error,\n                extra_check_functions=[]):\n  \"\"\"Processes a single line in the file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessLine",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessLine(filename, file_extension, clean_lines, line,\n                include_state, function_state, nesting_state, error,\n                extra_check_functions=[]):\n  \"\"\"Processes a single line in the file.\n  Args:\n    filename: Filename of the file that is being processed.\n    file_extension: The extension (dot not included) of the file.\n    clean_lines: An array of strings, each representing a line of the file,\n                 with comments stripped.\n    line: Number of line being processed.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FlagCxx11Features",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FlagCxx11Features(filename, clean_lines, linenum, error):\n  \"\"\"Flag those c++11 features that we only allow in certain places.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  include = Match(r'\\s*#\\s*include\\s+[<\"]([^<\"]+)[\">]', line)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FlagCxx14Features",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def FlagCxx14Features(filename, clean_lines, linenum, error):\n  \"\"\"Flag those C++14 features that we restrict.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  include = Match(r'\\s*#\\s*include\\s+[<\"]([^<\"]+)[\">]', line)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessFileData",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessFileData(filename, file_extension, lines, error,\n                    extra_check_functions=[]):\n  \"\"\"Performs lint checks and reports any errors to the given error function.\n  Args:\n    filename: Filename of the file that is being processed.\n    file_extension: The extension (dot not included) of the file.\n    lines: An array of strings, each representing a line of the file, with the\n           last element being empty if the file is terminated with a newline.\n    error: A callable to which errors are reported, which takes 4 arguments:\n           filename, line number, error level, and message",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessConfigOverrides",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessConfigOverrides(filename):\n  \"\"\" Loads the configuration files and processes the config overrides.\n  Args:\n    filename: The name of the file being processed by the linter.\n  Returns:\n    False if the current |filename| should not be processed further.\n  \"\"\"\n  abs_filename = os.path.abspath(filename)\n  cfg_filters = []\n  keep_looking = True",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessFile",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ProcessFile(filename, vlevel, extra_check_functions=[]):\n  \"\"\"Does google-lint on a single file.\n  Args:\n    filename: The name of the file to parse.\n    vlevel: The level of errors to report.  Every error of confidence\n    >= verbose_level will be reported.  0 is a good default.\n    extra_check_functions: An array of additional check functions that will be\n                           run on each source line. Each function takes 4\n                           arguments: filename, clean_lines, line, error\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PrintUsage",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def PrintUsage(message):\n  \"\"\"Prints a brief usage string and exits, optionally with an error message.\n  Args:\n    message: The optional error message.\n  \"\"\"\n  sys.stderr.write(_USAGE)\n  if message:\n    sys.exit('\\nFATAL ERROR: ' + message)\n  else:\n    sys.exit(1)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PrintCategories",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def PrintCategories():\n  \"\"\"Prints a list of all the error-categories used by error messages.\n  These are the categories used to filter messages via --filter.\n  \"\"\"\n  sys.stderr.write(''.join('  %s\\n' % cat for cat in _ERROR_CATEGORIES))\n  sys.exit(0)\ndef ParseArguments(args):\n  \"\"\"Parses the command line arguments.\n  This may set the output format and verbosity level as side-effects.\n  Args:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ParseArguments",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def ParseArguments(args):\n  \"\"\"Parses the command line arguments.\n  This may set the output format and verbosity level as side-effects.\n  Args:\n    args: The command line arguments:\n  Returns:\n    The list of filenames to lint.\n  \"\"\"\n  try:\n    (opts, filenames) = getopt.getopt(args, '', ['help', 'output=', 'verbose=',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "def main():\n  filenames = ParseArguments(sys.argv[1:])\n  # Change stderr to write with replacement characters so we don't die\n  # if we try to print something containing non-ASCII characters.\n  sys.stderr = codecs.StreamReaderWriter(sys.stderr,\n                                         codecs.getreader('utf8'),\n                                         codecs.getwriter('utf8'),\n                                         'replace')\n  _cpplint_state.ResetErrorCounts()\n  for filename in filenames:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_USAGE",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_USAGE = \"\"\"\nSyntax: cpplint.py [--verbose=#] [--output=vs7] [--filter=-x,+y,...]\n                   [--counting=total|toplevel|detailed] [--root=subdir]\n                   [--linelength=digits] [--headers=x,y,...]\n                   [--quiet]\n        <file> [file] ...\n  The style guidelines this tries to follow are those in\n    https://google-styleguide.googlecode.com/svn/trunk/cppguide.xml\n  Every problem is given a confidence score from 1-5, with 5 meaning we are\n  certain of the problem, and 1 meaning it could be a legitimate construct.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ERROR_CATEGORIES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_ERROR_CATEGORIES = [\n    'build/class',\n    'build/c++11',\n    'build/c++14',\n    'build/c++tr1',\n    'build/deprecated',\n    'build/endif_comment',\n    'build/explicit_make_pair',\n    'build/forward_decl',\n    'build/header_guard',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_LEGACY_ERROR_CATEGORIES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_LEGACY_ERROR_CATEGORIES = [\n    'readability/streams',\n    'readability/function',\n    ]\n# The default state of the category filter. This is overridden by the --filter=\n# flag. By default all errors are on, so only add here categories that should be\n# off by default (i.e., categories that must be enabled by the --filter= flags).\n# All entries here should start with a '-' or '+', as in the --filter= flag.\n_DEFAULT_FILTERS = ['-build/include_alpha']\n# The default list of categories suppressed for C (not C++) files.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_FILTERS",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_DEFAULT_FILTERS = ['-build/include_alpha']\n# The default list of categories suppressed for C (not C++) files.\n_DEFAULT_C_SUPPRESSED_CATEGORIES = [\n    'readability/casting',\n    ]\n# The default list of categories suppressed for Linux Kernel files.\n_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_C_SUPPRESSED_CATEGORIES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_DEFAULT_C_SUPPRESSED_CATEGORIES = [\n    'readability/casting',\n    ]\n# The default list of categories suppressed for Linux Kernel files.\n_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we\n# decided those were OK, as long as they were in UTF-8 and didn't represent\n# hard-coded international strings, which belong in a separate i18n file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we\n# decided those were OK, as long as they were in UTF-8 and didn't represent\n# hard-coded international strings, which belong in a separate i18n file.\n# C++ headers\n_CPP_HEADERS = frozenset([\n    # Legacy\n    'algobase.h',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CPP_HEADERS",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_CPP_HEADERS = frozenset([\n    # Legacy\n    'algobase.h',\n    'algo.h',\n    'alloc.h',\n    'builtinbuf.h',\n    'bvector.h',\n    'complex.h',\n    'defalloc.h',\n    'deque.h',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_TYPES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_TYPES = re.compile(\n    r'^(?:'\n    # [dcl.type.simple]\n    r'(char(16_t|32_t)?)|wchar_t|'\n    r'bool|short|int|long|signed|unsigned|float|double|'\n    # [support.types]\n    r'(ptrdiff_t|size_t|max_align_t|nullptr_t)|'\n    # [cstdint.syn]\n    r'(u?int(_fast|_least)?(8|16|32|64)_t)|'\n    r'(u?int(max|ptr)_t)|'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_THIRD_PARTY_HEADERS_PATTERN",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_THIRD_PARTY_HEADERS_PATTERN = re.compile(\n    r'^(?:[^/]*[A-Z][^/]*\\.h|lua\\.h|lauxlib\\.h|lualib\\.h)$')\n# Pattern for matching FileInfo.BaseName() against test file name\n_TEST_FILE_SUFFIX = r'(_test|_unittest|_regtest)$'\n# Pattern that matches only complete whitespace, possibly across multiple lines.\n_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_TEST_FILE_SUFFIX",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_TEST_FILE_SUFFIX = r'(_test|_unittest|_regtest)$'\n# Pattern that matches only complete whitespace, possibly across multiple lines.\n_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_EMPTY_CONDITIONAL_BODY_PATTERN",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]\n# Replacement macros for CHECK/DCHECK/EXPECT_TRUE/EXPECT_FALSE\n_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CHECK_MACROS",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]\n# Replacement macros for CHECK/DCHECK/EXPECT_TRUE/EXPECT_FALSE\n_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])\nfor op, replacement in [('==', 'EQ'), ('!=', 'NE'),\n                        ('>=', 'GE'), ('>', 'GT'),\n                        ('<=', 'LE'), ('<', 'LT')]:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CHECK_REPLACEMENT",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])\nfor op, replacement in [('==', 'EQ'), ('!=', 'NE'),\n                        ('>=', 'GE'), ('>', 'GT'),\n                        ('<=', 'LE'), ('<', 'LT')]:\n  _CHECK_REPLACEMENT['DCHECK'][op] = 'DCHECK_%s' % replacement\n  _CHECK_REPLACEMENT['CHECK'][op] = 'CHECK_%s' % replacement\n  _CHECK_REPLACEMENT['EXPECT_TRUE'][op] = 'EXPECT_%s' % replacement\n  _CHECK_REPLACEMENT['ASSERT_TRUE'][op] = 'ASSERT_%s' % replacement\nfor op, inv_replacement in [('==', 'NE'), ('!=', 'EQ'),\n                            ('>=', 'LT'), ('>', 'LE'),",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ALT_TOKEN_REPLACEMENT",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_ALT_TOKEN_REPLACEMENT = {\n    'and': '&&',\n    'bitor': '|',\n    'or': '||',\n    'xor': '^',\n    'compl': '~',\n    'bitand': '&',\n    'and_eq': '&=',\n    'or_eq': '|=',\n    'xor_eq': '^=',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ALT_TOKEN_REPLACEMENT_PATTERN",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_ALT_TOKEN_REPLACEMENT_PATTERN = re.compile(\n    r'[ =()](' + ('|'.join(_ALT_TOKEN_REPLACEMENT.keys())) + r')(?=[ (]|$)')\n# These constants define types of headers for use with\n# _IncludeState.CheckNextIncludeOrder().\n_C_SYS_HEADER = 1\n_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_C_SYS_HEADER",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_C_SYS_HEADER = 1\n_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CPP_SYS_HEADER",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_LIKELY_MY_HEADER",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_POSSIBLE_MY_HEADER",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_OTHER_HEADER",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_NO_ASM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_INSIDE_ASM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_END_ASM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_BLOCK_ASM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_MATCH_ASM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_SEARCH_C_FILE",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_SEARCH_KERNEL_FILE",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_regexp_compile_cache",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_error_suppressions",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_root",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_root_debug",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_line_length",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_valid_extensions",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_hpp_headers",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_global_error_suppressions",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)\n  except ValueError:\n    PrintUsage('Header extensions must be comma separated list.')\ndef IsHeaderExtension(file_extension):",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_cpplint_state",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_cpplint_state = _CppLintState()\ndef _OutputFormat():\n  \"\"\"Gets the module's output format.\"\"\"\n  return _cpplint_state.output_format\ndef _SetOutputFormat(output_format):\n  \"\"\"Sets the module's output format.\"\"\"\n  _cpplint_state.SetOutputFormat(output_format)\ndef _Quiet():\n  \"\"\"Return's the module's quiet setting.\"\"\"\n  return _cpplint_state.quiet",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CLEANSE_LINE_ESCAPES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CLEANSE_LINE_ESCAPES = re.compile(\n    r'\\\\([abfnrtv?\"\\\\\\']|\\d+|x[0-9a-fA-F]+)')\n# Match a single C style comment on the same line.\n_RE_PATTERN_C_COMMENTS = r'/\\*(?:[^*]|\\*(?!/))*\\*/'\n# Matches multi-line C style comments.\n# This RE is a little bit more complicated than one might expect, because we\n# have to take care of space removals tools so we can handle comments inside\n# statements better.\n# The current rule is: We only clear spaces from both sides when we're at the\n# end of the line. Otherwise, we try to remove spaces from the right side,",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_C_COMMENTS",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_C_COMMENTS = r'/\\*(?:[^*]|\\*(?!/))*\\*/'\n# Matches multi-line C style comments.\n# This RE is a little bit more complicated than one might expect, because we\n# have to take care of space removals tools so we can handle comments inside\n# statements better.\n# The current rule is: We only clear spaces from both sides when we're at the\n# end of the line. Otherwise, we try to remove spaces from the right side,\n# if this doesn't work we try on left side but only if there's a non-character\n# on the right.\n_RE_PATTERN_CLEANSE_LINE_C_COMMENTS = re.compile(",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CLEANSE_LINE_C_COMMENTS",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CLEANSE_LINE_C_COMMENTS = re.compile(\n    r'(\\s*' + _RE_PATTERN_C_COMMENTS + r'\\s*$|' +\n    _RE_PATTERN_C_COMMENTS + r'\\s+|' +\n    r'\\s+' + _RE_PATTERN_C_COMMENTS + r'(?=\\W)|' +\n    _RE_PATTERN_C_COMMENTS + r')')\ndef IsCppString(line):\n  \"\"\"Does line terminate so, that the next symbol is in string constant.\n  This function does not consider single-line nor multi-line comments.\n  Args:\n    line: is a partial line of code starting from the 0..n.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_UNSAFE_FUNC_PREFIX",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_UNSAFE_FUNC_PREFIX = r'(?:[-+*/=%^&|(<]\\s*|>\\s+)'\n_THREADING_LIST = (\n    ('asctime(', 'asctime_r(', _UNSAFE_FUNC_PREFIX + r'asctime\\([^)]+\\)'),\n    ('ctime(', 'ctime_r(', _UNSAFE_FUNC_PREFIX + r'ctime\\([^)]+\\)'),\n    ('getgrgid(', 'getgrgid_r(', _UNSAFE_FUNC_PREFIX + r'getgrgid\\([^)]+\\)'),\n    ('getgrnam(', 'getgrnam_r(', _UNSAFE_FUNC_PREFIX + r'getgrnam\\([^)]+\\)'),\n    ('getlogin(', 'getlogin_r(', _UNSAFE_FUNC_PREFIX + r'getlogin\\(\\)'),\n    ('getpwnam(', 'getpwnam_r(', _UNSAFE_FUNC_PREFIX + r'getpwnam\\([^)]+\\)'),\n    ('getpwuid(', 'getpwuid_r(', _UNSAFE_FUNC_PREFIX + r'getpwuid\\([^)]+\\)'),\n    ('gmtime(', 'gmtime_r(', _UNSAFE_FUNC_PREFIX + r'gmtime\\([^)]+\\)'),",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_THREADING_LIST",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_THREADING_LIST = (\n    ('asctime(', 'asctime_r(', _UNSAFE_FUNC_PREFIX + r'asctime\\([^)]+\\)'),\n    ('ctime(', 'ctime_r(', _UNSAFE_FUNC_PREFIX + r'ctime\\([^)]+\\)'),\n    ('getgrgid(', 'getgrgid_r(', _UNSAFE_FUNC_PREFIX + r'getgrgid\\([^)]+\\)'),\n    ('getgrnam(', 'getgrnam_r(', _UNSAFE_FUNC_PREFIX + r'getgrnam\\([^)]+\\)'),\n    ('getlogin(', 'getlogin_r(', _UNSAFE_FUNC_PREFIX + r'getlogin\\(\\)'),\n    ('getpwnam(', 'getpwnam_r(', _UNSAFE_FUNC_PREFIX + r'getpwnam\\([^)]+\\)'),\n    ('getpwuid(', 'getpwuid_r(', _UNSAFE_FUNC_PREFIX + r'getpwuid\\([^)]+\\)'),\n    ('gmtime(', 'gmtime_r(', _UNSAFE_FUNC_PREFIX + r'gmtime\\([^)]+\\)'),\n    ('localtime(', 'localtime_r(', _UNSAFE_FUNC_PREFIX + r'localtime\\([^)]+\\)'),",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_INVALID_INCREMENT",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_INVALID_INCREMENT = re.compile(\n    r'^\\s*\\*\\w+(\\+\\+|--);')\ndef CheckInvalidIncrement(filename, clean_lines, linenum, error):\n  \"\"\"Checks for invalid increment *count++.\n  For example following function:\n  void increment_counter(int* count) {\n    *count++;\n  }\n  is invalid, because it effectively does count++, moving pointer, and should\n  be replaced with ++*count, (*count)++ or *count += 1.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_TODO",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_TODO = re.compile(r'^//(\\s*)TODO(\\(.+?\\))?:?(\\s|$)?')\ndef CheckComment(line, filename, linenum, next_line_start, error):\n  \"\"\"Checks for common mistakes in comments.\n  Args:\n    line: The line in question.\n    filename: The name of the current file.\n    linenum: The number of the line to check.\n    next_line_start: The first non-whitespace column of the next line.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_INCLUDE",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_INCLUDE = re.compile(r'^\\s*#\\s*include\\s*([<\"])([^>\"]*)[>\"].*$')\n# Matches the first component of a filename delimited by -s and _s. That is:\n#  _RE_FIRST_COMPONENT.match('foo').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo.cc').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo-bar_baz.cc').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo_bar-baz.cc').group(0) == 'foo'\n_RE_FIRST_COMPONENT = re.compile(r'^[^-_.]+')\ndef _DropCommonSuffixes(filename):\n  \"\"\"Drops common suffixes like _test.cc or -inl.h from filename.\n  For example:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_FIRST_COMPONENT",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_FIRST_COMPONENT = re.compile(r'^[^-_.]+')\ndef _DropCommonSuffixes(filename):\n  \"\"\"Drops common suffixes like _test.cc or -inl.h from filename.\n  For example:\n    >>> _DropCommonSuffixes('foo/foo-inl.h')\n    'foo/foo'\n    >>> _DropCommonSuffixes('foo/bar/foo.cc')\n    'foo/bar/foo'\n    >>> _DropCommonSuffixes('foo/foo_internal.h')\n    'foo/foo'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_IDENT",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_IDENT = r'[_a-zA-Z]\\w*'  # =~ [[:alpha:]][[:alnum:]]*\n_RE_PATTERN_TYPE = (\n    r'(?:const\\s+)?(?:typename\\s+|class\\s+|struct\\s+|union\\s+|enum\\s+)?'\n    r'(?:\\w|'\n    r'\\s*<(?:<(?:<[^<>]*>|[^<>])*>|[^<>])*>|'\n    r'::)+')\n# A call-by-reference parameter ends with '& identifier'.\n_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_TYPE",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_TYPE = (\n    r'(?:const\\s+)?(?:typename\\s+|class\\s+|struct\\s+|union\\s+|enum\\s+)?'\n    r'(?:\\w|'\n    r'\\s*<(?:<(?:<[^<>]*>|[^<>])*>|[^<>])*>|'\n    r'::)+')\n# A call-by-reference parameter ends with '& identifier'.\n_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')\n# A call-by-const-reference parameter either ends with 'const& identifier'",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_REF_PARAM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')\n# A call-by-const-reference parameter either ends with 'const& identifier'\n# or looks like 'const type& identifier' when 'type' is atomic.\n_RE_PATTERN_CONST_REF_PARAM = (\n    r'(?:.*\\s*\\bconst\\s*&\\s*' + _RE_PATTERN_IDENT +\n    r'|const\\s+' + _RE_PATTERN_TYPE + r'\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\n# Stream types.\n_RE_PATTERN_REF_STREAM_PARAM = (",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CONST_REF_PARAM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CONST_REF_PARAM = (\n    r'(?:.*\\s*\\bconst\\s*&\\s*' + _RE_PATTERN_IDENT +\n    r'|const\\s+' + _RE_PATTERN_TYPE + r'\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\n# Stream types.\n_RE_PATTERN_REF_STREAM_PARAM = (\n    r'(?:.*stream\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\ndef CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_REF_STREAM_PARAM",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_REF_STREAM_PARAM = (\n    r'(?:.*stream\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\ndef CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using\n  uint32 inappropriately), but we do the best we can.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_HEADERS_CONTAINING_TEMPLATES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_HEADERS_CONTAINING_TEMPLATES = (\n    ('<deque>', ('deque',)),\n    ('<functional>', ('unary_function', 'binary_function',\n                      'plus', 'minus', 'multiplies', 'divides', 'modulus',\n                      'negate',\n                      'equal_to', 'not_equal_to', 'greater', 'less',\n                      'greater_equal', 'less_equal',\n                      'logical_and', 'logical_or', 'logical_not',\n                      'unary_negate', 'not1', 'binary_negate', 'not2',\n                      'bind1st', 'bind2nd',",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_HEADERS_MAYBE_TEMPLATES",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_HEADERS_MAYBE_TEMPLATES = (\n    ('<algorithm>', ('copy', 'max', 'min', 'min_element', 'sort',\n                     'transform',\n                    )),\n    ('<utility>', ('forward', 'make_pair', 'move', 'swap')),\n    )\n_RE_PATTERN_STRING = re.compile(r'\\bstring\\b')\n_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_STRING",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_STRING = re.compile(r'\\bstring\\b')\n_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:\n    # Match max<type>(..., ...), max(..., ...), but not foo->max, foo.max or\n    # type::max().\n    _re_pattern_headers_maybe_templates.append(\n        (re.compile(r'[^>.]\\b' + _template + r'(<.*?>)?\\([^\\)]'),\n            _template,\n            _header))",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_re_pattern_headers_maybe_templates",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:\n    # Match max<type>(..., ...), max(..., ...), but not foo->max, foo.max or\n    # type::max().\n    _re_pattern_headers_maybe_templates.append(\n        (re.compile(r'[^>.]\\b' + _template + r'(<.*?>)?\\([^\\)]'),\n            _template,\n            _header))\n# Other scripts may reach in and modify this pattern.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_re_pattern_templates",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_re_pattern_templates = []\nfor _header, _templates in _HEADERS_CONTAINING_TEMPLATES:\n  for _template in _templates:\n    _re_pattern_templates.append(\n        (re.compile(r'(\\<|\\b)' + _template + r'\\s*\\<'),\n         _template + '<>',\n         _header))\ndef FilesBelongToSameModule(filename_cc, filename_h):\n  \"\"\"Check if these two filenames belong to the same module.\n  The concept of a 'module' here is a as follows:",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_EXPLICIT_MAKEPAIR",
        "kind": 5,
        "importPath": "aom.tools.cpplint",
        "description": "aom.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_EXPLICIT_MAKEPAIR = re.compile(r'\\bmake_pair\\s*<')\ndef CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):\n  \"\"\"Check that make_pair's template arguments are deduced.\n  G++ 4.6 in C++11 mode fails badly if make_pair's template arguments are\n  specified explicitly, and such use isn't intended in any case.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.",
        "detail": "aom.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "DiffLines",
        "kind": 6,
        "importPath": "aom.tools.diff",
        "description": "aom.tools.diff",
        "peekOfCode": "class DiffLines(object):\n    \"\"\"A container for one half of a diff.\"\"\"\n    def __init__(self, filename, offset, length):\n        self.filename = filename\n        self.offset = offset\n        self.length = length\n        self.lines = []\n        self.delta_line_nums = []\n    def Append(self, line):\n        l = len(self.lines)",
        "detail": "aom.tools.diff",
        "documentation": {}
    },
    {
        "label": "DiffHunk",
        "kind": 6,
        "importPath": "aom.tools.diff",
        "description": "aom.tools.diff",
        "peekOfCode": "class DiffHunk(object):\n    \"\"\"A container for one diff hunk, consisting of two DiffLines.\"\"\"\n    def __init__(self, header, file_a, file_b, start_a, len_a, start_b, len_b):\n        self.header = header\n        self.left = DiffLines(file_a, start_a, len_a)\n        self.right = DiffLines(file_b, start_b, len_b)\n        self.lines = []\n    def Append(self, line):\n        \"\"\"Adds a line to the DiffHunk and its DiffLines children.\"\"\"\n        if line[0] == \"-\":",
        "detail": "aom.tools.diff",
        "documentation": {}
    },
    {
        "label": "ParseDiffHunks",
        "kind": 2,
        "importPath": "aom.tools.diff",
        "description": "aom.tools.diff",
        "peekOfCode": "def ParseDiffHunks(stream):\n    \"\"\"Walk a file-like object, yielding DiffHunks as they're parsed.\"\"\"\n    file_regex = re.compile(r\"(\\+\\+\\+|---) (\\S+)\")\n    range_regex = re.compile(r\"@@ -(\\d+)(,(\\d+))? \\+(\\d+)(,(\\d+))?\")\n    hunk = None\n    while True:\n        line = stream.readline()\n        if not line:\n            break\n        if hunk is None:",
        "detail": "aom.tools.diff",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.tools.diff",
        "description": "aom.tools.diff",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport re\nclass DiffLines(object):\n    \"\"\"A container for one half of a diff.\"\"\"\n    def __init__(self, filename, offset, length):\n        self.filename = filename\n        self.offset = offset\n        self.length = length\n        self.lines = []\n        self.delta_line_nums = []",
        "detail": "aom.tools.diff",
        "documentation": {}
    },
    {
        "label": "moving_average",
        "kind": 2,
        "importPath": "aom.tools.frame_size_variation_analyzer",
        "description": "aom.tools.frame_size_variation_analyzer",
        "peekOfCode": "def moving_average(x, w):\n  return np.convolve(x, np.ones(w), 'valid') / w\ndef frame_size_analysis(filename, target_br, fps):\n  tbr = target_br * 1000 / fps\n  with open(filename, 'r') as infile:\n    raw_data = list(csv.reader(infile, delimiter=','))\n  data = np.array(raw_data).astype(float)\n  fsize = data[:, 0].astype(float)  # frame size\n  qindex = data[:, 1].astype(float)  # qindex\n  # Frame bit rate mismatch",
        "detail": "aom.tools.frame_size_variation_analyzer",
        "documentation": {}
    },
    {
        "label": "frame_size_analysis",
        "kind": 2,
        "importPath": "aom.tools.frame_size_variation_analyzer",
        "description": "aom.tools.frame_size_variation_analyzer",
        "peekOfCode": "def frame_size_analysis(filename, target_br, fps):\n  tbr = target_br * 1000 / fps\n  with open(filename, 'r') as infile:\n    raw_data = list(csv.reader(infile, delimiter=','))\n  data = np.array(raw_data).astype(float)\n  fsize = data[:, 0].astype(float)  # frame size\n  qindex = data[:, 1].astype(float)  # qindex\n  # Frame bit rate mismatch\n  mismatch = np.absolute(fsize - np.full(fsize.size, tbr))\n  # Count how many frames are more than 2.5x of frame target bit rate.",
        "detail": "aom.tools.frame_size_variation_analyzer",
        "documentation": {}
    },
    {
        "label": "cdf_spareto",
        "kind": 2,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "def cdf_spareto(x, xm, beta):\n  p = 1 - (xm / (np.abs(x) + xm))**beta\n  p = 0.5 + 0.5 * np.sign(x) * p\n  return p\ndef get_spareto(p, beta):\n  cdf = cdf_spareto\n  def func(x):\n    return ((cdf(1.5, x, beta) - cdf(0.5, x, beta)) /\n            (1 - cdf(0.5, x, beta)) - p)**2\n  alpha = scipy.optimize.fminbound(func, 1e-12, 10000, xtol=1e-12)",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "get_spareto",
        "kind": 2,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "def get_spareto(p, beta):\n  cdf = cdf_spareto\n  def func(x):\n    return ((cdf(1.5, x, beta) - cdf(0.5, x, beta)) /\n            (1 - cdf(0.5, x, beta)) - p)**2\n  alpha = scipy.optimize.fminbound(func, 1e-12, 10000, xtol=1e-12)\n  parray = np.zeros(11)\n  parray[0] = 2 * (cdf(0.5, alpha, beta) - 0.5)\n  parray[1] = (2 * (cdf(1.5, alpha, beta) - cdf(0.5, alpha, beta)))\n  parray[2] = (2 * (cdf(2.5, alpha, beta) - cdf(1.5, alpha, beta)))",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "quantize_probs",
        "kind": 2,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "def quantize_probs(p, save_first_bin, bits):\n  \"\"\"Quantize probability precisely.\n  Quantize probabilities minimizing dH (Kullback-Leibler divergence)\n  approximated by: sum (p_i-q_i)^2/p_i.\n  References:\n  https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n  https://github.com/JarekDuda/AsymmetricNumeralSystemsToolkit\n  \"\"\"\n  num_sym = p.size\n  p = np.clip(p, 1e-16, 1)",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "get_quantized_spareto",
        "kind": 2,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "def get_quantized_spareto(p, beta, bits, first_token):\n  parray = get_spareto(p, beta)\n  parray = parray[1:] / (1 - parray[0])\n  # CONFIG_NEW_TOKENSET\n  if first_token > 1:\n    parray = parray[1:] / (1 - parray[0])\n  qarray = quantize_probs(parray, first_token == 1, bits)\n  return qarray.astype(np.int)\ndef main(bits=15, first_token=1):\n  beta = 8",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "def main(bits=15, first_token=1):\n  beta = 8\n  for q in range(1, 256):\n    parray = get_quantized_spareto(q / 256., beta, bits, first_token)\n    assert parray.sum() == 2**bits\n    print('{', ', '.join('%d' % i for i in parray), '},')\nif __name__ == '__main__':\n  if len(sys.argv) > 2:\n    main(int(sys.argv[1]), int(sys.argv[2]))\n  elif len(sys.argv) > 1:",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "cdf(x)",
        "kind": 5,
        "importPath": "aom.tools.gen_constrained_tokenset",
        "description": "aom.tools.gen_constrained_tokenset",
        "peekOfCode": "cdf(x) = 0.5 + 0.5 * sgn(x) * [1 - {alpha/(alpha + |x|)} ^ beta]\nFor a given beta and a given probability of the 1-node, the alpha\nis first solved, and then the {alpha, beta} pair is used to generate\nthe probabilities for the rest of the nodes.\n\"\"\"\nimport heapq\nimport sys\nimport numpy as np\nimport scipy.optimize\nimport scipy.stats",
        "detail": "aom.tools.gen_constrained_tokenset",
        "documentation": {}
    },
    {
        "label": "FormatDiffHunks",
        "kind": 2,
        "importPath": "aom.tools.intersect-diffs",
        "description": "aom.tools.intersect-diffs",
        "peekOfCode": "def FormatDiffHunks(hunks):\n    \"\"\"Re-serialize a list of DiffHunks.\"\"\"\n    r = []\n    last_header = None\n    for hunk in hunks:\n        this_header = hunk.header[0:2]\n        if last_header != this_header:\n            r.extend(hunk.header)\n            last_header = this_header\n        else:",
        "detail": "aom.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "ZipHunks",
        "kind": 2,
        "importPath": "aom.tools.intersect-diffs",
        "description": "aom.tools.intersect-diffs",
        "peekOfCode": "def ZipHunks(rhs_hunks, lhs_hunks):\n    \"\"\"Join two hunk lists on filename.\"\"\"\n    for rhs_hunk in rhs_hunks:\n        rhs_file = rhs_hunk.right.filename.split(\"/\")[1:]\n        for lhs_hunk in lhs_hunks:\n            lhs_file = lhs_hunk.left.filename.split(\"/\")[1:]\n            if lhs_file != rhs_file:\n                continue\n            yield (rhs_hunk, lhs_hunk)\ndef main():",
        "detail": "aom.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.intersect-diffs",
        "description": "aom.tools.intersect-diffs",
        "peekOfCode": "def main():\n    old_hunks = [x for x in diff.ParseDiffHunks(open(sys.argv[1], \"r\"))]\n    new_hunks = [x for x in diff.ParseDiffHunks(open(sys.argv[2], \"r\"))]\n    out_hunks = []\n    # Join the right hand side of the older diff with the left hand side of the\n    # newer diff.\n    for old_hunk, new_hunk in ZipHunks(old_hunks, new_hunks):\n        if new_hunk in out_hunks:\n            continue\n        old_lines = old_hunk.right",
        "detail": "aom.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.tools.intersect-diffs",
        "description": "aom.tools.intersect-diffs",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport sys\nimport diff\ndef FormatDiffHunks(hunks):\n    \"\"\"Re-serialize a list of DiffHunks.\"\"\"\n    r = []\n    last_header = None\n    for hunk in hunks:\n        this_header = hunk.header[0:2]\n        if last_header != this_header:",
        "detail": "aom.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "Usage",
        "kind": 6,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "class Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SubprocessException",
        "kind": 6,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "class SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args\n        self._expected_returncode = expected_returncode\n        super(Subprocess, self).__init__(args, **kwargs)",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "Subprocess",
        "kind": 6,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "class Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args\n        self._expected_returncode = expected_returncode\n        super(Subprocess, self).__init__(args, **kwargs)\n    def communicate(self, *args, **kwargs):\n        result = super(Subprocess, self).communicate(*args, **kwargs)\n        if self._expected_returncode is not None:\n            try:",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "def main(argv=None):\n    if argv is None:\n        argv = sys.argv\n    try:\n        try:\n            opts, args = getopt.getopt(argv[1:], SHORT_OPTIONS, LONG_OPTIONS)\n        except getopt.error as msg:\n            raise Usage(msg)\n        # process options\n        for o, _ in opts:",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SHORT_OPTIONS",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "SHORT_OPTIONS = \"h\"\nLONG_OPTIONS = [\"help\"]\nTOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "LONG_OPTIONS",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "LONG_OPTIONS = [\"help\"]\nTOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "TOPLEVEL_CMD",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "TOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "DIFF_CMD",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "DIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "DIFF_INDEX_CMD",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "DIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SHOW_CMD",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "SHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "CPPLINT_FILTERS",
        "kind": 5,
        "importPath": "aom.tools.lint-hunks",
        "description": "aom.tools.lint-hunks",
        "peekOfCode": "CPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):",
        "detail": "aom.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "wrap",
        "kind": 2,
        "importPath": "aom.tools.wrap-commit-msg",
        "description": "aom.tools.wrap-commit-msg",
        "peekOfCode": "def wrap(text):\n    if text:\n        return textwrap.fill(text, break_long_words=False) + '\\n'\n    return \"\"\ndef main(fileobj):\n    text = \"\"\n    output = \"\"\n    while True:\n        line = fileobj.readline()\n        if not line:",
        "detail": "aom.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "aom.tools.wrap-commit-msg",
        "description": "aom.tools.wrap-commit-msg",
        "peekOfCode": "def main(fileobj):\n    text = \"\"\n    output = \"\"\n    while True:\n        line = fileobj.readline()\n        if not line:\n            break\n        if line.lstrip() == line:\n            text += line\n        else:",
        "detail": "aom.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "aom.tools.wrap-commit-msg",
        "description": "aom.tools.wrap-commit-msg",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport textwrap\nimport sys\ndef wrap(text):\n    if text:\n        return textwrap.fill(text, break_long_words=False) + '\\n'\n    return \"\"\ndef main(fileobj):\n    text = \"\"\n    output = \"\"",
        "detail": "aom.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "line_width",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "line_width = 80\n# How many spaces to tab for indent\ntab_size = 2\n# If arglists are longer than this, break them always\nmax_subargs_per_line = 10\n# If true, separate flow control names from their parentheses with a space\nseparate_ctrl_name_with_space = False\n# If true, separate function names from parentheses with a space\nseparate_fn_name_with_space = False\n# If a statement is wrapped to more than one line, than dangle the closing",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "tab_size",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "tab_size = 2\n# If arglists are longer than this, break them always\nmax_subargs_per_line = 10\n# If true, separate flow control names from their parentheses with a space\nseparate_ctrl_name_with_space = False\n# If true, separate function names from parentheses with a space\nseparate_fn_name_with_space = False\n# If a statement is wrapped to more than one line, than dangle the closing\n# parenthesis on it's own line\ndangle_parens = False",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "max_subargs_per_line",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "max_subargs_per_line = 10\n# If true, separate flow control names from their parentheses with a space\nseparate_ctrl_name_with_space = False\n# If true, separate function names from parentheses with a space\nseparate_fn_name_with_space = False\n# If a statement is wrapped to more than one line, than dangle the closing\n# parenthesis on it's own line\ndangle_parens = False\n# What character to use for bulleted lists\nbullet_char = '*'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "separate_ctrl_name_with_space",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "separate_ctrl_name_with_space = False\n# If true, separate function names from parentheses with a space\nseparate_fn_name_with_space = False\n# If a statement is wrapped to more than one line, than dangle the closing\n# parenthesis on it's own line\ndangle_parens = False\n# What character to use for bulleted lists\nbullet_char = '*'\n# What character to use as punctuation after numerals in an enumerated list\nenum_char = '.'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "separate_fn_name_with_space",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "separate_fn_name_with_space = False\n# If a statement is wrapped to more than one line, than dangle the closing\n# parenthesis on it's own line\ndangle_parens = False\n# What character to use for bulleted lists\nbullet_char = '*'\n# What character to use as punctuation after numerals in an enumerated list\nenum_char = '.'\n# What style line endings to use in the output.\nline_ending = u'unix'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "dangle_parens",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "dangle_parens = False\n# What character to use for bulleted lists\nbullet_char = '*'\n# What character to use as punctuation after numerals in an enumerated list\nenum_char = '.'\n# What style line endings to use in the output.\nline_ending = u'unix'\n# Format command names consistently as 'lower' or 'upper' case\ncommand_case = u'lower'\n# Format keywords consistently as 'lower' or 'upper' case",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "bullet_char",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "bullet_char = '*'\n# What character to use as punctuation after numerals in an enumerated list\nenum_char = '.'\n# What style line endings to use in the output.\nline_ending = u'unix'\n# Format command names consistently as 'lower' or 'upper' case\ncommand_case = u'lower'\n# Format keywords consistently as 'lower' or 'upper' case\nkeyword_case = u'unchanged'\n# Specify structure for custom cmake functions",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "enum_char",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "enum_char = '.'\n# What style line endings to use in the output.\nline_ending = u'unix'\n# Format command names consistently as 'lower' or 'upper' case\ncommand_case = u'lower'\n# Format keywords consistently as 'lower' or 'upper' case\nkeyword_case = u'unchanged'\n# Specify structure for custom cmake functions\nadditional_commands = {\n  \"foo\": {",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "line_ending",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "line_ending = u'unix'\n# Format command names consistently as 'lower' or 'upper' case\ncommand_case = u'lower'\n# Format keywords consistently as 'lower' or 'upper' case\nkeyword_case = u'unchanged'\n# Specify structure for custom cmake functions\nadditional_commands = {\n  \"foo\": {\n    \"flags\": [\n      \"BAR\",",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "command_case",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "command_case = u'lower'\n# Format keywords consistently as 'lower' or 'upper' case\nkeyword_case = u'unchanged'\n# Specify structure for custom cmake functions\nadditional_commands = {\n  \"foo\": {\n    \"flags\": [\n      \"BAR\",\n      \"BAZ\"\n    ],",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "keyword_case",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "keyword_case = u'unchanged'\n# Specify structure for custom cmake functions\nadditional_commands = {\n  \"foo\": {\n    \"flags\": [\n      \"BAR\",\n      \"BAZ\"\n    ],\n    \"kwargs\": {\n      \"HEADERS\": \"*\",",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "additional_commands",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "additional_commands = {\n  \"foo\": {\n    \"flags\": [\n      \"BAR\",\n      \"BAZ\"\n    ],\n    \"kwargs\": {\n      \"HEADERS\": \"*\",\n      \"DEPENDS\": \"*\",\n      \"SOURCES\": \"*\"",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "always_wrap",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "always_wrap = []\n# Specify the order of wrapping algorithms during successive reflow attempts\nalgorithm_order = [0, 1, 2, 3, 4]\n# If true, the argument lists which are known to be sortable will be sorted\n# lexicographicall\nautosort = False\n# enable comment markup parsing and reflow\nenable_markup = True\n# If comment markup is enabled, don't reflow the first comment block in\n# eachlistfile. Use this to preserve formatting of your",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "algorithm_order",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "algorithm_order = [0, 1, 2, 3, 4]\n# If true, the argument lists which are known to be sortable will be sorted\n# lexicographicall\nautosort = False\n# enable comment markup parsing and reflow\nenable_markup = True\n# If comment markup is enabled, don't reflow the first comment block in\n# eachlistfile. Use this to preserve formatting of your\n# copyright/licensestatements.\nfirst_comment_is_literal = True",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "autosort",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "autosort = False\n# enable comment markup parsing and reflow\nenable_markup = True\n# If comment markup is enabled, don't reflow the first comment block in\n# eachlistfile. Use this to preserve formatting of your\n# copyright/licensestatements.\nfirst_comment_is_literal = True\n# If comment markup is enabled, don't reflow any comment block which matchesthis\n# (regex) pattern. Default is `None` (disabled).\nliteral_comment_pattern = None",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "enable_markup",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "enable_markup = True\n# If comment markup is enabled, don't reflow the first comment block in\n# eachlistfile. Use this to preserve formatting of your\n# copyright/licensestatements.\nfirst_comment_is_literal = True\n# If comment markup is enabled, don't reflow any comment block which matchesthis\n# (regex) pattern. Default is `None` (disabled).\nliteral_comment_pattern = None\n# Regular expression to match preformat fences in comments\n# default=r'^\\s*([`~]{3}[`~]*)(.*)$'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "first_comment_is_literal",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "first_comment_is_literal = True\n# If comment markup is enabled, don't reflow any comment block which matchesthis\n# (regex) pattern. Default is `None` (disabled).\nliteral_comment_pattern = None\n# Regular expression to match preformat fences in comments\n# default=r'^\\s*([`~]{3}[`~]*)(.*)$'\nfence_pattern = u'^\\\\s*([`~]{3}[`~]*)(.*)$'\n# Regular expression to match rulers in comments\n# default=r'^\\s*[^\\w\\s]{3}.*[^\\w\\s]{3}$'\nruler_pattern = u'^\\\\s*[^\\\\w\\\\s]{3}.*[^\\\\w\\\\s]{3}$'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "literal_comment_pattern",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "literal_comment_pattern = None\n# Regular expression to match preformat fences in comments\n# default=r'^\\s*([`~]{3}[`~]*)(.*)$'\nfence_pattern = u'^\\\\s*([`~]{3}[`~]*)(.*)$'\n# Regular expression to match rulers in comments\n# default=r'^\\s*[^\\w\\s]{3}.*[^\\w\\s]{3}$'\nruler_pattern = u'^\\\\s*[^\\\\w\\\\s]{3}.*[^\\\\w\\\\s]{3}$'\n# If true, emit the unicode byte-order mark (BOM) at the start of the file\nemit_byteorder_mark = False\n# If a comment line starts with at least this many consecutive hash characters,",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "fence_pattern",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "fence_pattern = u'^\\\\s*([`~]{3}[`~]*)(.*)$'\n# Regular expression to match rulers in comments\n# default=r'^\\s*[^\\w\\s]{3}.*[^\\w\\s]{3}$'\nruler_pattern = u'^\\\\s*[^\\\\w\\\\s]{3}.*[^\\\\w\\\\s]{3}$'\n# If true, emit the unicode byte-order mark (BOM) at the start of the file\nemit_byteorder_mark = False\n# If a comment line starts with at least this many consecutive hash characters,\n# then don't lstrip() them off. This allows for lazy hash rulers where the first\n# hash char is not separated by space\nhashruler_min_length = 10",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "ruler_pattern",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "ruler_pattern = u'^\\\\s*[^\\\\w\\\\s]{3}.*[^\\\\w\\\\s]{3}$'\n# If true, emit the unicode byte-order mark (BOM) at the start of the file\nemit_byteorder_mark = False\n# If a comment line starts with at least this many consecutive hash characters,\n# then don't lstrip() them off. This allows for lazy hash rulers where the first\n# hash char is not separated by space\nhashruler_min_length = 10\n# If true, then insert a space between the first hash char and remaining hash\n# chars in a hash ruler, and normalize it's length to fill the column\ncanonicalize_hashrulers = True",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "emit_byteorder_mark",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "emit_byteorder_mark = False\n# If a comment line starts with at least this many consecutive hash characters,\n# then don't lstrip() them off. This allows for lazy hash rulers where the first\n# hash char is not separated by space\nhashruler_min_length = 10\n# If true, then insert a space between the first hash char and remaining hash\n# chars in a hash ruler, and normalize it's length to fill the column\ncanonicalize_hashrulers = True\n# Specify the encoding of the input file. Defaults to utf-8.\ninput_encoding = u'utf-8'",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "hashruler_min_length",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "hashruler_min_length = 10\n# If true, then insert a space between the first hash char and remaining hash\n# chars in a hash ruler, and normalize it's length to fill the column\ncanonicalize_hashrulers = True\n# Specify the encoding of the input file. Defaults to utf-8.\ninput_encoding = u'utf-8'\n# Specify the encoding of the output file. Defaults to utf-8. Note that cmake\n# only claims to support utf-8 so be careful when using anything else\noutput_encoding = u'utf-8'\n# A dictionary containing any per-command configuration overrides. Currently",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "canonicalize_hashrulers",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "canonicalize_hashrulers = True\n# Specify the encoding of the input file. Defaults to utf-8.\ninput_encoding = u'utf-8'\n# Specify the encoding of the output file. Defaults to utf-8. Note that cmake\n# only claims to support utf-8 so be careful when using anything else\noutput_encoding = u'utf-8'\n# A dictionary containing any per-command configuration overrides. Currently\n# only `command_case` is supported.\nper_command = {}",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "input_encoding",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "input_encoding = u'utf-8'\n# Specify the encoding of the output file. Defaults to utf-8. Note that cmake\n# only claims to support utf-8 so be careful when using anything else\noutput_encoding = u'utf-8'\n# A dictionary containing any per-command configuration overrides. Currently\n# only `command_case` is supported.\nper_command = {}",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "output_encoding",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "output_encoding = u'utf-8'\n# A dictionary containing any per-command configuration overrides. Currently\n# only `command_case` is supported.\nper_command = {}",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "per_command",
        "kind": 5,
        "importPath": "aom..cmake-format",
        "description": "aom..cmake-format",
        "peekOfCode": "per_command = {}",
        "detail": "aom..cmake-format",
        "documentation": {}
    },
    {
        "label": "visible_device_list",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "visible_device_list = '0' # use , separator for more GPUs like '0, 1'\nper_process_gpu_memory_fraction = 0.9 # avoid out of memory\nintra_op_parallelism_threads = 2  # default in tensorflow\ninter_op_parallelism_threads = 5  # default in tensorflow\ngpu_options = tf.compat.v1.GPUOptions(\n              per_process_gpu_memory_fraction = per_process_gpu_memory_fraction,\n              visible_device_list = visible_device_list,\n              allow_growth = True)\nconfig = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "per_process_gpu_memory_fraction",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "per_process_gpu_memory_fraction = 0.9 # avoid out of memory\nintra_op_parallelism_threads = 2  # default in tensorflow\ninter_op_parallelism_threads = 5  # default in tensorflow\ngpu_options = tf.compat.v1.GPUOptions(\n              per_process_gpu_memory_fraction = per_process_gpu_memory_fraction,\n              visible_device_list = visible_device_list,\n              allow_growth = True)\nconfig = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,\n         log_device_placement = False,",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "intra_op_parallelism_threads",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "intra_op_parallelism_threads = 2  # default in tensorflow\ninter_op_parallelism_threads = 5  # default in tensorflow\ngpu_options = tf.compat.v1.GPUOptions(\n              per_process_gpu_memory_fraction = per_process_gpu_memory_fraction,\n              visible_device_list = visible_device_list,\n              allow_growth = True)\nconfig = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,\n         log_device_placement = False,\n         intra_op_parallelism_threads = intra_op_parallelism_threads,",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "inter_op_parallelism_threads",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "inter_op_parallelism_threads = 5  # default in tensorflow\ngpu_options = tf.compat.v1.GPUOptions(\n              per_process_gpu_memory_fraction = per_process_gpu_memory_fraction,\n              visible_device_list = visible_device_list,\n              allow_growth = True)\nconfig = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,\n         log_device_placement = False,\n         intra_op_parallelism_threads = intra_op_parallelism_threads,\n         inter_op_parallelism_threads = inter_op_parallelism_threads,",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "gpu_options",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "gpu_options = tf.compat.v1.GPUOptions(\n              per_process_gpu_memory_fraction = per_process_gpu_memory_fraction,\n              visible_device_list = visible_device_list,\n              allow_growth = True)\nconfig = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,\n         log_device_placement = False,\n         intra_op_parallelism_threads = intra_op_parallelism_threads,\n         inter_op_parallelism_threads = inter_op_parallelism_threads,\n         gpu_options = gpu_options)",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "config = tf.compat.v1.ConfigProto(\n         allow_soft_placement = True,\n         log_device_placement = False,\n         intra_op_parallelism_threads = intra_op_parallelism_threads,\n         inter_op_parallelism_threads = inter_op_parallelism_threads,\n         gpu_options = gpu_options)\ns = config.SerializeToString()\n# print(list(map(hex, s)))  # print by json if need\nprint('a serialized protobuf string for TF_SetConfig, note the byte order is in normal order.')\nb = ''.join(format(b,'02x') for b in s)",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "s",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "s = config.SerializeToString()\n# print(list(map(hex, s)))  # print by json if need\nprint('a serialized protobuf string for TF_SetConfig, note the byte order is in normal order.')\nb = ''.join(format(b,'02x') for b in s)\nprint('0x%s' % b) # print by hex format",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "ffmpeg.tools.python.tf_sess_config",
        "description": "ffmpeg.tools.python.tf_sess_config",
        "peekOfCode": "b = ''.join(format(b,'02x') for b in s)\nprint('0x%s' % b) # print by hex format",
        "detail": "ffmpeg.tools.python.tf_sess_config",
        "documentation": {}
    },
    {
        "label": "Formatter",
        "kind": 6,
        "importPath": "ffmpeg.tools.normalize",
        "description": "ffmpeg.tools.normalize",
        "peekOfCode": "class Formatter(\n    argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter\n):\n    pass\ndef normalize():\n    parser = argparse.ArgumentParser(description=HELP, formatter_class=Formatter)\n    parser.add_argument('--input', '-i', required=True, help='specify input file')\n    parser.add_argument('--output', '-o', required=True, help='specify output file')\n    parser.add_argument('--dry-run', '-n', help='simulate commands', action='store_true')\n    parser.add_argument('encode_arguments', nargs='*', help='specify encode options used for the actual encoding')",
        "detail": "ffmpeg.tools.normalize",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "ffmpeg.tools.normalize",
        "description": "ffmpeg.tools.normalize",
        "peekOfCode": "def normalize():\n    parser = argparse.ArgumentParser(description=HELP, formatter_class=Formatter)\n    parser.add_argument('--input', '-i', required=True, help='specify input file')\n    parser.add_argument('--output', '-o', required=True, help='specify output file')\n    parser.add_argument('--dry-run', '-n', help='simulate commands', action='store_true')\n    parser.add_argument('encode_arguments', nargs='*', help='specify encode options used for the actual encoding')\n    args = parser.parse_args()\n    analysis_cmd = [\n        'ffprobe', '-v', 'error', '-of', 'compact=p=0:nk=1',\n        '-show_entries', 'frame_tags=lavfi.r128.I', '-f', 'lavfi',",
        "detail": "ffmpeg.tools.normalize",
        "documentation": {}
    },
    {
        "label": "HELP",
        "kind": 5,
        "importPath": "ffmpeg.tools.normalize",
        "description": "ffmpeg.tools.normalize",
        "peekOfCode": "HELP = '''\nNormalize audio input.\nThe command uses ffprobe to analyze an input file with the ebur128\nfilter, and finally run ffmpeg to normalize the input depending on the\ncomputed adjustment.\nffmpeg encoding arguments can be passed through the extra arguments\nafter options, for example as in:\nnormalize.py --input input.mp3 --output output.mp3 -- -loglevel debug -y\n'''\nlogging.basicConfig(format='normalize|%(levelname)s> %(message)s', level=logging.INFO)",
        "detail": "ffmpeg.tools.normalize",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "ffmpeg.tools.normalize",
        "description": "ffmpeg.tools.normalize",
        "peekOfCode": "log = logging.getLogger()\nclass Formatter(\n    argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter\n):\n    pass\ndef normalize():\n    parser = argparse.ArgumentParser(description=HELP, formatter_class=Formatter)\n    parser.add_argument('--input', '-i', required=True, help='specify input file')\n    parser.add_argument('--output', '-o', required=True, help='specify output file')\n    parser.add_argument('--dry-run', '-n', help='simulate commands', action='store_true')",
        "detail": "ffmpeg.tools.normalize",
        "documentation": {}
    },
    {
        "label": "LavfiCmd",
        "kind": 6,
        "importPath": "ffmpeg.tools.zmqshell",
        "description": "ffmpeg.tools.zmqshell",
        "peekOfCode": "class LavfiCmd(cmd.Cmd):\n    prompt = 'lavfi> '\n    def __init__(self, bind_address):\n        context = zmq.Context()\n        self.requester = context.socket(zmq.REQ)\n        self.requester.connect(bind_address)\n        cmd.Cmd.__init__(self)\n    def onecmd(self, cmd):\n        if cmd == 'EOF':\n            sys.exit(0)",
        "detail": "ffmpeg.tools.zmqshell",
        "documentation": {}
    },
    {
        "label": "Formatter",
        "kind": 6,
        "importPath": "ffmpeg.tools.zmqshell",
        "description": "ffmpeg.tools.zmqshell",
        "peekOfCode": "class Formatter(\n    argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter\n):\n    pass\ndef main():\n    parser = argparse.ArgumentParser(description=HELP, formatter_class=Formatter)\n    parser.add_argument('--bind-address', '-b', default='tcp://localhost:5555', help='specify bind address used to communicate with ZMQ')\n    args = parser.parse_args()\n    try:\n        LavfiCmd(args.bind_address).cmdloop('FFmpeg libavfilter interactive shell')",
        "detail": "ffmpeg.tools.zmqshell",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ffmpeg.tools.zmqshell",
        "description": "ffmpeg.tools.zmqshell",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=HELP, formatter_class=Formatter)\n    parser.add_argument('--bind-address', '-b', default='tcp://localhost:5555', help='specify bind address used to communicate with ZMQ')\n    args = parser.parse_args()\n    try:\n        LavfiCmd(args.bind_address).cmdloop('FFmpeg libavfilter interactive shell')\n    except KeyboardInterrupt:\n        pass\nif __name__ == '__main__':\n    main()",
        "detail": "ffmpeg.tools.zmqshell",
        "documentation": {}
    },
    {
        "label": "HELP",
        "kind": 5,
        "importPath": "ffmpeg.tools.zmqshell",
        "description": "ffmpeg.tools.zmqshell",
        "peekOfCode": "HELP = '''\nProvide a shell used to send interactive commands to a zmq filter.\nThe command assumes there is a running zmq or azmq filter acting as a\nZMQ server.\nYou can send a command to it, follwing the syntax:\nTARGET COMMAND [COMMAND_ARGS]\n* TARGET is the target filter identifier to send the command to\n* COMMAND is the name of the command sent to the filter\n* COMMAND_ARGS is the optional specification of command arguments\nSee the zmq/azmq filters documentation for more details, and the",
        "detail": "ffmpeg.tools.zmqshell",
        "documentation": {}
    },
    {
        "label": "log",
        "kind": 5,
        "importPath": "ffmpeg.tools.zmqshell",
        "description": "ffmpeg.tools.zmqshell",
        "peekOfCode": "log = logging.getLogger()\nclass LavfiCmd(cmd.Cmd):\n    prompt = 'lavfi> '\n    def __init__(self, bind_address):\n        context = zmq.Context()\n        self.requester = context.socket(zmq.REQ)\n        self.requester.connect(bind_address)\n        cmd.Cmd.__init__(self)\n    def onecmd(self, cmd):\n        if cmd == 'EOF':",
        "detail": "ffmpeg.tools.zmqshell",
        "documentation": {}
    },
    {
        "label": "get_file_sha",
        "kind": 2,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "def get_file_sha(filename):\n  try:\n    sha_hash = hashlib.sha1()\n    with open(filename, 'rb') as file:\n      buf = file.read(HASH_CHUNK)\n      while len(buf) > 0:\n        sha_hash.update(buf)\n        buf = file.read(HASH_CHUNK)\n      return sha_hash.hexdigest()\n  except IOError:",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "download_and_check_sha",
        "kind": 2,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "def download_and_check_sha(url, filename, sha):\n  path = os.path.join(local_resource_path, filename)\n  fp = open(path, \"wb\")\n  curl = pycurl.Curl()\n  curl.setopt(pycurl.URL, url + \"/\" + filename)\n  curl.setopt(pycurl.WRITEDATA, fp)\n  curl.perform()\n  curl.close()\n  fp.close()\n  return get_file_sha(path) == sha",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "url = ''\nfile_list_path = ''\nlocal_resource_path = ''\n# Helper functions:\n# A simple function which returns the sha hash of a file in hex\ndef get_file_sha(filename):\n  try:\n    sha_hash = hashlib.sha1()\n    with open(filename, 'rb') as file:\n      buf = file.read(HASH_CHUNK)",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "file_list_path",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "file_list_path = ''\nlocal_resource_path = ''\n# Helper functions:\n# A simple function which returns the sha hash of a file in hex\ndef get_file_sha(filename):\n  try:\n    sha_hash = hashlib.sha1()\n    with open(filename, 'rb') as file:\n      buf = file.read(HASH_CHUNK)\n      while len(buf) > 0:",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "local_resource_path",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "local_resource_path = ''\n# Helper functions:\n# A simple function which returns the sha hash of a file in hex\ndef get_file_sha(filename):\n  try:\n    sha_hash = hashlib.sha1()\n    with open(filename, 'rb') as file:\n      buf = file.read(HASH_CHUNK)\n      while len(buf) > 0:\n        sha_hash.update(buf)",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "ftp_retries",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "ftp_retries = 3\nSHA_COL = 0\nNAME_COL = 1\nEXPECTED_COL = 2\nHASH_CHUNK = 65536\n# Main script\ntry:\n  opts, args = \\\n      getopt.getopt(sys.argv[1:], \\\n                    \"u:i:o:\", [\"url=\", \"input_csv=\", \"output_dir=\"])",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "SHA_COL",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "SHA_COL = 0\nNAME_COL = 1\nEXPECTED_COL = 2\nHASH_CHUNK = 65536\n# Main script\ntry:\n  opts, args = \\\n      getopt.getopt(sys.argv[1:], \\\n                    \"u:i:o:\", [\"url=\", \"input_csv=\", \"output_dir=\"])\nexcept:",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "NAME_COL",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "NAME_COL = 1\nEXPECTED_COL = 2\nHASH_CHUNK = 65536\n# Main script\ntry:\n  opts, args = \\\n      getopt.getopt(sys.argv[1:], \\\n                    \"u:i:o:\", [\"url=\", \"input_csv=\", \"output_dir=\"])\nexcept:\n  print('get_files.py -u <url> -i <input_csv> -o <output_dir>')",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "EXPECTED_COL",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "EXPECTED_COL = 2\nHASH_CHUNK = 65536\n# Main script\ntry:\n  opts, args = \\\n      getopt.getopt(sys.argv[1:], \\\n                    \"u:i:o:\", [\"url=\", \"input_csv=\", \"output_dir=\"])\nexcept:\n  print('get_files.py -u <url> -i <input_csv> -o <output_dir>')\n  sys.exit(2)",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "HASH_CHUNK",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "HASH_CHUNK = 65536\n# Main script\ntry:\n  opts, args = \\\n      getopt.getopt(sys.argv[1:], \\\n                    \"u:i:o:\", [\"url=\", \"input_csv=\", \"output_dir=\"])\nexcept:\n  print('get_files.py -u <url> -i <input_csv> -o <output_dir>')\n  sys.exit(2)\nfor opt, arg in opts:",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "file_list_csv",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "file_list_csv = open(file_list_path, \"rb\")\n# Our 'csv' file uses multiple spaces as a delimiter, python's\n# csv class only uses single character delimiters, so we convert them below\nfile_list_reader = csv.reader((re.sub(' +', ' ', line.decode('utf-8')) \\\n    for line in file_list_csv), delimiter = ' ')\nfile_shas = []\nfile_names = []\nfor row in file_list_reader:\n  if len(row) != EXPECTED_COL:\n      continue",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "file_list_reader",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "file_list_reader = csv.reader((re.sub(' +', ' ', line.decode('utf-8')) \\\n    for line in file_list_csv), delimiter = ' ')\nfile_shas = []\nfile_names = []\nfor row in file_list_reader:\n  if len(row) != EXPECTED_COL:\n      continue\n  file_shas.append(row[SHA_COL])\n  file_names.append(row[NAME_COL])\nfile_list_csv.close()",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "file_shas",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "file_shas = []\nfile_names = []\nfor row in file_list_reader:\n  if len(row) != EXPECTED_COL:\n      continue\n  file_shas.append(row[SHA_COL])\n  file_names.append(row[NAME_COL])\nfile_list_csv.close()\n# Download files, only if they don't already exist and have correct shas\nfor filename, sha in zip(file_names, file_shas):",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "file_names",
        "kind": 5,
        "importPath": "libvpx.test.android.get_files",
        "description": "libvpx.test.android.get_files",
        "peekOfCode": "file_names = []\nfor row in file_list_reader:\n  if len(row) != EXPECTED_COL:\n      continue\n  file_shas.append(row[SHA_COL])\n  file_names.append(row[NAME_COL])\nfile_list_csv.close()\n# Download files, only if they don't already exist and have correct shas\nfor filename, sha in zip(file_names, file_shas):\n  filename = filename.lstrip('*')",
        "detail": "libvpx.test.android.get_files",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "libvpx.test.android.scrape_gtest_log",
        "description": "libvpx.test.android.scrape_gtest_log",
        "peekOfCode": "def main():\n  if len(sys.argv) != 3:\n    print \"Expects a file to write json to!\"\n    exit(1)\n  try:\n    opts, _ = \\\n        getopt.getopt(sys.argv[1:], \\\n                      'o:', ['output-json='])\n  except getopt.GetOptError:\n    print 'scrape_gtest_log.py -o <output_json>'",
        "detail": "libvpx.test.android.scrape_gtest_log",
        "documentation": {}
    },
    {
        "label": "Anandan",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Anandan",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Anandan",
        "peekOfCode": "class Anandan(MotionEST):\n  \"\"\"\n    constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        beta: smooth constrain weight\n        k1,k2,k3: confidence coefficients\n        max_iter: maximum number of iterations\n    \"\"\"",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Anandan",
        "documentation": {}
    },
    {
        "label": "Exhaust",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "peekOfCode": "class Exhaust(MotionEST):\n  \"\"\"\n    Constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        wnd_size: search window size\n        metric: metric to compare the blocks distrotion\n    \"\"\"\n  def __init__(self, cur_f, ref_f, blk_size, wnd_size, metric=MSE):",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "documentation": {}
    },
    {
        "label": "ExhaustNeighbor",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "peekOfCode": "class ExhaustNeighbor(MotionEST):\n  \"\"\"\n    Constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        wnd_size: search window size\n        beta: neigbor loss weight\n        metric: metric to compare the blocks distrotion\n    \"\"\"",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "documentation": {}
    },
    {
        "label": "ExhaustNeighborFeatureScore",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "peekOfCode": "class ExhaustNeighborFeatureScore(MotionEST):\n  \"\"\"\n    Constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        wnd_size: search window size\n        beta: neigbor loss weight\n        max_iter: maximum number of iterations\n        metric: metric to compare the blocks distrotion",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Exhaust",
        "documentation": {}
    },
    {
        "label": "GroundTruth",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.GroundTruth",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.GroundTruth",
        "peekOfCode": "class GroundTruth(MotionEST):\n  \"\"\"constructor:\n    cur_f:current\n    frame ref_f:reference\n    frame blk_sz:block size\n    gt_path:ground truth motion field file path\n    \"\"\"\n  def __init__(self, cur_f, ref_f, blk_sz, gt_path, mf=None, mask=None):\n    self.name = 'ground truth'\n    super(GroundTruth, self).__init__(cur_f, ref_f, blk_sz)",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.GroundTruth",
        "documentation": {}
    },
    {
        "label": "HornSchunck",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.HornSchunck",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.HornSchunck",
        "peekOfCode": "class HornSchunck(MotionEST):\n  \"\"\"\n    constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        alpha: smooth constrain weight\n        sigma: gaussian blur parameter\n    \"\"\"\n  def __init__(self, cur_f, ref_f, blk_sz, alpha, sigma, max_iter=100):",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.HornSchunck",
        "documentation": {}
    },
    {
        "label": "MotionEST",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.MotionEST",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.MotionEST",
        "peekOfCode": "class MotionEST(object):\n  \"\"\"\n    constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n    \"\"\"\n  def __init__(self, cur_f, ref_f, blk_sz):\n    self.cur_f = cur_f\n    self.ref_f = ref_f",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.MotionEST",
        "documentation": {}
    },
    {
        "label": "SearchSmoothAdapt",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "peekOfCode": "class SearchSmoothAdapt(MotionEST):\n  \"\"\"\n    Constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        wnd_size: search window size\n        beta: neigbor loss weight\n        max_iter: maximum number of iterations\n        metric: metric to compare the blocks distrotion",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "documentation": {}
    },
    {
        "label": "SearchSmoothFix",
        "kind": 6,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "peekOfCode": "class SearchSmoothFix(MotionEST):\n  \"\"\"\n    Constructor:\n        cur_f: current frame\n        ref_f: reference frame\n        blk_sz: block size\n        wnd_size: search window size\n        beta: neigbor loss weight\n        max_iter: maximum number of iterations\n        metric: metric to compare the blocks distrotion",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.SearchSmooth",
        "documentation": {}
    },
    {
        "label": "MSE",
        "kind": 2,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "peekOfCode": "def MSE(blk1, blk2):\n  return np.mean(\n      LA.norm(\n          np.array(blk1, dtype=int) - np.array(blk2, dtype=int), axis=2))\ndef drawMF(img, blk_sz, mf):\n  img_rgba = img.convert('RGBA')\n  mf_layer = Image.new(mode='RGBA', size=img_rgba.size, color=(0, 0, 0, 0))\n  draw = ImageDraw.Draw(mf_layer)\n  width = img_rgba.size[0]\n  height = img_rgba.size[1]",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "documentation": {}
    },
    {
        "label": "drawMF",
        "kind": 2,
        "importPath": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "description": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "peekOfCode": "def drawMF(img, blk_sz, mf):\n  img_rgba = img.convert('RGBA')\n  mf_layer = Image.new(mode='RGBA', size=img_rgba.size, color=(0, 0, 0, 0))\n  draw = ImageDraw.Draw(mf_layer)\n  width = img_rgba.size[0]\n  height = img_rgba.size[1]\n  num_row = height // blk_sz\n  num_col = width // blk_sz\n  for i in xrange(num_row):\n    left = (0, i * blk_sz)",
        "detail": "libvpx.tools.3D-Reconstruction.MotionEST.Util",
        "documentation": {}
    },
    {
        "label": "generate",
        "kind": 2,
        "importPath": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "description": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "peekOfCode": "def generate(args, frames):\n  if len(frames) == 0:\n    return\n  #sort the frames based on the frame index\n  frames = sorted(frames, key=lambda x: x[0])\n  #convert the frames to YUV form\n  frames = [f.convert(\"YCbCr\") for _, f in frames]\n  #write the header\n  header = \"YUV4MPEG2 W%d H%d F%s %s A%s\" % (frames[0].width, frames[0].height,\n                                             args.frame_rate, args.interlacing,",
        "detail": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "description": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"--frame_path\", default=\"../data/frame/\", type=str)\nparser.add_argument(\"--frame_rate\", default=\"25:1\", type=str)\nparser.add_argument(\"--interlacing\", default=\"Ip\", type=str)\nparser.add_argument(\"--pix_ratio\", default=\"0:0\", type=str)\nparser.add_argument(\"--color_space\", default=\"4:2:0\", type=str)\nparser.add_argument(\"--output\", default=\"output.y4m\", type=str)\ndef generate(args, frames):\n  if len(frames) == 0:\n    return",
        "detail": "libvpx.tools.3D-Reconstruction.genY4M.genY4M",
        "documentation": {}
    },
    {
        "label": "draw_mv_ls",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def draw_mv_ls(axis, mv_ls, mode=0):\n  colors = np.array([(1., 0., 0., 1.)])\n  segs = np.array([\n      np.array([[ptr[0], ptr[1]], [ptr[0] + ptr[2], ptr[1] + ptr[3]]])\n      for ptr in mv_ls\n  ])\n  line_segments = LineCollection(\n      segs, linewidths=(1.,), colors=colors, linestyle='solid')\n  axis.add_collection(line_segments)\n  if mode == 0:",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "draw_pred_block_ls",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def draw_pred_block_ls(axis, mv_ls, bs, mode=0):\n  colors = np.array([(0., 0., 0., 1.)])\n  segs = []\n  for ptr in mv_ls:\n    if mode == 0:\n      x = ptr[0]\n      y = ptr[1]\n    else:\n      x = ptr[0] + ptr[2]\n      y = ptr[1] + ptr[3]",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "read_frame",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def read_frame(fp, no_swap=0):\n  plane = [None, None, None]\n  for i in range(3):\n    line = fp.readline()\n    word_ls = line.split()\n    word_ls = [int(item) for item in word_ls]\n    rows = word_ls[0]\n    cols = word_ls[1]\n    line = fp.readline()\n    word_ls = line.split()",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "yuv_to_rgb",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def yuv_to_rgb(yuv):\n  #mat = np.array([\n  #    [1.164,   0   , 1.596  ],\n  #    [1.164, -0.391, -0.813],\n  #    [1.164, 2.018 , 0     ] ]\n  #               )\n  #c = np.array([[ -16 , -16 , -16  ],\n  #              [ 0   , -128, -128 ],\n  #              [ -128, -128,   0  ]])\n  mat = np.array([[1, 0, 1.4075], [1, -0.3445, -0.7169], [1, 1.7790, 0]])",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "read_feature_score",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def read_feature_score(fp, mv_rows, mv_cols):\n  line = fp.readline()\n  word_ls = line.split()\n  feature_score = np.array([math.log(float(v) + 1, 2) for v in word_ls])\n  feature_score = feature_score.reshape(mv_rows, mv_cols)\n  return feature_score\ndef read_mv_mode_arr(fp, mv_rows, mv_cols):\n  line = fp.readline()\n  word_ls = line.split()\n  mv_mode_arr = np.array([int(v) for v in word_ls])",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "read_mv_mode_arr",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def read_mv_mode_arr(fp, mv_rows, mv_cols):\n  line = fp.readline()\n  word_ls = line.split()\n  mv_mode_arr = np.array([int(v) for v in word_ls])\n  mv_mode_arr = mv_mode_arr.reshape(mv_rows, mv_cols)\n  return mv_mode_arr\ndef read_frame_dpl_stats(fp):\n  line = fp.readline()\n  word_ls = line.split()\n  frame_idx = int(word_ls[1])",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "read_frame_dpl_stats",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def read_frame_dpl_stats(fp):\n  line = fp.readline()\n  word_ls = line.split()\n  frame_idx = int(word_ls[1])\n  mi_rows = int(word_ls[3])\n  mi_cols = int(word_ls[5])\n  bs = int(word_ls[7])\n  ref_frame_idx = int(word_ls[9])\n  rf_idx = int(word_ls[11])\n  gf_frame_offset = int(word_ls[13])",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "read_dpl_stats_file",
        "kind": 2,
        "importPath": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "description": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "peekOfCode": "def read_dpl_stats_file(filename, frame_num=0):\n  fp = open(filename)\n  line = fp.readline()\n  width = 0\n  height = 0\n  data_ls = []\n  while (line):\n    if line[0] == '=':\n      data_ls.append(read_frame_dpl_stats(fp))\n    line = fp.readline()",
        "detail": "libvpx.tools.non_greedy_mv.non_greedy_mv",
        "documentation": {}
    },
    {
        "label": "_IncludeState",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _IncludeState(object):\n  \"\"\"Tracks line numbers for includes, and the order in which includes appear.\n  include_list contains list of lists of (header, line number) pairs.\n  It's a lists of lists rather than just one flat list to make it\n  easier to update across preprocessor boundaries.\n  Call CheckNextIncludeOrder() once for each header in the file, passing\n  in the type constants defined above. Calls in an illegal order will\n  raise an _IncludeError with an appropriate error message.\n  \"\"\"\n  # self._section will move monotonically through this set. If it ever",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CppLintState",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _CppLintState(object):\n  \"\"\"Maintains module-wide state..\"\"\"\n  def __init__(self):\n    self.verbose_level = 1  # global setting.\n    self.error_count = 0    # global count of reported errors\n    # filters to apply when emitting error messages\n    self.filters = _DEFAULT_FILTERS[:]\n    # backup of filter list. Used to restore the state after each file.\n    self._filters_backup = self.filters[:]\n    self.counting = 'total'  # In what way are we counting errors?",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_FunctionState",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _FunctionState(object):\n  \"\"\"Tracks current function name and the number of lines in its body.\"\"\"\n  _NORMAL_TRIGGER = 250  # for --v=0, 500 for --v=1, etc.\n  _TEST_TRIGGER = 400    # about 50% more than _NORMAL_TRIGGER.\n  def __init__(self):\n    self.in_a_function = False\n    self.lines_in_function = 0\n    self.current_function = ''\n  def Begin(self, function_name):\n    \"\"\"Start analyzing function body.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_IncludeError",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _IncludeError(Exception):\n  \"\"\"Indicates a problem with the include order in a file.\"\"\"\n  pass\nclass FileInfo(object):\n  \"\"\"Provides utility functions for filenames.\n  FileInfo provides easy access to the components of a file's path\n  relative to the project root.\n  \"\"\"\n  def __init__(self, filename):\n    self._filename = filename",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FileInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class FileInfo(object):\n  \"\"\"Provides utility functions for filenames.\n  FileInfo provides easy access to the components of a file's path\n  relative to the project root.\n  \"\"\"\n  def __init__(self, filename):\n    self._filename = filename\n  def FullName(self):\n    \"\"\"Make Windows paths like Unix.\"\"\"\n    return os.path.abspath(self._filename).replace('\\\\', '/')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleansedLines",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class CleansedLines(object):\n  \"\"\"Holds 4 copies of all lines with different preprocessing applied to them.\n  1) elided member contains lines without strings and comments.\n  2) lines member contains lines without comments.\n  3) raw_lines member contains all the lines without processing.\n  4) lines_without_raw_strings member is same as raw_lines, but with C++11 raw\n     strings removed.\n  All these members are of <type 'list'>, and of the same length.\n  \"\"\"\n  def __init__(self, lines):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_BlockInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"\n  def __init__(self, linenum, seen_open_brace):\n    self.starting_linenum = linenum\n    self.seen_open_brace = seen_open_brace\n    self.open_parentheses = 0\n    self.inline_asm = _NO_ASM\n    self.check_namespace_indentation = False\n  def CheckBegin(self, filename, clean_lines, linenum, error):\n    \"\"\"Run checks that applies to text up to the opening brace.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ExternCInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _ExternCInfo(_BlockInfo):\n  \"\"\"Stores information about an 'extern \"C\"' block.\"\"\"\n  def __init__(self, linenum):\n    _BlockInfo.__init__(self, linenum, True)\nclass _ClassInfo(_BlockInfo):\n  \"\"\"Stores information about a class.\"\"\"\n  def __init__(self, name, class_or_struct, clean_lines, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name\n    self.is_derived = False",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ClassInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _ClassInfo(_BlockInfo):\n  \"\"\"Stores information about a class.\"\"\"\n  def __init__(self, name, class_or_struct, clean_lines, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name\n    self.is_derived = False\n    self.check_namespace_indentation = True\n    if class_or_struct == 'struct':\n      self.access = 'public'\n      self.is_struct = True",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_NamespaceInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _NamespaceInfo(_BlockInfo):\n  \"\"\"Stores information about a namespace.\"\"\"\n  def __init__(self, name, linenum):\n    _BlockInfo.__init__(self, linenum, False)\n    self.name = name or ''\n    self.check_namespace_indentation = True\n  def CheckEnd(self, filename, clean_lines, linenum, error):\n    \"\"\"Check end of namespace comments.\"\"\"\n    line = clean_lines.raw_lines[linenum]\n    # Check how many lines is enclosed in this namespace.  Don't issue",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_PreprocessorInfo",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class _PreprocessorInfo(object):\n  \"\"\"Stores checkpoints of nesting stacks when #if/#else is seen.\"\"\"\n  def __init__(self, stack_before_if):\n    # The entire nesting stack before #if\n    self.stack_before_if = stack_before_if\n    # The entire nesting stack up to #else\n    self.stack_before_else = []\n    # Whether we have already seen #else or #elif\n    self.seen_else = False\nclass NestingState(object):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "NestingState",
        "kind": 6,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "class NestingState(object):\n  \"\"\"Holds states related to parsing braces.\"\"\"\n  def __init__(self):\n    # Stack for tracking all braces.  An object is pushed whenever we\n    # see a \"{\", and popped when we see a \"}\".  Only 3 types of\n    # objects are possible:\n    # - _ClassInfo: a class or struct.\n    # - _NamespaceInfo: a namespace.\n    # - _BlockInfo: some other type of block.\n    self.stack = []",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessHppHeadersOption",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)\n  except ValueError:\n    PrintUsage('Header extensions must be comma separated list.')\ndef IsHeaderExtension(file_extension):\n  return file_extension in _hpp_headers",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsHeaderExtension",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsHeaderExtension(file_extension):\n  return file_extension in _hpp_headers\ndef ParseNolintSuppressions(filename, raw_line, linenum, error):\n  \"\"\"Updates the global list of line error-suppressions.\n  Parses any NOLINT comments on the current line, updating the global\n  error_suppressions store.  Reports an error if the NOLINT comment\n  was malformed.\n  Args:\n    filename: str, the name of the input file.\n    raw_line: str, the line of input text, with comments.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ParseNolintSuppressions",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ParseNolintSuppressions(filename, raw_line, linenum, error):\n  \"\"\"Updates the global list of line error-suppressions.\n  Parses any NOLINT comments on the current line, updating the global\n  error_suppressions store.  Reports an error if the NOLINT comment\n  was malformed.\n  Args:\n    filename: str, the name of the input file.\n    raw_line: str, the line of input text, with comments.\n    linenum: int, the number of the current line.\n    error: function, an error handler.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessGlobalSuppresions",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessGlobalSuppresions(lines):\n  \"\"\"Updates the list of global error suppressions.\n  Parses any lint directives in the file that have global effect.\n  Args:\n    lines: An array of strings, each representing a line of the file, with the\n           last element being empty if the file is terminated with a newline.\n  \"\"\"\n  for line in lines:\n    if _SEARCH_C_FILE.search(line):\n      for category in _DEFAULT_C_SUPPRESSED_CATEGORIES:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ResetNolintSuppressions",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ResetNolintSuppressions():\n  \"\"\"Resets the set of NOLINT suppressions to empty.\"\"\"\n  _error_suppressions.clear()\n  _global_error_suppressions.clear()\ndef IsErrorSuppressedByNolint(category, linenum):\n  \"\"\"Returns true if the specified error category is suppressed on this line.\n  Consults the global error_suppressions map populated by\n  ParseNolintSuppressions/ProcessGlobalSuppresions/ResetNolintSuppressions.\n  Args:\n    category: str, the category of the error.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsErrorSuppressedByNolint",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsErrorSuppressedByNolint(category, linenum):\n  \"\"\"Returns true if the specified error category is suppressed on this line.\n  Consults the global error_suppressions map populated by\n  ParseNolintSuppressions/ProcessGlobalSuppresions/ResetNolintSuppressions.\n  Args:\n    category: str, the category of the error.\n    linenum: int, the current line number.\n  Returns:\n    bool, True iff the error should be suppressed due to a NOLINT comment or\n    global suppression.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Match",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def Match(pattern, s):\n  \"\"\"Matches the string with the pattern, caching the compiled regexp.\"\"\"\n  # The regexp compilation caching is inlined in both Match and Search for\n  # performance reasons; factoring it out into a separate function turns out\n  # to be noticeably expensive.\n  if pattern not in _regexp_compile_cache:\n    _regexp_compile_cache[pattern] = sre_compile.compile(pattern)\n  return _regexp_compile_cache[pattern].match(s)\ndef ReplaceAll(pattern, rep, s):\n  \"\"\"Replaces instances of pattern in a string with a replacement.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ReplaceAll",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ReplaceAll(pattern, rep, s):\n  \"\"\"Replaces instances of pattern in a string with a replacement.\n  The compiled regex is kept in a cache shared by Match and Search.\n  Args:\n    pattern: regex pattern\n    rep: replacement text\n    s: search string\n  Returns:\n    string with replacements made (or original string if no replacements)\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Search",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def Search(pattern, s):\n  \"\"\"Searches the string for the pattern, caching the compiled regexp.\"\"\"\n  if pattern not in _regexp_compile_cache:\n    _regexp_compile_cache[pattern] = sre_compile.compile(pattern)\n  return _regexp_compile_cache[pattern].search(s)\ndef _IsSourceExtension(s):\n  \"\"\"File extension (excluding dot) matches a source file extension.\"\"\"\n  return s in ('c', 'cc', 'cpp', 'cxx')\nclass _IncludeState(object):\n  \"\"\"Tracks line numbers for includes, and the order in which includes appear.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "Error",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def Error(filename, linenum, category, confidence, message):\n  \"\"\"Logs the fact we've found a lint error.\n  We log where the error was found, and also our confidence in the error,\n  that is, how certain we are this is a legitimate style regression, and\n  not a misidentification or a use that's sometimes justified.\n  False positives can be suppressed by the use of\n  \"cpplint(category)\"  comments on the offending line.  These are\n  parsed into _error_suppressions.\n  Args:\n    filename: The name of the file containing the error.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsCppString",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsCppString(line):\n  \"\"\"Does line terminate so, that the next symbol is in string constant.\n  This function does not consider single-line nor multi-line comments.\n  Args:\n    line: is a partial line of code starting from the 0..n.\n  Returns:\n    True, if next character appended to 'line' is inside a\n    string constant.\n  \"\"\"\n  line = line.replace(r'\\\\', 'XX')  # after this, \\\\\" does not match to \\\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleanseRawStrings",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CleanseRawStrings(raw_lines):\n  \"\"\"Removes C++11 raw strings from lines.\n    Before:\n      static const char kData[] = R\"(\n          multi-line string\n          )\";\n    After:\n      static const char kData[] = \"\"\n          (replaced by blank line)\n          \"\";",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindNextMultiLineCommentStart",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FindNextMultiLineCommentStart(lines, lineix):\n  \"\"\"Find the beginning marker for a multiline comment.\"\"\"\n  while lineix < len(lines):\n    if lines[lineix].strip().startswith('/*'):\n      # Only return this marker if the comment goes beyond this line\n      if lines[lineix].strip().find('*/', 2) < 0:\n        return lineix\n    lineix += 1\n  return len(lines)\ndef FindNextMultiLineCommentEnd(lines, lineix):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindNextMultiLineCommentEnd",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FindNextMultiLineCommentEnd(lines, lineix):\n  \"\"\"We are inside a comment, find the end marker.\"\"\"\n  while lineix < len(lines):\n    if lines[lineix].strip().endswith('*/'):\n      return lineix\n    lineix += 1\n  return len(lines)\ndef RemoveMultiLineCommentsFromRange(lines, begin, end):\n  \"\"\"Clears a range of lines for multi-line comments.\"\"\"\n  # Having // <empty> comments makes the lines non-empty, so we will not get",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "RemoveMultiLineCommentsFromRange",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def RemoveMultiLineCommentsFromRange(lines, begin, end):\n  \"\"\"Clears a range of lines for multi-line comments.\"\"\"\n  # Having // <empty> comments makes the lines non-empty, so we will not get\n  # unnecessary blank line warnings later in the code.\n  for i in range(begin, end):\n    lines[i] = '/**/'\ndef RemoveMultiLineComments(filename, lines, error):\n  \"\"\"Removes multiline (c-style) comments from lines.\"\"\"\n  lineix = 0\n  while lineix < len(lines):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "RemoveMultiLineComments",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def RemoveMultiLineComments(filename, lines, error):\n  \"\"\"Removes multiline (c-style) comments from lines.\"\"\"\n  lineix = 0\n  while lineix < len(lines):\n    lineix_begin = FindNextMultiLineCommentStart(lines, lineix)\n    if lineix_begin >= len(lines):\n      return\n    lineix_end = FindNextMultiLineCommentEnd(lines, lineix_begin)\n    if lineix_end >= len(lines):\n      error(filename, lineix_begin + 1, 'readability/multiline_comment', 5,",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CleanseComments",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CleanseComments(line):\n  \"\"\"Removes //-comments and single-line C-style /* */ comments.\n  Args:\n    line: A line of C++ source.\n  Returns:\n    The line with single-line comments removed.\n  \"\"\"\n  commentpos = line.find('//')\n  if commentpos != -1 and not IsCppString(line[:commentpos]):\n    line = line[:commentpos].rstrip()",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindEndOfExpressionInLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FindEndOfExpressionInLine(line, startpos, stack):\n  \"\"\"Find the position just after the end of current parenthesized expression.\n  Args:\n    line: a CleansedLines line.\n    startpos: start searching at this position.\n    stack: nesting stack at startpos.\n  Returns:\n    On finding matching end: (index just after matching end, None)\n    On finding an unclosed expression: (-1, None)\n    Otherwise: (-1, new stack at end of this line)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CloseExpression",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CloseExpression(clean_lines, linenum, pos):\n  \"\"\"If input points to ( or { or [ or <, finds the position that closes it.\n  If lines[linenum][pos] points to a '(' or '{' or '[' or '<', finds the\n  linenum/pos that correspond to the closing of the expression.\n  TODO(unknown): cpplint spends a fair bit of time matching parentheses.\n  Ideally we would want to index all opening and closing parentheses once\n  and have CloseExpression be just a simple lookup, but due to preprocessor\n  tricks, this is not so easy.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindStartOfExpressionInLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FindStartOfExpressionInLine(line, endpos, stack):\n  \"\"\"Find position at the matching start of current expression.\n  This is almost the reverse of FindEndOfExpressionInLine, but note\n  that the input position and returned position differs by 1.\n  Args:\n    line: a CleansedLines line.\n    endpos: start searching at this position.\n    stack: nesting stack at endpos.\n  Returns:\n    On finding matching start: (index at matching start, None)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ReverseCloseExpression",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ReverseCloseExpression(clean_lines, linenum, pos):\n  \"\"\"If input points to ) or } or ] or >, finds the position that opens it.\n  If lines[linenum][pos] points to a ')' or '}' or ']' or '>', finds the\n  linenum/pos that correspond to the opening of the expression.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    pos: A position on the line.\n  Returns:\n    A tuple (line, linenum, pos) pointer *at* the opening brace, or",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForCopyright",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForCopyright(filename, lines, error):\n  \"\"\"Logs an error if no Copyright message appears at the top of the file.\"\"\"\n  # We'll say it should occur by line 10. Don't forget there's a\n  # placeholder line at the front.\n  for line in xrange(1, min(len(lines), 11)):\n    if re.search(r'Copyright', lines[line], re.I): break\n  else:                       # means no copyright line was found\n    error(filename, 0, 'legal/copyright', 5,\n          'No copyright message found.  '\n          'You should have a line: \"Copyright [year] <Copyright Owner>\"')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetIndentLevel",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def GetIndentLevel(line):\n  \"\"\"Return the number of leading spaces in line.\n  Args:\n    line: A string to check.\n  Returns:\n    An integer count of leading spaces, possibly zero.\n  \"\"\"\n  indent = Match(r'^( *)\\S', line)\n  if indent:\n    return len(indent.group(1))",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PathSplitToList",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def PathSplitToList(path):\n  \"\"\"Returns the path split into a list by the separator.\n  Args:\n    path: An absolute or relative path (e.g. '/a/b/c/' or '../a')\n  Returns:\n    A list of path components (e.g. ['a', 'b', 'c]).\n  \"\"\"\n  lst = []\n  while True:\n    (head, tail) = os.path.split(path)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetHeaderGuardCPPVariable",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def GetHeaderGuardCPPVariable(filename):\n  \"\"\"Returns the CPP variable that should be used as a header guard.\n  Args:\n    filename: The name of a C++ header file.\n  Returns:\n    The CPP variable that should be used as a header guard in the\n    named file.\n  \"\"\"\n  # Restores original filename in case that cpplint is invoked from Emacs's\n  # flymake.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForHeaderGuard",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForHeaderGuard(filename, clean_lines, error):\n  \"\"\"Checks that the file contains a header guard.\n  Logs an error if no #ifndef header guard is present.  For other\n  headers, checks that the full pathname is used.\n  Args:\n    filename: The name of the C++ header file.\n    clean_lines: A CleansedLines instance containing the file.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Don't check for header guards if there are error suppression",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckHeaderFileIncluded",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckHeaderFileIncluded(filename, include_state, error):\n  \"\"\"Logs an error if a .cc file does not include its header.\"\"\"\n  # Do not check test files\n  fileinfo = FileInfo(filename)\n  if Search(_TEST_FILE_SUFFIX, fileinfo.BaseName()):\n    return\n  headerfile = filename[0:len(filename) - len(fileinfo.Extension())] + '.h'\n  if not os.path.exists(headerfile):\n    return\n  headername = FileInfo(headerfile).RepositoryName()",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForBadCharacters",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForBadCharacters(filename, lines, error):\n  \"\"\"Logs an error for each line containing bad characters.\n  Two kinds of bad characters:\n  1. Unicode replacement characters: These indicate that either the file\n  contained invalid UTF-8 (likely) or Unicode replacement characters (which\n  it shouldn't).  Note that it's possible for this to throw off line\n  numbering if the invalid UTF-8 occurred adjacent to a newline.\n  2. NUL bytes.  These are problematic for some tools.\n  Args:\n    filename: The name of the current file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNewlineAtEOF",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForNewlineAtEOF(filename, lines, error):\n  \"\"\"Logs an error if there is no newline char at the end of the file.\n  Args:\n    filename: The name of the current file.\n    lines: An array of strings, each representing a line of the file.\n    error: The function to call with any errors found.\n  \"\"\"\n  # The array lines() was created by adding two newlines to the\n  # original file (go figure), then splitting on \\n.\n  # To verify that the file ends in \\n, we just have to make sure the",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForMultilineCommentsAndStrings",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForMultilineCommentsAndStrings(filename, clean_lines, linenum, error):\n  \"\"\"Logs an error if we see /* ... */ or \"...\" that extend past one line.\n  /* ... */ comments are legit inside macros, for one line.\n  Otherwise, we prefer // comments, so it's ok to warn about the\n  other.  Likewise, it's ok for strings to extend across multiple\n  lines, as long as a line continuation character (backslash)\n  terminates each line. Although not currently prohibited by the C++\n  style guide, it's ugly and unnecessary. We don't do well with either\n  in this lint program, so we warn about both.\n  Args:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckPosixThreading",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckPosixThreading(filename, clean_lines, linenum, error):\n  \"\"\"Checks for calls to thread-unsafe functions.\n  Much code has been originally written without consideration of\n  multi-threading. Also, engineers are relying on their old experience;\n  they have learned posix before threading extensions were added. These\n  tests guide the engineers to use thread-safe functions (when using\n  posix directly).\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckVlogArguments",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckVlogArguments(filename, clean_lines, linenum, error):\n  \"\"\"Checks that VLOG() is only used for defining a logging level.\n  For example, VLOG(2) is correct. VLOG(INFO), VLOG(WARNING), VLOG(ERROR), and\n  VLOG(FATAL) are not.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckInvalidIncrement",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckInvalidIncrement(filename, clean_lines, linenum, error):\n  \"\"\"Checks for invalid increment *count++.\n  For example following function:\n  void increment_counter(int* count) {\n    *count++;\n  }\n  is invalid, because it effectively does count++, moving pointer, and should\n  be replaced with ++*count, (*count)++ or *count += 1.\n  Args:\n    filename: The name of the current file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsMacroDefinition",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsMacroDefinition(clean_lines, linenum):\n  if Search(r'^#define', clean_lines[linenum]):\n    return True\n  if linenum > 0 and Search(r'\\\\$', clean_lines[linenum - 1]):\n    return True\n  return False\ndef IsForwardClassDeclaration(clean_lines, linenum):\n  return Match(r'^\\s*(\\btemplate\\b)*.*class\\s+\\w+;\\s*$', clean_lines[linenum])\nclass _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsForwardClassDeclaration",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsForwardClassDeclaration(clean_lines, linenum):\n  return Match(r'^\\s*(\\btemplate\\b)*.*class\\s+\\w+;\\s*$', clean_lines[linenum])\nclass _BlockInfo(object):\n  \"\"\"Stores information about a generic block of code.\"\"\"\n  def __init__(self, linenum, seen_open_brace):\n    self.starting_linenum = linenum\n    self.seen_open_brace = seen_open_brace\n    self.open_parentheses = 0\n    self.inline_asm = _NO_ASM\n    self.check_namespace_indentation = False",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNonStandardConstructs",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForNonStandardConstructs(filename, clean_lines, linenum,\n                                  nesting_state, error):\n  r\"\"\"Logs an error if we see certain non-ANSI constructs ignored by gcc-2.\n  Complain about several constructs which gcc-2 accepts, but which are\n  not standard C++.  Warning about these in lint is one way to ease the\n  transition to new compilers.\n  - put storage class first (e.g. \"static const\" instead of \"const static\").\n  - \"%lld\" instead of %qd\" in printf-type functions.\n  - \"%1$d\" is non-standard in printf-type functions.\n  - \"\\%\" is an undefined character escape sequence.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSpacingForFunctionCall",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckSpacingForFunctionCall(filename, clean_lines, linenum, error):\n  \"\"\"Checks for the correctness of various spacing around function calls.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Since function calls often occur inside if/for/while/switch",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsBlankLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsBlankLine(line):\n  \"\"\"Returns true if the given line is blank.\n  We consider a line to be blank if the line is empty or consists of\n  only white spaces.\n  Args:\n    line: A line of a string.\n  Returns:\n    True, if the given line is blank.\n  \"\"\"\n  return not line or line.isspace()",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNamespaceIndentation",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForNamespaceIndentation(filename, nesting_state, clean_lines, line,\n                                 error):\n  is_namespace_indent_item = (\n      len(nesting_state.stack) > 1 and\n      nesting_state.stack[-1].check_namespace_indentation and\n      isinstance(nesting_state.previous_stack_top, _NamespaceInfo) and\n      nesting_state.previous_stack_top == nesting_state.stack[-2])\n  if ShouldCheckNamespaceIndentation(nesting_state, is_namespace_indent_item,\n                                     clean_lines.elided, line):\n    CheckItemIndentationInNamespace(filename, clean_lines.elided,",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForFunctionLengths",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForFunctionLengths(filename, clean_lines, linenum,\n                            function_state, error):\n  \"\"\"Reports for long function bodies.\n  For an overview why this is done, see:\n  https://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Write_Short_Functions\n  Uses a simplistic algorithm assuming other style guidelines\n  (especially spacing) are followed.\n  Only checks unindented functions, so class members are unchecked.\n  Trivial bodies are unchecked, so constructors with huge initializer lists\n  may be missed.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckComment",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckComment(line, filename, linenum, next_line_start, error):\n  \"\"\"Checks for common mistakes in comments.\n  Args:\n    line: The line in question.\n    filename: The name of the current file.\n    linenum: The number of the line to check.\n    next_line_start: The first non-whitespace column of the next line.\n    error: The function to call with any errors found.\n  \"\"\"\n  commentpos = line.find('//')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckSpacing(filename, clean_lines, linenum, nesting_state, error):\n  \"\"\"Checks for the correctness of various spacing issues in the code.\n  Things we check for: spaces around operators, spaces after\n  if/for/while/switch, no spaces around parens in function calls, two\n  spaces between code and comment, don't start a block with a blank\n  line, don't end a function with a blank line, don't add a blank line\n  after public/protected/private, don't have too many blank lines in a row.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckOperatorSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckOperatorSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing around operators.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Don't try to do spacing checks for operator methods.  Do this by",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckParenthesisSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckParenthesisSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing around parentheses.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # No spaces after an if, while, switch, or for",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCommaSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckCommaSpacing(filename, clean_lines, linenum, error):\n  \"\"\"Checks for horizontal spacing near commas and semicolons.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  raw = clean_lines.lines_without_raw_strings\n  line = clean_lines.elided[linenum]",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckBracesSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckBracesSpacing(filename, clean_lines, linenum, nesting_state, error):\n  \"\"\"Checks for horizontal spacing near commas.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    nesting_state: A NestingState instance which maintains information about\n                   the current stack of nested blocks being parsed.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsDecltype",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsDecltype(clean_lines, linenum, column):\n  \"\"\"Check if the token ending on (linenum, column) is decltype().\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: the number of the line to check.\n    column: end column of the token to check.\n  Returns:\n    True if this token is decltype() expression, False otherwise.\n  \"\"\"\n  (text, _, start_col) = ReverseCloseExpression(clean_lines, linenum, column)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckSectionSpacing",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckSectionSpacing(filename, clean_lines, class_info, linenum, error):\n  \"\"\"Checks for additional blank line issues related to sections.\n  Currently the only thing checked here is blank line before protected/private.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    class_info: A _ClassInfo objects.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetPreviousNonBlankLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def GetPreviousNonBlankLine(clean_lines, linenum):\n  \"\"\"Return the most recent non-blank line and its line number.\n  Args:\n    clean_lines: A CleansedLines instance containing the file contents.\n    linenum: The number of the line to check.\n  Returns:\n    A tuple with two elements.  The first element is the contents of the last\n    non-blank line before the current line, or the empty string if this is the\n    first non-blank line.  The second is the line number of that line, or -1\n    if this is the first non-blank line.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckBraces",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckBraces(filename, clean_lines, linenum, error):\n  \"\"\"Looks for misplaced braces (e.g. at the end of line).\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]        # get rid of comments and strings\n  if Match(r'\\s*{\\s*$', line):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckTrailingSemicolon",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckTrailingSemicolon(filename, clean_lines, linenum, error):\n  \"\"\"Looks for redundant trailing semicolon.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Block bodies should not be followed by a semicolon.  Due to C++11",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckEmptyBlockBody",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckEmptyBlockBody(filename, clean_lines, linenum, error):\n  \"\"\"Look for empty loop/conditional body with only a single semicolon.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Search for loop keywords at the beginning of the line.  Because only\n  # whitespaces are allowed before the keywords, this will also ignore most",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FindCheckMacro",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FindCheckMacro(line):\n  \"\"\"Find a replaceable CHECK-like macro.\n  Args:\n    line: line to search on.\n  Returns:\n    (macro name, start position), or (None, -1) if no replaceable\n    macro is found.\n  \"\"\"\n  for macro in _CHECK_MACROS:\n    i = line.find(macro)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCheck",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckCheck(filename, clean_lines, linenum, error):\n  \"\"\"Checks the use of CHECK and EXPECT macros.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Decide the set of replacement macros that should be suggested\n  lines = clean_lines.elided",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckAltTokens",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckAltTokens(filename, clean_lines, linenum, error):\n  \"\"\"Check alternative keywords being used in boolean expressions.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Avoid preprocessor lines",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "GetLineWidth",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def GetLineWidth(line):\n  \"\"\"Determines the width of the line in column positions.\n  Args:\n    line: A string, which may be a Unicode string.\n  Returns:\n    The width of the line in column positions, accounting for Unicode\n    combining characters and wide characters.\n  \"\"\"\n  if isinstance(line, unicode):\n    width = 0",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckStyle",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n               error):\n  \"\"\"Checks rules from the 'C++ style rules' section of cppguide.html.\n  Most of these rules are hard to test (naming, comment style), but we\n  do what we can.  In particular we check for 2-space indents, line lengths,\n  tab usage, spaces inside code, etc.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckIncludeLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):\n  \"\"\"Check rules that are applicable to #include lines.\n  Strings on #include lines are NOT removed from elided line, to make\n  certain tasks easier. However, to prevent false positives, checks\n  applicable to #include lines in CheckLanguage must be put here.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    include_state: An _IncludeState instance in which the headers are inserted.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckLanguage",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using\n  uint32 inappropriately), but we do the best we can.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    file_extension: The extension (without the dot) of the filename.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckGlobalStatic",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckGlobalStatic(filename, clean_lines, linenum, error):\n  \"\"\"Check for unsafe global or static objects.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Match two lines at a time to support multiline declarations",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckPrintf",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckPrintf(filename, clean_lines, linenum, error):\n  \"\"\"Check for printf related issues.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # When snprintf is used, the second argument shouldn't be a literal.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsDerivedFunction",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsDerivedFunction(clean_lines, linenum):\n  \"\"\"Check if current line contains an inherited function.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line contains a function with \"override\"\n    virt-specifier.\n  \"\"\"\n  # Scan back a few lines for start of current function",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsOutOfLineMethodDefinition",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsOutOfLineMethodDefinition(clean_lines, linenum):\n  \"\"\"Check if current line contains an out-of-line method definition.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line contains an out-of-line method definition.\n  \"\"\"\n  # Scan back a few lines for start of current function\n  for i in xrange(linenum, max(-1, linenum - 10), -1):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsInitializerList",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsInitializerList(clean_lines, linenum):\n  \"\"\"Check if current line is inside constructor initializer list.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if current line appears to be inside constructor initializer\n    list, False otherwise.\n  \"\"\"\n  for i in xrange(linenum, 1, -1):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForNonConstReference",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForNonConstReference(filename, clean_lines, linenum,\n                              nesting_state, error):\n  \"\"\"Check for non-const references.\n  Separate from CheckLanguage since it scans backwards from current\n  line, instead of scanning forward.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    nesting_state: A NestingState instance which maintains information about",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCasts",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckCasts(filename, clean_lines, linenum, error):\n  \"\"\"Various cast related checks.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  # Check to see if they're using an conversion function cast.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckCStyleCast",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckCStyleCast(filename, clean_lines, linenum, cast_type, pattern, error):\n  \"\"\"Checks for a C-style cast by looking for the pattern.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    cast_type: The string for the C++ cast to recommend.  This is either\n      reinterpret_cast, static_cast, or const_cast, depending.\n    pattern: The regular expression used to find C-style casts.\n    error: The function to call with any errors found.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ExpectingFunctionArgs",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ExpectingFunctionArgs(clean_lines, linenum):\n  \"\"\"Checks whether where function type arguments are expected.\n  Args:\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n  Returns:\n    True if the line at 'linenum' is inside something that expects arguments\n    of function types.\n  \"\"\"\n  line = clean_lines.elided[linenum]",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FilesBelongToSameModule",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FilesBelongToSameModule(filename_cc, filename_h):\n  \"\"\"Check if these two filenames belong to the same module.\n  The concept of a 'module' here is a as follows:\n  foo.h, foo-inl.h, foo.cc, foo_test.cc and foo_unittest.cc belong to the\n  same 'module' if they are in the same directory.\n  some/path/public/xyzzy and some/path/internal/xyzzy are also considered\n  to belong to the same module here.\n  If the filename_cc contains a longer path than the filename_h, for example,\n  '/absolute/path/to/base/sysinfo.cc', and this file would include\n  'base/sysinfo.h', this function also produces the prefix needed to open the",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "UpdateIncludeState",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def UpdateIncludeState(filename, include_dict, io=codecs):\n  \"\"\"Fill up the include_dict with new includes found from the file.\n  Args:\n    filename: the name of the header to read.\n    include_dict: a dictionary in which the headers are inserted.\n    io: The io factory to use to read the file. Provided for testability.\n  Returns:\n    True if a header was successfully added. False otherwise.\n  \"\"\"\n  headerfile = None",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckForIncludeWhatYouUse",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n                              io=codecs):\n  \"\"\"Reports for missing stl includes.\n  This function will output warnings to make sure you are including the headers\n  necessary for the stl containers and functions that you use. We only give one\n  reason to include a header. For example, if you use both equal_to<> and\n  less<> in a .h file, only one (the latter in the file) of these will be\n  reported as a reason to include the <functional>.\n  Args:\n    filename: The name of the current file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckMakePairUsesDeduction",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):\n  \"\"\"Check that make_pair's template arguments are deduced.\n  G++ 4.6 in C++11 mode fails badly if make_pair's template arguments are\n  specified explicitly, and such use isn't intended in any case.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckRedundantVirtual",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckRedundantVirtual(filename, clean_lines, linenum, error):\n  \"\"\"Check if line contains a redundant \"virtual\" function-specifier.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Look for \"virtual\" on current line.\n  line = clean_lines.elided[linenum]",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckRedundantOverrideOrFinal",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckRedundantOverrideOrFinal(filename, clean_lines, linenum, error):\n  \"\"\"Check if line contains a redundant \"override\" or \"final\" virt-specifier.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  # Look for closing parenthesis nearby.  We need one to confirm where\n  # the declarator ends and where the virt-specifier starts to avoid",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "IsBlockInNameSpace",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def IsBlockInNameSpace(nesting_state, is_forward_declaration):\n  \"\"\"Checks that the new block is directly in a namespace.\n  Args:\n    nesting_state: The _NestingState object that contains info about our state.\n    is_forward_declaration: If the class is a forward declared class.\n  Returns:\n    Whether or not the new block is directly in a namespace.\n  \"\"\"\n  if is_forward_declaration:\n    if len(nesting_state.stack) >= 1 and (",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ShouldCheckNamespaceIndentation",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ShouldCheckNamespaceIndentation(nesting_state, is_namespace_indent_item,\n                                    raw_lines_no_comments, linenum):\n  \"\"\"This method determines if we should apply our namespace indentation check.\n  Args:\n    nesting_state: The current nesting state.\n    is_namespace_indent_item: If we just put a new class on the stack, True.\n      If the top of the stack is not a class, or we did not recently\n      add the class, False.\n    raw_lines_no_comments: The lines without the comments.\n    linenum: The current line number we are processing.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "CheckItemIndentationInNamespace",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def CheckItemIndentationInNamespace(filename, raw_lines_no_comments, linenum,\n                                    error):\n  line = raw_lines_no_comments[linenum]\n  if Match(r'^\\s+', line):\n    error(filename, linenum, 'runtime/indentation_namespace', 4,\n          'Do not indent within a namespace')\ndef ProcessLine(filename, file_extension, clean_lines, line,\n                include_state, function_state, nesting_state, error,\n                extra_check_functions=[]):\n  \"\"\"Processes a single line in the file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessLine",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessLine(filename, file_extension, clean_lines, line,\n                include_state, function_state, nesting_state, error,\n                extra_check_functions=[]):\n  \"\"\"Processes a single line in the file.\n  Args:\n    filename: Filename of the file that is being processed.\n    file_extension: The extension (dot not included) of the file.\n    clean_lines: An array of strings, each representing a line of the file,\n                 with comments stripped.\n    line: Number of line being processed.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FlagCxx11Features",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FlagCxx11Features(filename, clean_lines, linenum, error):\n  \"\"\"Flag those c++11 features that we only allow in certain places.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  include = Match(r'\\s*#\\s*include\\s+[<\"]([^<\"]+)[\">]', line)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "FlagCxx14Features",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def FlagCxx14Features(filename, clean_lines, linenum, error):\n  \"\"\"Flag those C++14 features that we restrict.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.\n  \"\"\"\n  line = clean_lines.elided[linenum]\n  include = Match(r'\\s*#\\s*include\\s+[<\"]([^<\"]+)[\">]', line)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessFileData",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessFileData(filename, file_extension, lines, error,\n                    extra_check_functions=[]):\n  \"\"\"Performs lint checks and reports any errors to the given error function.\n  Args:\n    filename: Filename of the file that is being processed.\n    file_extension: The extension (dot not included) of the file.\n    lines: An array of strings, each representing a line of the file, with the\n           last element being empty if the file is terminated with a newline.\n    error: A callable to which errors are reported, which takes 4 arguments:\n           filename, line number, error level, and message",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessConfigOverrides",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessConfigOverrides(filename):\n  \"\"\" Loads the configuration files and processes the config overrides.\n  Args:\n    filename: The name of the file being processed by the linter.\n  Returns:\n    False if the current |filename| should not be processed further.\n  \"\"\"\n  abs_filename = os.path.abspath(filename)\n  cfg_filters = []\n  keep_looking = True",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ProcessFile",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ProcessFile(filename, vlevel, extra_check_functions=[]):\n  \"\"\"Does google-lint on a single file.\n  Args:\n    filename: The name of the file to parse.\n    vlevel: The level of errors to report.  Every error of confidence\n    >= verbose_level will be reported.  0 is a good default.\n    extra_check_functions: An array of additional check functions that will be\n                           run on each source line. Each function takes 4\n                           arguments: filename, clean_lines, line, error\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PrintUsage",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def PrintUsage(message):\n  \"\"\"Prints a brief usage string and exits, optionally with an error message.\n  Args:\n    message: The optional error message.\n  \"\"\"\n  sys.stderr.write(_USAGE)\n  if message:\n    sys.exit('\\nFATAL ERROR: ' + message)\n  else:\n    sys.exit(1)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "PrintCategories",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def PrintCategories():\n  \"\"\"Prints a list of all the error-categories used by error messages.\n  These are the categories used to filter messages via --filter.\n  \"\"\"\n  sys.stderr.write(''.join('  %s\\n' % cat for cat in _ERROR_CATEGORIES))\n  sys.exit(0)\ndef ParseArguments(args):\n  \"\"\"Parses the command line arguments.\n  This may set the output format and verbosity level as side-effects.\n  Args:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "ParseArguments",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def ParseArguments(args):\n  \"\"\"Parses the command line arguments.\n  This may set the output format and verbosity level as side-effects.\n  Args:\n    args: The command line arguments:\n  Returns:\n    The list of filenames to lint.\n  \"\"\"\n  try:\n    (opts, filenames) = getopt.getopt(args, '', ['help', 'output=', 'verbose=',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "def main():\n  filenames = ParseArguments(sys.argv[1:])\n  # Change stderr to write with replacement characters so we don't die\n  # if we try to print something containing non-ASCII characters.\n  sys.stderr = codecs.StreamReaderWriter(sys.stderr,\n                                         codecs.getreader('utf8'),\n                                         codecs.getwriter('utf8'),\n                                         'replace')\n  _cpplint_state.ResetErrorCounts()\n  for filename in filenames:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_USAGE",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_USAGE = \"\"\"\nSyntax: cpplint.py [--verbose=#] [--output=vs7] [--filter=-x,+y,...]\n                   [--counting=total|toplevel|detailed] [--root=subdir]\n                   [--linelength=digits] [--headers=x,y,...]\n                   [--quiet]\n        <file> [file] ...\n  The style guidelines this tries to follow are those in\n    https://google-styleguide.googlecode.com/svn/trunk/cppguide.xml\n  Every problem is given a confidence score from 1-5, with 5 meaning we are\n  certain of the problem, and 1 meaning it could be a legitimate construct.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ERROR_CATEGORIES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_ERROR_CATEGORIES = [\n    'build/class',\n    'build/c++11',\n    'build/c++14',\n    'build/c++tr1',\n    'build/deprecated',\n    'build/endif_comment',\n    'build/explicit_make_pair',\n    'build/forward_decl',\n    'build/header_guard',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_LEGACY_ERROR_CATEGORIES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_LEGACY_ERROR_CATEGORIES = [\n    'readability/streams',\n    'readability/function',\n    ]\n# The default state of the category filter. This is overridden by the --filter=\n# flag. By default all errors are on, so only add here categories that should be\n# off by default (i.e., categories that must be enabled by the --filter= flags).\n# All entries here should start with a '-' or '+', as in the --filter= flag.\n_DEFAULT_FILTERS = ['-build/include_alpha']\n# The default list of categories suppressed for C (not C++) files.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_FILTERS",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_DEFAULT_FILTERS = ['-build/include_alpha']\n# The default list of categories suppressed for C (not C++) files.\n_DEFAULT_C_SUPPRESSED_CATEGORIES = [\n    'readability/casting',\n    ]\n# The default list of categories suppressed for Linux Kernel files.\n_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_C_SUPPRESSED_CATEGORIES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_DEFAULT_C_SUPPRESSED_CATEGORIES = [\n    'readability/casting',\n    ]\n# The default list of categories suppressed for Linux Kernel files.\n_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we\n# decided those were OK, as long as they were in UTF-8 and didn't represent\n# hard-coded international strings, which belong in a separate i18n file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_DEFAULT_KERNEL_SUPPRESSED_CATEGORIES = [\n    'whitespace/tab',\n    ]\n# We used to check for high-bit characters, but after much discussion we\n# decided those were OK, as long as they were in UTF-8 and didn't represent\n# hard-coded international strings, which belong in a separate i18n file.\n# C++ headers\n_CPP_HEADERS = frozenset([\n    # Legacy\n    'algobase.h',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CPP_HEADERS",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_CPP_HEADERS = frozenset([\n    # Legacy\n    'algobase.h',\n    'algo.h',\n    'alloc.h',\n    'builtinbuf.h',\n    'bvector.h',\n    'complex.h',\n    'defalloc.h',\n    'deque.h',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_TYPES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_TYPES = re.compile(\n    r'^(?:'\n    # [dcl.type.simple]\n    r'(char(16_t|32_t)?)|wchar_t|'\n    r'bool|short|int|long|signed|unsigned|float|double|'\n    # [support.types]\n    r'(ptrdiff_t|size_t|max_align_t|nullptr_t)|'\n    # [cstdint.syn]\n    r'(u?int(_fast|_least)?(8|16|32|64)_t)|'\n    r'(u?int(max|ptr)_t)|'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_THIRD_PARTY_HEADERS_PATTERN",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_THIRD_PARTY_HEADERS_PATTERN = re.compile(\n    r'^(?:[^/]*[A-Z][^/]*\\.h|lua\\.h|lauxlib\\.h|lualib\\.h)$')\n# Pattern for matching FileInfo.BaseName() against test file name\n_TEST_FILE_SUFFIX = r'(_test|_unittest|_regtest)$'\n# Pattern that matches only complete whitespace, possibly across multiple lines.\n_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_TEST_FILE_SUFFIX",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_TEST_FILE_SUFFIX = r'(_test|_unittest|_regtest)$'\n# Pattern that matches only complete whitespace, possibly across multiple lines.\n_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_EMPTY_CONDITIONAL_BODY_PATTERN",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n# Assertion macros.  These are defined in base/logging.h and\n# testing/base/public/gunit.h.\n_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]\n# Replacement macros for CHECK/DCHECK/EXPECT_TRUE/EXPECT_FALSE\n_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CHECK_MACROS",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_CHECK_MACROS = [\n    'DCHECK', 'CHECK',\n    'EXPECT_TRUE', 'ASSERT_TRUE',\n    'EXPECT_FALSE', 'ASSERT_FALSE',\n    ]\n# Replacement macros for CHECK/DCHECK/EXPECT_TRUE/EXPECT_FALSE\n_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])\nfor op, replacement in [('==', 'EQ'), ('!=', 'NE'),\n                        ('>=', 'GE'), ('>', 'GT'),\n                        ('<=', 'LE'), ('<', 'LT')]:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CHECK_REPLACEMENT",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])\nfor op, replacement in [('==', 'EQ'), ('!=', 'NE'),\n                        ('>=', 'GE'), ('>', 'GT'),\n                        ('<=', 'LE'), ('<', 'LT')]:\n  _CHECK_REPLACEMENT['DCHECK'][op] = 'DCHECK_%s' % replacement\n  _CHECK_REPLACEMENT['CHECK'][op] = 'CHECK_%s' % replacement\n  _CHECK_REPLACEMENT['EXPECT_TRUE'][op] = 'EXPECT_%s' % replacement\n  _CHECK_REPLACEMENT['ASSERT_TRUE'][op] = 'ASSERT_%s' % replacement\nfor op, inv_replacement in [('==', 'NE'), ('!=', 'EQ'),\n                            ('>=', 'LT'), ('>', 'LE'),",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ALT_TOKEN_REPLACEMENT",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_ALT_TOKEN_REPLACEMENT = {\n    'and': '&&',\n    'bitor': '|',\n    'or': '||',\n    'xor': '^',\n    'compl': '~',\n    'bitand': '&',\n    'and_eq': '&=',\n    'or_eq': '|=',\n    'xor_eq': '^=',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_ALT_TOKEN_REPLACEMENT_PATTERN",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_ALT_TOKEN_REPLACEMENT_PATTERN = re.compile(\n    r'[ =()](' + ('|'.join(_ALT_TOKEN_REPLACEMENT.keys())) + r')(?=[ (]|$)')\n# These constants define types of headers for use with\n# _IncludeState.CheckNextIncludeOrder().\n_C_SYS_HEADER = 1\n_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_C_SYS_HEADER",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_C_SYS_HEADER = 1\n_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_CPP_SYS_HEADER",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_CPP_SYS_HEADER = 2\n_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_LIKELY_MY_HEADER",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_LIKELY_MY_HEADER = 3\n_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_POSSIBLE_MY_HEADER",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_POSSIBLE_MY_HEADER = 4\n_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_OTHER_HEADER",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_OTHER_HEADER = 5\n# These constants define the current inline assembly state\n_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_NO_ASM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_NO_ASM = 0       # Outside of inline assembly block\n_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_INSIDE_ASM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_INSIDE_ASM = 1   # Inside inline assembly block\n_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_END_ASM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_END_ASM = 2      # Last line of inline assembly block\n_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_BLOCK_ASM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_BLOCK_ASM = 3    # The whole block is an inline assembly block\n# Match start of assembly blocks\n_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_MATCH_ASM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_MATCH_ASM = re.compile(r'^\\s*(?:asm|_asm|__asm|__asm__)'\n                        r'(?:\\s+(volatile|__volatile__))?'\n                        r'\\s*[{(]')\n# Match strings that indicate we're working on a C (not C++) file.\n_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_SEARCH_C_FILE",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_SEARCH_C_FILE = re.compile(r'\\b(?:LINT_C_FILE|'\n                            r'vim?:\\s*.*(\\s*|:)filetype=c(\\s*|:|$))')\n# Match string that indicates we're working on a Linux Kernel file.\n_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_SEARCH_KERNEL_FILE",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_regexp_compile_cache",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_regexp_compile_cache = {}\n# {str, set(int)}: a map from error categories to sets of linenumbers\n# on which those errors are expected and should be suppressed.\n_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_error_suppressions",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_error_suppressions = {}\n# The root directory used for deriving header guard CPP variable.\n# This is set by --root flag.\n_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_root",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_root = None\n_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_root_debug",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_root_debug = False\n# The allowed line length of files.\n# This is set by --linelength flag.\n_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_line_length",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_line_length = 80\n# The allowed extensions for file names\n# This is set by --extensions flag.\n_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_valid_extensions",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n# Treat all headers starting with 'h' equally: .h, .hpp, .hxx etc.\n# This is set by --headers flag.\n_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_hpp_headers",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_hpp_headers = set(['h'])\n# {str, bool}: a map from error categories to booleans which indicate if the\n# category should be suppressed for every line.\n_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_global_error_suppressions",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_global_error_suppressions = {}\ndef ProcessHppHeadersOption(val):\n  global _hpp_headers\n  try:\n    _hpp_headers = set(val.split(','))\n    # Automatically append to extensions list so it does not have to be set 2 times\n    _valid_extensions.update(_hpp_headers)\n  except ValueError:\n    PrintUsage('Header extensions must be comma separated list.')\ndef IsHeaderExtension(file_extension):",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_cpplint_state",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_cpplint_state = _CppLintState()\ndef _OutputFormat():\n  \"\"\"Gets the module's output format.\"\"\"\n  return _cpplint_state.output_format\ndef _SetOutputFormat(output_format):\n  \"\"\"Sets the module's output format.\"\"\"\n  _cpplint_state.SetOutputFormat(output_format)\ndef _Quiet():\n  \"\"\"Return's the module's quiet setting.\"\"\"\n  return _cpplint_state.quiet",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CLEANSE_LINE_ESCAPES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CLEANSE_LINE_ESCAPES = re.compile(\n    r'\\\\([abfnrtv?\"\\\\\\']|\\d+|x[0-9a-fA-F]+)')\n# Match a single C style comment on the same line.\n_RE_PATTERN_C_COMMENTS = r'/\\*(?:[^*]|\\*(?!/))*\\*/'\n# Matches multi-line C style comments.\n# This RE is a little bit more complicated than one might expect, because we\n# have to take care of space removals tools so we can handle comments inside\n# statements better.\n# The current rule is: We only clear spaces from both sides when we're at the\n# end of the line. Otherwise, we try to remove spaces from the right side,",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_C_COMMENTS",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_C_COMMENTS = r'/\\*(?:[^*]|\\*(?!/))*\\*/'\n# Matches multi-line C style comments.\n# This RE is a little bit more complicated than one might expect, because we\n# have to take care of space removals tools so we can handle comments inside\n# statements better.\n# The current rule is: We only clear spaces from both sides when we're at the\n# end of the line. Otherwise, we try to remove spaces from the right side,\n# if this doesn't work we try on left side but only if there's a non-character\n# on the right.\n_RE_PATTERN_CLEANSE_LINE_C_COMMENTS = re.compile(",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CLEANSE_LINE_C_COMMENTS",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CLEANSE_LINE_C_COMMENTS = re.compile(\n    r'(\\s*' + _RE_PATTERN_C_COMMENTS + r'\\s*$|' +\n    _RE_PATTERN_C_COMMENTS + r'\\s+|' +\n    r'\\s+' + _RE_PATTERN_C_COMMENTS + r'(?=\\W)|' +\n    _RE_PATTERN_C_COMMENTS + r')')\ndef IsCppString(line):\n  \"\"\"Does line terminate so, that the next symbol is in string constant.\n  This function does not consider single-line nor multi-line comments.\n  Args:\n    line: is a partial line of code starting from the 0..n.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_UNSAFE_FUNC_PREFIX",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_UNSAFE_FUNC_PREFIX = r'(?:[-+*/=%^&|(<]\\s*|>\\s+)'\n_THREADING_LIST = (\n    ('asctime(', 'asctime_r(', _UNSAFE_FUNC_PREFIX + r'asctime\\([^)]+\\)'),\n    ('ctime(', 'ctime_r(', _UNSAFE_FUNC_PREFIX + r'ctime\\([^)]+\\)'),\n    ('getgrgid(', 'getgrgid_r(', _UNSAFE_FUNC_PREFIX + r'getgrgid\\([^)]+\\)'),\n    ('getgrnam(', 'getgrnam_r(', _UNSAFE_FUNC_PREFIX + r'getgrnam\\([^)]+\\)'),\n    ('getlogin(', 'getlogin_r(', _UNSAFE_FUNC_PREFIX + r'getlogin\\(\\)'),\n    ('getpwnam(', 'getpwnam_r(', _UNSAFE_FUNC_PREFIX + r'getpwnam\\([^)]+\\)'),\n    ('getpwuid(', 'getpwuid_r(', _UNSAFE_FUNC_PREFIX + r'getpwuid\\([^)]+\\)'),\n    ('gmtime(', 'gmtime_r(', _UNSAFE_FUNC_PREFIX + r'gmtime\\([^)]+\\)'),",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_THREADING_LIST",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_THREADING_LIST = (\n    ('asctime(', 'asctime_r(', _UNSAFE_FUNC_PREFIX + r'asctime\\([^)]+\\)'),\n    ('ctime(', 'ctime_r(', _UNSAFE_FUNC_PREFIX + r'ctime\\([^)]+\\)'),\n    ('getgrgid(', 'getgrgid_r(', _UNSAFE_FUNC_PREFIX + r'getgrgid\\([^)]+\\)'),\n    ('getgrnam(', 'getgrnam_r(', _UNSAFE_FUNC_PREFIX + r'getgrnam\\([^)]+\\)'),\n    ('getlogin(', 'getlogin_r(', _UNSAFE_FUNC_PREFIX + r'getlogin\\(\\)'),\n    ('getpwnam(', 'getpwnam_r(', _UNSAFE_FUNC_PREFIX + r'getpwnam\\([^)]+\\)'),\n    ('getpwuid(', 'getpwuid_r(', _UNSAFE_FUNC_PREFIX + r'getpwuid\\([^)]+\\)'),\n    ('gmtime(', 'gmtime_r(', _UNSAFE_FUNC_PREFIX + r'gmtime\\([^)]+\\)'),\n    ('localtime(', 'localtime_r(', _UNSAFE_FUNC_PREFIX + r'localtime\\([^)]+\\)'),",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_INVALID_INCREMENT",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_INVALID_INCREMENT = re.compile(\n    r'^\\s*\\*\\w+(\\+\\+|--);')\ndef CheckInvalidIncrement(filename, clean_lines, linenum, error):\n  \"\"\"Checks for invalid increment *count++.\n  For example following function:\n  void increment_counter(int* count) {\n    *count++;\n  }\n  is invalid, because it effectively does count++, moving pointer, and should\n  be replaced with ++*count, (*count)++ or *count += 1.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_TODO",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_TODO = re.compile(r'^//(\\s*)TODO(\\(.+?\\))?:?(\\s|$)?')\ndef CheckComment(line, filename, linenum, next_line_start, error):\n  \"\"\"Checks for common mistakes in comments.\n  Args:\n    line: The line in question.\n    filename: The name of the current file.\n    linenum: The number of the line to check.\n    next_line_start: The first non-whitespace column of the next line.\n    error: The function to call with any errors found.\n  \"\"\"",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_INCLUDE",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_INCLUDE = re.compile(r'^\\s*#\\s*include\\s*([<\"])([^>\"]*)[>\"].*$')\n# Matches the first component of a filename delimited by -s and _s. That is:\n#  _RE_FIRST_COMPONENT.match('foo').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo.cc').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo-bar_baz.cc').group(0) == 'foo'\n#  _RE_FIRST_COMPONENT.match('foo_bar-baz.cc').group(0) == 'foo'\n_RE_FIRST_COMPONENT = re.compile(r'^[^-_.]+')\ndef _DropCommonSuffixes(filename):\n  \"\"\"Drops common suffixes like _test.cc or -inl.h from filename.\n  For example:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_FIRST_COMPONENT",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_FIRST_COMPONENT = re.compile(r'^[^-_.]+')\ndef _DropCommonSuffixes(filename):\n  \"\"\"Drops common suffixes like _test.cc or -inl.h from filename.\n  For example:\n    >>> _DropCommonSuffixes('foo/foo-inl.h')\n    'foo/foo'\n    >>> _DropCommonSuffixes('foo/bar/foo.cc')\n    'foo/bar/foo'\n    >>> _DropCommonSuffixes('foo/foo_internal.h')\n    'foo/foo'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_IDENT",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_IDENT = r'[_a-zA-Z]\\w*'  # =~ [[:alpha:]][[:alnum:]]*\n_RE_PATTERN_TYPE = (\n    r'(?:const\\s+)?(?:typename\\s+|class\\s+|struct\\s+|union\\s+|enum\\s+)?'\n    r'(?:\\w|'\n    r'\\s*<(?:<(?:<[^<>]*>|[^<>])*>|[^<>])*>|'\n    r'::)+')\n# A call-by-reference parameter ends with '& identifier'.\n_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_TYPE",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_TYPE = (\n    r'(?:const\\s+)?(?:typename\\s+|class\\s+|struct\\s+|union\\s+|enum\\s+)?'\n    r'(?:\\w|'\n    r'\\s*<(?:<(?:<[^<>]*>|[^<>])*>|[^<>])*>|'\n    r'::)+')\n# A call-by-reference parameter ends with '& identifier'.\n_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')\n# A call-by-const-reference parameter either ends with 'const& identifier'",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_REF_PARAM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_REF_PARAM = re.compile(\n    r'(' + _RE_PATTERN_TYPE + r'(?:\\s*(?:\\bconst\\b|[*]))*\\s*'\n    r'&\\s*' + _RE_PATTERN_IDENT + r')\\s*(?:=[^,()]+)?[,)]')\n# A call-by-const-reference parameter either ends with 'const& identifier'\n# or looks like 'const type& identifier' when 'type' is atomic.\n_RE_PATTERN_CONST_REF_PARAM = (\n    r'(?:.*\\s*\\bconst\\s*&\\s*' + _RE_PATTERN_IDENT +\n    r'|const\\s+' + _RE_PATTERN_TYPE + r'\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\n# Stream types.\n_RE_PATTERN_REF_STREAM_PARAM = (",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_CONST_REF_PARAM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_CONST_REF_PARAM = (\n    r'(?:.*\\s*\\bconst\\s*&\\s*' + _RE_PATTERN_IDENT +\n    r'|const\\s+' + _RE_PATTERN_TYPE + r'\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\n# Stream types.\n_RE_PATTERN_REF_STREAM_PARAM = (\n    r'(?:.*stream\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\ndef CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_REF_STREAM_PARAM",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_REF_STREAM_PARAM = (\n    r'(?:.*stream\\s*&\\s*' + _RE_PATTERN_IDENT + r')')\ndef CheckLanguage(filename, clean_lines, linenum, file_extension,\n                  include_state, nesting_state, error):\n  \"\"\"Checks rules from the 'C++ language rules' section of cppguide.html.\n  Some of these rules are hard to test (function overloading, using\n  uint32 inappropriately), but we do the best we can.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_HEADERS_CONTAINING_TEMPLATES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_HEADERS_CONTAINING_TEMPLATES = (\n    ('<deque>', ('deque',)),\n    ('<functional>', ('unary_function', 'binary_function',\n                      'plus', 'minus', 'multiplies', 'divides', 'modulus',\n                      'negate',\n                      'equal_to', 'not_equal_to', 'greater', 'less',\n                      'greater_equal', 'less_equal',\n                      'logical_and', 'logical_or', 'logical_not',\n                      'unary_negate', 'not1', 'binary_negate', 'not2',\n                      'bind1st', 'bind2nd',",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_HEADERS_MAYBE_TEMPLATES",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_HEADERS_MAYBE_TEMPLATES = (\n    ('<algorithm>', ('copy', 'max', 'min', 'min_element', 'sort',\n                     'transform',\n                    )),\n    ('<utility>', ('forward', 'make_pair', 'move', 'swap')),\n    )\n_RE_PATTERN_STRING = re.compile(r'\\bstring\\b')\n_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_STRING",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_STRING = re.compile(r'\\bstring\\b')\n_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:\n    # Match max<type>(..., ...), max(..., ...), but not foo->max, foo.max or\n    # type::max().\n    _re_pattern_headers_maybe_templates.append(\n        (re.compile(r'[^>.]\\b' + _template + r'(<.*?>)?\\([^\\)]'),\n            _template,\n            _header))",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_re_pattern_headers_maybe_templates",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_re_pattern_headers_maybe_templates = []\nfor _header, _templates in _HEADERS_MAYBE_TEMPLATES:\n  for _template in _templates:\n    # Match max<type>(..., ...), max(..., ...), but not foo->max, foo.max or\n    # type::max().\n    _re_pattern_headers_maybe_templates.append(\n        (re.compile(r'[^>.]\\b' + _template + r'(<.*?>)?\\([^\\)]'),\n            _template,\n            _header))\n# Other scripts may reach in and modify this pattern.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_re_pattern_templates",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_re_pattern_templates = []\nfor _header, _templates in _HEADERS_CONTAINING_TEMPLATES:\n  for _template in _templates:\n    _re_pattern_templates.append(\n        (re.compile(r'(\\<|\\b)' + _template + r'\\s*\\<'),\n         _template + '<>',\n         _header))\ndef FilesBelongToSameModule(filename_cc, filename_h):\n  \"\"\"Check if these two filenames belong to the same module.\n  The concept of a 'module' here is a as follows:",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "_RE_PATTERN_EXPLICIT_MAKEPAIR",
        "kind": 5,
        "importPath": "libvpx.tools.cpplint",
        "description": "libvpx.tools.cpplint",
        "peekOfCode": "_RE_PATTERN_EXPLICIT_MAKEPAIR = re.compile(r'\\bmake_pair\\s*<')\ndef CheckMakePairUsesDeduction(filename, clean_lines, linenum, error):\n  \"\"\"Check that make_pair's template arguments are deduced.\n  G++ 4.6 in C++11 mode fails badly if make_pair's template arguments are\n  specified explicitly, and such use isn't intended in any case.\n  Args:\n    filename: The name of the current file.\n    clean_lines: A CleansedLines instance containing the file.\n    linenum: The number of the line to check.\n    error: The function to call with any errors found.",
        "detail": "libvpx.tools.cpplint",
        "documentation": {}
    },
    {
        "label": "DiffLines",
        "kind": 6,
        "importPath": "libvpx.tools.diff",
        "description": "libvpx.tools.diff",
        "peekOfCode": "class DiffLines(object):\n    \"\"\"A container for one half of a diff.\"\"\"\n    def __init__(self, filename, offset, length):\n        self.filename = filename\n        self.offset = offset\n        self.length = length\n        self.lines = []\n        self.delta_line_nums = []\n    def Append(self, line):\n        l = len(self.lines)",
        "detail": "libvpx.tools.diff",
        "documentation": {}
    },
    {
        "label": "DiffHunk",
        "kind": 6,
        "importPath": "libvpx.tools.diff",
        "description": "libvpx.tools.diff",
        "peekOfCode": "class DiffHunk(object):\n    \"\"\"A container for one diff hunk, consisting of two DiffLines.\"\"\"\n    def __init__(self, header, file_a, file_b, start_a, len_a, start_b, len_b):\n        self.header = header\n        self.left = DiffLines(file_a, start_a, len_a)\n        self.right = DiffLines(file_b, start_b, len_b)\n        self.lines = []\n    def Append(self, line):\n        \"\"\"Adds a line to the DiffHunk and its DiffLines children.\"\"\"\n        if line[0] == \"-\":",
        "detail": "libvpx.tools.diff",
        "documentation": {}
    },
    {
        "label": "ParseDiffHunks",
        "kind": 2,
        "importPath": "libvpx.tools.diff",
        "description": "libvpx.tools.diff",
        "peekOfCode": "def ParseDiffHunks(stream):\n    \"\"\"Walk a file-like object, yielding DiffHunks as they're parsed.\"\"\"\n    file_regex = re.compile(r\"(\\+\\+\\+|---) (\\S+)\")\n    range_regex = re.compile(r\"@@ -(\\d+)(,(\\d+))? \\+(\\d+)(,(\\d+))?\")\n    hunk = None\n    while True:\n        line = stream.readline()\n        if not line:\n            break\n        if hunk is None:",
        "detail": "libvpx.tools.diff",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "libvpx.tools.diff",
        "description": "libvpx.tools.diff",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport re\nclass DiffLines(object):\n    \"\"\"A container for one half of a diff.\"\"\"\n    def __init__(self, filename, offset, length):\n        self.filename = filename\n        self.offset = offset\n        self.length = length\n        self.lines = []\n        self.delta_line_nums = []",
        "detail": "libvpx.tools.diff",
        "documentation": {}
    },
    {
        "label": "FormatDiffHunks",
        "kind": 2,
        "importPath": "libvpx.tools.intersect-diffs",
        "description": "libvpx.tools.intersect-diffs",
        "peekOfCode": "def FormatDiffHunks(hunks):\n    \"\"\"Re-serialize a list of DiffHunks.\"\"\"\n    r = []\n    last_header = None\n    for hunk in hunks:\n        this_header = hunk.header[0:2]\n        if last_header != this_header:\n            r.extend(hunk.header)\n            last_header = this_header\n        else:",
        "detail": "libvpx.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "ZipHunks",
        "kind": 2,
        "importPath": "libvpx.tools.intersect-diffs",
        "description": "libvpx.tools.intersect-diffs",
        "peekOfCode": "def ZipHunks(rhs_hunks, lhs_hunks):\n    \"\"\"Join two hunk lists on filename.\"\"\"\n    for rhs_hunk in rhs_hunks:\n        rhs_file = rhs_hunk.right.filename.split(\"/\")[1:]\n        for lhs_hunk in lhs_hunks:\n            lhs_file = lhs_hunk.left.filename.split(\"/\")[1:]\n            if lhs_file != rhs_file:\n                continue\n            yield (rhs_hunk, lhs_hunk)\ndef main():",
        "detail": "libvpx.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "libvpx.tools.intersect-diffs",
        "description": "libvpx.tools.intersect-diffs",
        "peekOfCode": "def main():\n    old_hunks = [x for x in diff.ParseDiffHunks(open(sys.argv[1], \"r\"))]\n    new_hunks = [x for x in diff.ParseDiffHunks(open(sys.argv[2], \"r\"))]\n    out_hunks = []\n    # Join the right hand side of the older diff with the left hand side of the\n    # newer diff.\n    for old_hunk, new_hunk in ZipHunks(old_hunks, new_hunks):\n        if new_hunk in out_hunks:\n            continue\n        old_lines = old_hunk.right",
        "detail": "libvpx.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "libvpx.tools.intersect-diffs",
        "description": "libvpx.tools.intersect-diffs",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport sys\nimport diff\ndef FormatDiffHunks(hunks):\n    \"\"\"Re-serialize a list of DiffHunks.\"\"\"\n    r = []\n    last_header = None\n    for hunk in hunks:\n        this_header = hunk.header[0:2]\n        if last_header != this_header:",
        "detail": "libvpx.tools.intersect-diffs",
        "documentation": {}
    },
    {
        "label": "Usage",
        "kind": 6,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "class Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SubprocessException",
        "kind": 6,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "class SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args\n        self._expected_returncode = expected_returncode\n        super(Subprocess, self).__init__(args, **kwargs)",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "Subprocess",
        "kind": 6,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "class Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):\n        self._args = args\n        self._expected_returncode = expected_returncode\n        super(Subprocess, self).__init__(args, **kwargs)\n    def communicate(self, *args, **kwargs):\n        result = super(Subprocess, self).communicate(*args, **kwargs)\n        if self._expected_returncode is not None:\n            try:",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "def main(argv=None):\n    if argv is None:\n        argv = sys.argv\n    try:\n        try:\n            opts, args = getopt.getopt(argv[1:], SHORT_OPTIONS, LONG_OPTIONS)\n        except getopt.error as msg:\n            raise Usage(msg)\n        # process options\n        for o, _ in opts:",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SHORT_OPTIONS",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "SHORT_OPTIONS = \"h\"\nLONG_OPTIONS = [\"help\"]\nTOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "LONG_OPTIONS",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "LONG_OPTIONS = [\"help\"]\nTOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "TOPLEVEL_CMD",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "TOPLEVEL_CMD = [\"git\", \"rev-parse\", \"--show-toplevel\"]\nDIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "DIFF_CMD",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "DIFF_CMD = [\"git\", \"diff\"]\nDIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "DIFF_INDEX_CMD",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "DIFF_INDEX_CMD = [\"git\", \"diff-index\", \"-u\", \"HEAD\", \"--\"]\nSHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "SHOW_CMD",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "SHOW_CMD = [\"git\", \"show\"]\nCPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "CPPLINT_FILTERS",
        "kind": 5,
        "importPath": "libvpx.tools.lint-hunks",
        "description": "libvpx.tools.lint-hunks",
        "peekOfCode": "CPPLINT_FILTERS = [\"-readability/casting\"]\nclass Usage(Exception):\n    pass\nclass SubprocessException(Exception):\n    def __init__(self, args):\n        msg = \"Failed to execute '%s'\"%(\" \".join(args))\n        super(SubprocessException, self).__init__(msg)\nclass Subprocess(subprocess.Popen):\n    \"\"\"Adds the notion of an expected returncode to Popen.\"\"\"\n    def __init__(self, args, expected_returncode=0, **kwargs):",
        "detail": "libvpx.tools.lint-hunks",
        "documentation": {}
    },
    {
        "label": "wrap",
        "kind": 2,
        "importPath": "libvpx.tools.wrap-commit-msg",
        "description": "libvpx.tools.wrap-commit-msg",
        "peekOfCode": "def wrap(text):\n    if text:\n        return textwrap.fill(text, break_long_words=False) + '\\n'\n    return \"\"\ndef main(fileobj):\n    text = \"\"\n    output = \"\"\n    while True:\n        line = fileobj.readline()\n        if not line:",
        "detail": "libvpx.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "libvpx.tools.wrap-commit-msg",
        "description": "libvpx.tools.wrap-commit-msg",
        "peekOfCode": "def main(fileobj):\n    text = \"\"\n    output = \"\"\n    while True:\n        line = fileobj.readline()\n        if not line:\n            break\n        if line.lstrip() == line:\n            text += line\n        else:",
        "detail": "libvpx.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "libvpx.tools.wrap-commit-msg",
        "description": "libvpx.tools.wrap-commit-msg",
        "peekOfCode": "__author__ = \"jkoleszar@google.com\"\nimport textwrap\nimport sys\ndef wrap(text):\n    if text:\n        return textwrap.fill(text, break_long_words=False) + '\\n'\n    return \"\"\ndef main(fileobj):\n    text = \"\"\n    output = \"\"",
        "detail": "libvpx.tools.wrap-commit-msg",
        "documentation": {}
    },
    {
        "label": "checkout",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def checkout(revision):\n    \"\"\"\n    Checkout a revision.\n    \"\"\"\n    pass\ndef current_rev():\n    \"\"\"\n    Get the current revision\n    \"\"\"\n    return str(random())",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "current_rev",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def current_rev():\n    \"\"\"\n    Get the current revision\n    \"\"\"\n    return str(random())\ndef revisions(rev_a, rev_b):\n    \"\"\"\n    Get a list of revisions from one to another.\n    \"\"\"\n    pass",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "revisions",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def revisions(rev_a, rev_b):\n    \"\"\"\n    Get a list of revisions from one to another.\n    \"\"\"\n    pass\ndef stash():\n    \"\"\"\n    Stash the repository.\n    \"\"\"\n    pass",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "stash",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def stash():\n    \"\"\"\n    Stash the repository.\n    \"\"\"\n    pass\ndef unstash():\n    \"\"\"\n    Unstash the repository.\n    \"\"\"\n    pass",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "unstash",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def unstash():\n    \"\"\"\n    Unstash the repository.\n    \"\"\"\n    pass\ndef bisect(command, revision):\n    \"\"\"\n    Perform a bisection.\n    \"\"\"\n    raise NotImplementedError(\"dummy SCM backend does not support bisection\")",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.dummy",
        "description": "x264.tools.digress.scm.dummy",
        "peekOfCode": "def bisect(command, revision):\n    \"\"\"\n    Perform a bisection.\n    \"\"\"\n    raise NotImplementedError(\"dummy SCM backend does not support bisection\")",
        "detail": "x264.tools.digress.scm.dummy",
        "documentation": {}
    },
    {
        "label": "checkout",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def checkout(revision):\n    \"\"\"\n    Checkout a revision from git.\n    \"\"\"\n    proc = Popen([\n        \"git\",\n        \"checkout\",\n        \"-f\",\n        revision\n    ], stdout=PIPE, stderr=STDOUT)",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "rev_parse",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def rev_parse(ref):\n    proc = Popen([\n        \"git\",\n        \"rev-parse\",\n        ref\n    ], stdout=PIPE, stderr=STDOUT)\n    output = proc.communicate()[0].strip()\n    if proc.returncode != 0:\n        raise SCMError(\"rev-parse error: %s\" % output)\n    return output",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "current_rev",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def current_rev():\n    \"\"\"\n    Get the current revision.\n    \"\"\"\n    return rev_parse(\"HEAD\")\ndef current_branch():\n    \"\"\"\n    Get the current branch.\n    \"\"\"\n    proc = Popen([",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "current_branch",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def current_branch():\n    \"\"\"\n    Get the current branch.\n    \"\"\"\n    proc = Popen([\n        \"git\",\n        \"branch\",\n        \"--no-color\"\n    ], stdout=PIPE, stderr=STDOUT)\n    output = proc.communicate()[0].strip()",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "revisions",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def revisions(rev_a, rev_b):\n    \"\"\"\n    Get a list of revisions from one to another.\n    \"\"\"\n    proc = Popen([\n        \"git\",\n        \"log\",\n        \"--format=%H\", (\"%s...%s\" % (rev_a, rev_b))\n    ], stdout=PIPE, stderr=STDOUT)\n    output = proc.communicate()[0].strip()",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "stash",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def stash():\n    \"\"\"\n    Stash the repository.\n    \"\"\"\n    proc = Popen([\n        \"git\",\n        \"stash\",\n        \"save\",\n        \"--keep-index\"\n    ], stdout=PIPE, stderr=STDOUT)",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "unstash",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def unstash():\n    \"\"\"\n    Unstash the repository.\n    \"\"\"\n    proc = Popen([\"git\", \"stash\", \"pop\"], stdout=PIPE, stderr=STDOUT)\n    proc.communicate()\ndef bisect(*args):\n    \"\"\"\n    Perform a bisection.\n    \"\"\"",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def bisect(*args):\n    \"\"\"\n    Perform a bisection.\n    \"\"\"\n    proc = Popen(([\"git\", \"bisect\"] + list(args)), stdout=PIPE, stderr=STDOUT)\n    output = proc.communicate()[0]\n    if proc.returncode != 0:\n        raise SCMError(\"bisect error: %s\" % output)\n    return output\ndef dirty():",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "dirty",
        "kind": 2,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "def dirty():\n    \"\"\"\n    Check if the working tree is dirty.\n    \"\"\"\n    proc = Popen([\"git\", \"status\"], stdout=PIPE, stderr=STDOUT)\n    output = proc.communicate()[0].strip()\n    if proc.returncode != 0:\n        raise SCMError(\"status error: %s\" % output)\n    if \"modified:\" in output:\n        return True",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "GIT_BRANCH_EXPR",
        "kind": 5,
        "importPath": "x264.tools.digress.scm.git",
        "description": "x264.tools.digress.scm.git",
        "peekOfCode": "GIT_BRANCH_EXPR = re.compile(\"[*] (.*)\")\ndef checkout(revision):\n    \"\"\"\n    Checkout a revision from git.\n    \"\"\"\n    proc = Popen([\n        \"git\",\n        \"checkout\",\n        \"-f\",\n        revision",
        "detail": "x264.tools.digress.scm.git",
        "documentation": {}
    },
    {
        "label": "Dispatcher",
        "kind": 6,
        "importPath": "x264.tools.digress.cli",
        "description": "x264.tools.digress.cli",
        "peekOfCode": "class Dispatcher(object):\n    \"\"\"\n    Dispatcher for CLI commands.\n    \"\"\"\n    def __init__(self, fixture):\n        self.fixture = fixture\n        fixture.dispatcher = self\n    def _monkey_print_help(self, optparse, *args, **kwargs):\n        # monkey patches OptionParser._print_help\n        OptionParser.print_help(optparse, *args, **kwargs)",
        "detail": "x264.tools.digress.cli",
        "documentation": {}
    },
    {
        "label": "dispatchable",
        "kind": 2,
        "importPath": "x264.tools.digress.cli",
        "description": "x264.tools.digress.cli",
        "peekOfCode": "def dispatchable(func):\n    \"\"\"\n    Mark a method as dispatchable.\n    \"\"\"\n    func.digress_dispatchable = True\n    return func\nclass Dispatcher(object):\n    \"\"\"\n    Dispatcher for CLI commands.\n    \"\"\"",
        "detail": "x264.tools.digress.cli",
        "documentation": {}
    },
    {
        "label": "compare_direct",
        "kind": 2,
        "importPath": "x264.tools.digress.comparers",
        "description": "x264.tools.digress.comparers",
        "peekOfCode": "def compare_direct(value_a, value_b):\n    if value_a != value_b:\n        raise ComparisonError(\"%s is not %s\" % (value_a, value_b))\ndef compare_pass(value_a, value_b):\n    \"\"\"\n    Always true, as long as the test is passed.\n    \"\"\"\ndef compare_tolerance(tolerance):\n    def _compare_tolerance(value_a, value_b):\n        if abs(value_a - value_b) > tolerance:",
        "detail": "x264.tools.digress.comparers",
        "documentation": {}
    },
    {
        "label": "compare_pass",
        "kind": 2,
        "importPath": "x264.tools.digress.comparers",
        "description": "x264.tools.digress.comparers",
        "peekOfCode": "def compare_pass(value_a, value_b):\n    \"\"\"\n    Always true, as long as the test is passed.\n    \"\"\"\ndef compare_tolerance(tolerance):\n    def _compare_tolerance(value_a, value_b):\n        if abs(value_a - value_b) > tolerance:\n            raise ComparisonError(\"%s is not %s (tolerance: %s)\" % (\n                value_a,\n                value_b,",
        "detail": "x264.tools.digress.comparers",
        "documentation": {}
    },
    {
        "label": "compare_tolerance",
        "kind": 2,
        "importPath": "x264.tools.digress.comparers",
        "description": "x264.tools.digress.comparers",
        "peekOfCode": "def compare_tolerance(tolerance):\n    def _compare_tolerance(value_a, value_b):\n        if abs(value_a - value_b) > tolerance:\n            raise ComparisonError(\"%s is not %s (tolerance: %s)\" % (\n                value_a,\n                value_b,\n                tolerance\n            ))\n    return _compare_tolerance\ndef compare_files(file_a, file_b):",
        "detail": "x264.tools.digress.comparers",
        "documentation": {}
    },
    {
        "label": "compare_files",
        "kind": 2,
        "importPath": "x264.tools.digress.comparers",
        "description": "x264.tools.digress.comparers",
        "peekOfCode": "def compare_files(file_a, file_b):\n    size_a = os.path.getsize(file_a)\n    size_b = os.path.getsize(file_b)\n    print file_a, file_b\n    if size_a != size_b:\n        raise ComparisonError(\"%s is not the same size as %s\" % (\n            file_a,\n            file_b\n        ))\n    BUFFER_SIZE = 8196",
        "detail": "x264.tools.digress.comparers",
        "documentation": {}
    },
    {
        "label": "TEST_PASS",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "TEST_PASS = 0\nTEST_FAIL = 1\nTEST_DISABLED = 2\nTEST_SKIPPED = 3\nCASE_PASS = 0\nCASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "TEST_FAIL",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "TEST_FAIL = 1\nTEST_DISABLED = 2\nTEST_SKIPPED = 3\nCASE_PASS = 0\nCASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "TEST_DISABLED",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "TEST_DISABLED = 2\nTEST_SKIPPED = 3\nCASE_PASS = 0\nCASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "TEST_SKIPPED",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "TEST_SKIPPED = 3\nCASE_PASS = 0\nCASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "CASE_PASS",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "CASE_PASS = 0\nCASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "CASE_FAIL",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "CASE_FAIL = 1\nFIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "FIXTURE_PASS",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "FIXTURE_PASS = 0\nFIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "FIXTURE_FAIL",
        "kind": 5,
        "importPath": "x264.tools.digress.constants",
        "description": "x264.tools.digress.constants",
        "peekOfCode": "FIXTURE_FAIL = 1",
        "detail": "x264.tools.digress.constants",
        "documentation": {}
    },
    {
        "label": "DigressError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class DigressError(Exception):\n    \"\"\"\n    Digress error base class.\n    \"\"\"\nclass NoSuchTestError(DigressError):\n    \"\"\"\n    Raised when no such test exists.\n    \"\"\"\nclass DisabledTestError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "NoSuchTestError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class NoSuchTestError(DigressError):\n    \"\"\"\n    Raised when no such test exists.\n    \"\"\"\nclass DisabledTestError(DigressError):\n    \"\"\"\n    Test is disabled.\n    \"\"\"\nclass SkippedTestError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "DisabledTestError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class DisabledTestError(DigressError):\n    \"\"\"\n    Test is disabled.\n    \"\"\"\nclass SkippedTestError(DigressError):\n    \"\"\"\n    Test is marked as skipped.\n    \"\"\"\nclass DisabledCaseError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "SkippedTestError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class SkippedTestError(DigressError):\n    \"\"\"\n    Test is marked as skipped.\n    \"\"\"\nclass DisabledCaseError(DigressError):\n    \"\"\"\n    Case is marked as disabled.\n    \"\"\"\nclass SkippedCaseError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "DisabledCaseError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class DisabledCaseError(DigressError):\n    \"\"\"\n    Case is marked as disabled.\n    \"\"\"\nclass SkippedCaseError(DigressError):\n    \"\"\"\n    Case is marked as skipped.\n    \"\"\"\nclass FailedTestError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "SkippedCaseError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class SkippedCaseError(DigressError):\n    \"\"\"\n    Case is marked as skipped.\n    \"\"\"\nclass FailedTestError(DigressError):\n    \"\"\"\n    Test failed.\n    \"\"\"\nclass ComparisonError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "FailedTestError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class FailedTestError(DigressError):\n    \"\"\"\n    Test failed.\n    \"\"\"\nclass ComparisonError(DigressError):\n    \"\"\"\n    Comparison failed.\n    \"\"\"\nclass IncomparableError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "ComparisonError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class ComparisonError(DigressError):\n    \"\"\"\n    Comparison failed.\n    \"\"\"\nclass IncomparableError(DigressError):\n    \"\"\"\n    Values cannot be compared.\n    \"\"\"\nclass AlreadyRunError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "IncomparableError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class IncomparableError(DigressError):\n    \"\"\"\n    Values cannot be compared.\n    \"\"\"\nclass AlreadyRunError(DigressError):\n    \"\"\"\n    Test/case has already been run.\n    \"\"\"\nclass SCMError(DigressError):\n    \"\"\"",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "AlreadyRunError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class AlreadyRunError(DigressError):\n    \"\"\"\n    Test/case has already been run.\n    \"\"\"\nclass SCMError(DigressError):\n    \"\"\"\n    Error occurred in SCM.\n    \"\"\"\n    def __init__(self, message):\n        self.message = message.replace(\"\\n\", \" \")",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "SCMError",
        "kind": 6,
        "importPath": "x264.tools.digress.errors",
        "description": "x264.tools.digress.errors",
        "peekOfCode": "class SCMError(DigressError):\n    \"\"\"\n    Error occurred in SCM.\n    \"\"\"\n    def __init__(self, message):\n        self.message = message.replace(\"\\n\", \" \")\n    def __str__(self):\n        return self.message",
        "detail": "x264.tools.digress.errors",
        "documentation": {}
    },
    {
        "label": "depends",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class depends(object):\n    \"\"\"\n    Dependency decorator for a test.\n    \"\"\"\n    def __init__(self, *test_names):\n        self.test_names = test_names\n    def __call__(self, func):\n        func.digress_depends = self.test_names\n        return func\nclass _skipped(object):",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "_skipped",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class _skipped(object):\n    \"\"\"\n    Internal skipped decorator.\n    \"\"\"\n    def __init__(self, reason=\"\"):\n        self._reason = reason\n    def __call__(self, func):\n        @wraps(func)\n        def _closure(*args):\n            raise SkippedTestError(self._reason)",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "disabled",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class disabled(object):\n    \"\"\"\n    Disable a test, with reason.\n    \"\"\"\n    def __init__(self, reason=\"\"):\n        self._reason = reason\n    def __call__(self, func):\n        @wraps(func)\n        def _closure(*args):\n            raise DisabledTestError(self._reason)",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "comparer",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class comparer(object):\n    \"\"\"\n    Set the comparer for a test.\n    \"\"\"\n    def __init__(self, comparer_):\n        self._comparer = comparer_\n    def __call__(self, func):\n        func.digress_comparer = self._comparer\n        return func\nclass Fixture(object):",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "Fixture",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class Fixture(object):\n    cases = []\n    scm = None\n    flush_before = False\n    def _skip_case(self, case, depend):\n        for name, meth in inspect.getmembers(case):\n            if name[:5] == \"test_\":\n                setattr(\n                    case,\n                    name,",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "Case",
        "kind": 6,
        "importPath": "x264.tools.digress.testing",
        "description": "x264.tools.digress.testing",
        "peekOfCode": "class Case(object):\n    depends = []\n    fixture = None\n    def _get_test_by_name(self, test_name):\n        if not hasattr(self, \"test_%s\" % test_name):\n            raise NoSuchTestError(test_name)\n        return getattr(self, \"test_%s\" % test_name)\n    def _run_test(self, test, results):\n        test_name = test.__name__[5:]\n        if test_name in results:",
        "detail": "x264.tools.digress.testing",
        "documentation": {}
    },
    {
        "label": "x264",
        "kind": 6,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "class x264(Fixture):\n    scm = x264git\nclass Compile(Case):\n    @comparer(compare_pass)\n    def test_configure(self):\n        Popen([\n            \"make\",\n            \"distclean\"\n        ], stdout=PIPE, stderr=STDOUT).communicate()\n        configure_proc = Popen([",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "Compile",
        "kind": 6,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "class Compile(Case):\n    @comparer(compare_pass)\n    def test_configure(self):\n        Popen([\n            \"make\",\n            \"distclean\"\n        ], stdout=PIPE, stderr=STDOUT).communicate()\n        configure_proc = Popen([\n            \"./configure\"\n        ] + self.fixture.dispatcher.configure, stdout=PIPE, stderr=STDOUT)",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "Regression",
        "kind": 6,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "class Regression(Case):\n    depends = [ Compile ]\n    _psnr_pattern = re.compile(r\"x264 [[]info[]]: PSNR Mean Y:\\d+[.]\\d+ U:\\d+[.]\\d+ V:\\d+[.]\\d+ Avg:\\d+[.]\\d+ Global:(\\d+[.]\\d+) kb/s:\\d+[.]\\d+\")\n    _ssim_pattern = re.compile(r\"x264 [[]info[]]: SSIM Mean Y:(\\d+[.]\\d+) [(]\\d+[.]\\d+db[)]\")\n    def __init__(self):\n        if self.fixture.dispatcher.x264:\n            self.__class__.__name__ += \" %s\" % \" \".join(self.fixture.dispatcher.x264)\n    def test_psnr(self):\n        try:\n            x264_proc = Popen([",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "Dispatcher",
        "kind": 6,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "class Dispatcher(_Dispatcher):\n    video = \"akiyo_qcif.y4m\"\n    products = 50\n    configure = []\n    x264 = []\n    yuv_tests = [ \"jm\" ]\n    def _populate_parser(self):\n        super(Dispatcher, self)._populate_parser()\n        # don't do a whole lot with this\n        tcase = _YUVOutputComparisonFactory()",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "compare_yuv_output",
        "kind": 2,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "def compare_yuv_output(width, height):\n    def _compare_yuv_output(file_a, file_b):\n        size_a = os.path.getsize(file_a)\n        size_b = os.path.getsize(file_b)\n        if size_a != size_b:\n            raise ComparisonError(\"%s is not the same size as %s\" % (\n                file_a,\n                file_b\n            ))\n        BUFFER_SIZE = 8196",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "program_exists",
        "kind": 2,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "def program_exists(program):\n    def is_exe(fpath):\n        return os.path.exists(fpath) and os.access(fpath, os.X_OK)\n    fpath, fname = os.path.split(program)\n    if fpath:\n        if is_exe(program):\n            return program\n    else:\n        for path in os.environ[\"PATH\"].split(os.pathsep):\n            exe_file = os.path.join(path, program)",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "OPTIONS",
        "kind": 5,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "OPTIONS = [\n    [ \"--tune %s\" % t for t in (\"film\", \"zerolatency\") ],\n    (\"\", \"--intra-refresh\"),\n    (\"\", \"--no-cabac\"),\n    (\"\", \"--interlaced\"),\n    (\"\", \"--slice-max-size 1000\"),\n    (\"\", \"--frame-packing 5\"),\n    [ \"--preset %s\" % p for p in (\"ultrafast\",\n                                  \"superfast\",\n                                  \"veryfast\",",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "_dimension_pattern",
        "kind": 5,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "_dimension_pattern = re.compile(r\"\\w+ [[]info[]]: (\\d+)x(\\d+)[pi] \\d+:\\d+ @ \\d+/\\d+ fps [(][vc]fr[)]\")\ndef _YUVOutputComparisonFactory():\n    class YUVOutputComparison(Case):\n        _dimension_pattern = _dimension_pattern\n        depends = [ Compile ]\n        options = []\n        def __init__(self):\n            for name, meth in inspect.getmembers(self):\n                if name[:5] == \"test_\" and name[5:] not in self.fixture.dispatcher.yuv_tests:\n                    delattr(self.__class__, name)",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "_generated",
        "kind": 5,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "_generated = []\nfixture = x264()\nfixture.register_case(Compile)\nfixture.register_case(Regression)\nclass Dispatcher(_Dispatcher):\n    video = \"akiyo_qcif.y4m\"\n    products = 50\n    configure = []\n    x264 = []\n    yuv_tests = [ \"jm\" ]",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "fixture",
        "kind": 5,
        "importPath": "x264.tools.test_x264",
        "description": "x264.tools.test_x264",
        "peekOfCode": "fixture = x264()\nfixture.register_case(Compile)\nfixture.register_case(Regression)\nclass Dispatcher(_Dispatcher):\n    video = \"akiyo_qcif.y4m\"\n    products = 50\n    configure = []\n    x264 = []\n    yuv_tests = [ \"jm\" ]\n    def _populate_parser(self):",
        "detail": "x264.tools.test_x264",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "source_suffix = '.rst'\n# Name of the master file \nmaster_doc = 'index'\n# General information about the project.\nproject = u'x265'\n# This is the Copyright Information that will appear on the bottom of the document\ncopyright = u'2014 MulticoreWare Inc'\n# -- Options for HTML output ---------------------------------------------------\nhtml_theme = \"sphinx_rtd_theme\"\n# One entry per manual page. List of tuples",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "master_doc = 'index'\n# General information about the project.\nproject = u'x265'\n# This is the Copyright Information that will appear on the bottom of the document\ncopyright = u'2014 MulticoreWare Inc'\n# -- Options for HTML output ---------------------------------------------------\nhtml_theme = \"sphinx_rtd_theme\"\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "project = u'x265'\n# This is the Copyright Information that will appear on the bottom of the document\ncopyright = u'2014 MulticoreWare Inc'\n# -- Options for HTML output ---------------------------------------------------\nhtml_theme = \"sphinx_rtd_theme\"\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    ('index', 'libx265', 'Full x265 Documentation',\n    ['MulticoreWare Inc'], 3),",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "copyright = u'2014 MulticoreWare Inc'\n# -- Options for HTML output ---------------------------------------------------\nhtml_theme = \"sphinx_rtd_theme\"\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    ('index', 'libx265', 'Full x265 Documentation',\n    ['MulticoreWare Inc'], 3),\n    ('x265', 'x265', 'x265 CLI Documentation',\n    ['MulticoreWare Inc'], 1)",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "html_theme = \"sphinx_rtd_theme\"\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    ('index', 'libx265', 'Full x265 Documentation',\n    ['MulticoreWare Inc'], 3),\n    ('x265', 'x265', 'x265 CLI Documentation',\n    ['MulticoreWare Inc'], 1)\n]",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "x265_git.doc.reST.conf",
        "description": "x265_git.doc.reST.conf",
        "peekOfCode": "man_pages = [\n    ('index', 'libx265', 'Full x265 Documentation',\n    ['MulticoreWare Inc'], 3),\n    ('x265', 'x265', 'x265 CLI Documentation',\n    ['MulticoreWare Inc'], 1)\n]",
        "detail": "x265_git.doc.reST.conf",
        "documentation": {}
    }
]